{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a8ebfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/ubuntu/anaconda3/lib/python3.10/site-packages (23.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8af310f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ubuntu/anaconda3/lib/python3.10/site-packages (4.24.0)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (0.19.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (0.11.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3df390e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/ubuntu/anaconda3/lib/python3.10/site-packages (2.14.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (12.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: xxhash in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (0.19.0)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1e76a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu==2.8.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (23.5.26)\n",
      "Requirement already satisfied: gast>=0.2.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (3.7.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.1.2)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (16.0.6)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (3.20.0)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (65.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (4.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.14.1)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (2.8.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (2.8.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.59.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-gpu==2.8.0) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-gpu==2.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "265ce3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.20 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (3.20.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install protobuf==3.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c89037b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import re\n",
    "import os\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5458e22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 수 : 5010\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('랜덤_5010개_GPT4.csv')\n",
    "print('총 샘플의 수 :',len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90855a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>sentence</th>\n",
       "      <th>게시일</th>\n",
       "      <th>영상 좋아요 수</th>\n",
       "      <th>kor_sentence</th>\n",
       "      <th>작성자</th>\n",
       "      <th>댓글 작성일</th>\n",
       "      <th>댓글 좋아요 수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>리니지W 전섭최초 집행검! 330억 투자한 캐릭 소개합니다 (성북동초코파이형님)  ...</td>\n",
       "      <td>2023-05-05T12:45:55Z</td>\n",
       "      <td>1048</td>\n",
       "      <td>🥛롤🥛뱃🥛올한해 가장 잘한인을 한게 아닐까 싶다.. 삶의 질이 달라져 버렸습니다 고...</td>\n",
       "      <td>1M CYRUS</td>\n",
       "      <td>2023-11-06T17:52:52Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>배그 이후 가장 성공한 한국 FPS (feat. 넥슨)</td>\n",
       "      <td>2023-11-05T13:39:51Z</td>\n",
       "      <td>2977</td>\n",
       "      <td>원격포맷은 지룡자🕷</td>\n",
       "      <td>JAY</td>\n",
       "      <td>2023-11-10T10:39:24Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[피파4] 1억부터 4600억까지 몰아보기 feat. 인생강화</td>\n",
       "      <td>2022-12-06T09:11:47Z</td>\n",
       "      <td>4052</td>\n",
       "      <td>여캠 롤비제이들 왜케 못하는데 긔엽냐 지는게 꿀인줄알았는데 이기기도 하네 🇨🇬롤🇨🇬뱃🇨🇬</td>\n",
       "      <td>Neardie Born</td>\n",
       "      <td>2023-10-21T11:15:42Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>패치 후 피파를 떠납니다!... 피파4</td>\n",
       "      <td>2023-06-27T08:30:00Z</td>\n",
       "      <td>106</td>\n",
       "      <td>현피장인 코뚱잉 바텀을 평정한다 배헤당 일.85 접속해서 확인합시다 ?비?제?이?벳?</td>\n",
       "      <td>the dale lee lowe jr family</td>\n",
       "      <td>2023-07-24T10:26:22Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>아니; 떡락도 이런 떡락이 없는 로스트아크 글로벌 서버 근황;;</td>\n",
       "      <td>2023-06-11T12:00:39Z</td>\n",
       "      <td>5097</td>\n",
       "      <td>⌯비⌯제⌯이⌯벳⌯ 저에게 이런곳을 알게해줘서 너모고마워요~~</td>\n",
       "      <td>aaltu faaltu</td>\n",
       "      <td>2023-08-03T17:51:58Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>1</td>\n",
       "      <td>워헤이븐 - 공식 트레일러 | 영웅적 플레이를 경험하라!</td>\n",
       "      <td>2023-09-14T07:28:58Z</td>\n",
       "      <td>15</td>\n",
       "      <td>흥해라 워헤이븐!</td>\n",
       "      <td>한선생 유튜브 Gaming HanTeacher</td>\n",
       "      <td>2023-09-14T11:57:35Z</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>1</td>\n",
       "      <td>제2의나라 Cross Worlds OST '끝없는 하늘'</td>\n",
       "      <td>2021-08-11T02:15:07Z</td>\n",
       "      <td>21</td>\n",
       "      <td>히사이시 조 선생님의 ost를 이렇게 피아노 솔로로 들으니 새롭게 들리네요!! 오늘...</td>\n",
       "      <td>공담 ♪</td>\n",
       "      <td>2021-10-06T07:34:27Z</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>1</td>\n",
       "      <td>『126곡』 최신 우타이테 명곡만 모아 넣은 플레이리스트 【노래모음/Playlist】</td>\n",
       "      <td>2023-05-06T09:09:11Z</td>\n",
       "      <td>1072</td>\n",
       "      <td>ㅏ 진짜 띵곡들만 모아놨다..</td>\n",
       "      <td>인간</td>\n",
       "      <td>2023-09-04T06:35:47Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>1</td>\n",
       "      <td>일반전과 재화밸런스 조정! 신규 스킨 업데이트까지 [베일드 엑스퍼트 6월22일 패치노트]</td>\n",
       "      <td>2023-06-22T08:45:16Z</td>\n",
       "      <td>13</td>\n",
       "      <td>ㅠㅠ 일반전 3vs3 모드가 사라진게 아쉬울따름이네요..! 대신 업그레이드 재화가 ...</td>\n",
       "      <td>네카</td>\n",
       "      <td>2023-06-23T04:44:50Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>1</td>\n",
       "      <td>낭만 그 자체, 비키니 아일랜드 깜짝 이벤트 [다시, 여름방학]</td>\n",
       "      <td>2023-07-26T16:32:16Z</td>\n",
       "      <td>274</td>\n",
       "      <td>ㅠㅠ일하고 너무피곤해서 다 스킵하고 봤는데 형 영상보고 같이 울어버림</td>\n",
       "      <td>째엉</td>\n",
       "      <td>2023-07-27T22:57:43Z</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5010 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                           sentence  \\\n",
       "0          0  리니지W 전섭최초 집행검! 330억 투자한 캐릭 소개합니다 (성북동초코파이형님)  ...   \n",
       "1          0                     배그 이후 가장 성공한 한국 FPS (feat. 넥슨)   \n",
       "2          0                 [피파4] 1억부터 4600억까지 몰아보기 feat. 인생강화   \n",
       "3          0                              패치 후 피파를 떠납니다!... 피파4   \n",
       "4          0                아니; 떡락도 이런 떡락이 없는 로스트아크 글로벌 서버 근황;;   \n",
       "...      ...                                                ...   \n",
       "5005       1                    워헤이븐 - 공식 트레일러 | 영웅적 플레이를 경험하라!   \n",
       "5006       1                    제2의나라 Cross Worlds OST '끝없는 하늘'   \n",
       "5007       1    『126곡』 최신 우타이테 명곡만 모아 넣은 플레이리스트 【노래모음/Playlist】   \n",
       "5008       1  일반전과 재화밸런스 조정! 신규 스킨 업데이트까지 [베일드 엑스퍼트 6월22일 패치노트]   \n",
       "5009       1                낭만 그 자체, 비키니 아일랜드 깜짝 이벤트 [다시, 여름방학]   \n",
       "\n",
       "                       게시일  영상 좋아요 수  \\\n",
       "0     2023-05-05T12:45:55Z      1048   \n",
       "1     2023-11-05T13:39:51Z      2977   \n",
       "2     2022-12-06T09:11:47Z      4052   \n",
       "3     2023-06-27T08:30:00Z       106   \n",
       "4     2023-06-11T12:00:39Z      5097   \n",
       "...                    ...       ...   \n",
       "5005  2023-09-14T07:28:58Z        15   \n",
       "5006  2021-08-11T02:15:07Z        21   \n",
       "5007  2023-05-06T09:09:11Z      1072   \n",
       "5008  2023-06-22T08:45:16Z        13   \n",
       "5009  2023-07-26T16:32:16Z       274   \n",
       "\n",
       "                                           kor_sentence  \\\n",
       "0     🥛롤🥛뱃🥛올한해 가장 잘한인을 한게 아닐까 싶다.. 삶의 질이 달라져 버렸습니다 고...   \n",
       "1                                            원격포맷은 지룡자🕷   \n",
       "2     여캠 롤비제이들 왜케 못하는데 긔엽냐 지는게 꿀인줄알았는데 이기기도 하네 🇨🇬롤🇨🇬뱃🇨🇬   \n",
       "3       현피장인 코뚱잉 바텀을 평정한다 배헤당 일.85 접속해서 확인합시다 ?비?제?이?벳?   \n",
       "4                     ⌯비⌯제⌯이⌯벳⌯ 저에게 이런곳을 알게해줘서 너모고마워요~~   \n",
       "...                                                 ...   \n",
       "5005                                          흥해라 워헤이븐!   \n",
       "5006  히사이시 조 선생님의 ost를 이렇게 피아노 솔로로 들으니 새롭게 들리네요!! 오늘...   \n",
       "5007                                   ㅏ 진짜 띵곡들만 모아놨다..   \n",
       "5008  ㅠㅠ 일반전 3vs3 모드가 사라진게 아쉬울따름이네요..! 대신 업그레이드 재화가 ...   \n",
       "5009             ㅠㅠ일하고 너무피곤해서 다 스킵하고 봤는데 형 영상보고 같이 울어버림   \n",
       "\n",
       "                                작성자                댓글 작성일  댓글 좋아요 수  \n",
       "0                          1M CYRUS  2023-11-06T17:52:52Z         0  \n",
       "1                               JAY  2023-11-10T10:39:24Z         0  \n",
       "2                      Neardie Born  2023-10-21T11:15:42Z         0  \n",
       "3      the dale lee lowe jr family   2023-07-24T10:26:22Z         0  \n",
       "4                      aaltu faaltu  2023-08-03T17:51:58Z         0  \n",
       "...                             ...                   ...       ...  \n",
       "5005      한선생 유튜브 Gaming HanTeacher  2023-09-14T11:57:35Z         1  \n",
       "5006                           공담 ♪  2021-10-06T07:34:27Z         3  \n",
       "5007                             인간  2023-09-04T06:35:47Z         0  \n",
       "5008                             네카  2023-06-23T04:44:50Z         0  \n",
       "5009                             째엉  2023-07-27T22:57:43Z         2  \n",
       "\n",
       "[5010 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe38bc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>sentence</th>\n",
       "      <th>게시일</th>\n",
       "      <th>영상 좋아요 수</th>\n",
       "      <th>kor_sentence</th>\n",
       "      <th>작성자</th>\n",
       "      <th>댓글 작성일</th>\n",
       "      <th>댓글 좋아요 수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>리니지W 전섭최초 집행검! 330억 투자한 캐릭 소개합니다 (성북동초코파이형님)  ...</td>\n",
       "      <td>2023-05-05T12:45:55Z</td>\n",
       "      <td>1048</td>\n",
       "      <td>🥛롤🥛뱃🥛올한해 가장 잘한인을 한게 아닐까 싶다.. 삶의 질이 달라져 버렸습니다 고...</td>\n",
       "      <td>1M CYRUS</td>\n",
       "      <td>2023-11-06T17:52:52Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>배그 이후 가장 성공한 한국 FPS (feat. 넥슨)</td>\n",
       "      <td>2023-11-05T13:39:51Z</td>\n",
       "      <td>2977</td>\n",
       "      <td>원격포맷은 지룡자🕷</td>\n",
       "      <td>JAY</td>\n",
       "      <td>2023-11-10T10:39:24Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[피파4] 1억부터 4600억까지 몰아보기 feat. 인생강화</td>\n",
       "      <td>2022-12-06T09:11:47Z</td>\n",
       "      <td>4052</td>\n",
       "      <td>여캠 롤비제이들 왜케 못하는데 긔엽냐 지는게 꿀인줄알았는데 이기기도 하네 🇨🇬롤🇨🇬뱃🇨🇬</td>\n",
       "      <td>Neardie Born</td>\n",
       "      <td>2023-10-21T11:15:42Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>패치 후 피파를 떠납니다!... 피파4</td>\n",
       "      <td>2023-06-27T08:30:00Z</td>\n",
       "      <td>106</td>\n",
       "      <td>현피장인 코뚱잉 바텀을 평정한다 배헤당 일.85 접속해서 확인합시다 ?비?제?이?벳?</td>\n",
       "      <td>the dale lee lowe jr family</td>\n",
       "      <td>2023-07-24T10:26:22Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>아니; 떡락도 이런 떡락이 없는 로스트아크 글로벌 서버 근황;;</td>\n",
       "      <td>2023-06-11T12:00:39Z</td>\n",
       "      <td>5097</td>\n",
       "      <td>⌯비⌯제⌯이⌯벳⌯ 저에게 이런곳을 알게해줘서 너모고마워요~~</td>\n",
       "      <td>aaltu faaltu</td>\n",
       "      <td>2023-08-03T17:51:58Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                           sentence  \\\n",
       "0       0  리니지W 전섭최초 집행검! 330억 투자한 캐릭 소개합니다 (성북동초코파이형님)  ...   \n",
       "1       0                     배그 이후 가장 성공한 한국 FPS (feat. 넥슨)   \n",
       "2       0                 [피파4] 1억부터 4600억까지 몰아보기 feat. 인생강화   \n",
       "3       0                              패치 후 피파를 떠납니다!... 피파4   \n",
       "4       0                아니; 떡락도 이런 떡락이 없는 로스트아크 글로벌 서버 근황;;   \n",
       "\n",
       "                    게시일  영상 좋아요 수  \\\n",
       "0  2023-05-05T12:45:55Z      1048   \n",
       "1  2023-11-05T13:39:51Z      2977   \n",
       "2  2022-12-06T09:11:47Z      4052   \n",
       "3  2023-06-27T08:30:00Z       106   \n",
       "4  2023-06-11T12:00:39Z      5097   \n",
       "\n",
       "                                        kor_sentence  \\\n",
       "0  🥛롤🥛뱃🥛올한해 가장 잘한인을 한게 아닐까 싶다.. 삶의 질이 달라져 버렸습니다 고...   \n",
       "1                                         원격포맷은 지룡자🕷   \n",
       "2  여캠 롤비제이들 왜케 못하는데 긔엽냐 지는게 꿀인줄알았는데 이기기도 하네 🇨🇬롤🇨🇬뱃🇨🇬   \n",
       "3    현피장인 코뚱잉 바텀을 평정한다 배헤당 일.85 접속해서 확인합시다 ?비?제?이?벳?   \n",
       "4                  ⌯비⌯제⌯이⌯벳⌯ 저에게 이런곳을 알게해줘서 너모고마워요~~   \n",
       "\n",
       "                             작성자                댓글 작성일  댓글 좋아요 수  \n",
       "0                       1M CYRUS  2023-11-06T17:52:52Z         0  \n",
       "1                            JAY  2023-11-10T10:39:24Z         0  \n",
       "2                   Neardie Born  2023-10-21T11:15:42Z         0  \n",
       "3   the dale lee lowe jr family   2023-07-24T10:26:22Z         0  \n",
       "4                   aaltu faaltu  2023-08-03T17:51:58Z         0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09fdc038",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['sentence', '게시일', '영상 좋아요 수', '작성자', '댓글 작성일', '댓글 좋아요 수'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d44878ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>kor_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>🥛롤🥛뱃🥛올한해 가장 잘한인을 한게 아닐까 싶다.. 삶의 질이 달라져 버렸습니다 고...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>원격포맷은 지룡자🕷</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>여캠 롤비제이들 왜케 못하는데 긔엽냐 지는게 꿀인줄알았는데 이기기도 하네 🇨🇬롤🇨🇬뱃🇨🇬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>현피장인 코뚱잉 바텀을 평정한다 배헤당 일.85 접속해서 확인합시다 ?비?제?이?벳?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>⌯비⌯제⌯이⌯벳⌯ 저에게 이런곳을 알게해줘서 너모고마워요~~</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                       kor_sentence\n",
       "0       0  🥛롤🥛뱃🥛올한해 가장 잘한인을 한게 아닐까 싶다.. 삶의 질이 달라져 버렸습니다 고...\n",
       "1       0                                         원격포맷은 지룡자🕷\n",
       "2       0  여캠 롤비제이들 왜케 못하는데 긔엽냐 지는게 꿀인줄알았는데 이기기도 하네 🇨🇬롤🇨🇬뱃🇨🇬\n",
       "3       0    현피장인 코뚱잉 바텀을 평정한다 배헤당 일.85 접속해서 확인합시다 ?비?제?이?벳?\n",
       "4       0                  ⌯비⌯제⌯이⌯벳⌯ 저에게 이런곳을 알게해줘서 너모고마워요~~"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b251528a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측값 여부 : False\n"
     ]
    }
   ],
   "source": [
    "print('결측값 여부 :',data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5003489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kor_sentence 열의 유니크한 값 : 4845\n"
     ]
    }
   ],
   "source": [
    "print('kor_sentence 열의 유니크한 값 :',data['kor_sentence'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7319ade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3a85442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측값 여부 : False\n"
     ]
    }
   ],
   "source": [
    "print('결측값 여부 :',data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2f5f6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kor_sentence 열의 유니크한 값 : 4845\n"
     ]
    }
   ],
   "source": [
    "print('kor_sentence 열의 유니크한 값 :',data['kor_sentence'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f7e5a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복된 행을 보는 코드\n",
    "duplicate = data[data.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f5e984f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>kor_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0</td>\n",
       "      <td>부랴부랴 출근준비 하고 바쁘다고 할때 난 🧿롤🧿뱃🧿 떄문에 집에서 느긋하게 늦잠자면...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0</td>\n",
       "      <td>슈퍼꾸랙 이상호리 정글 플레이서 꾸르르르잼 뱃하면서 구경해요 이상호 패가 정🧍‍♀️...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0</td>\n",
       "      <td>🍽️롤🍽️뱃🍽️옷장에 후질근한 옷 이며 신발이며 다갓다 버리고 썌걸로 쫙 갈아 엎자...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0</td>\n",
       "      <td>근데 하나같이 디자인 왤케 쉰내남? (메구우사 클래식, 프리미엄 제외) 틀딱겜 냄새...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>0</td>\n",
       "      <td>⌯비⌯제⌯이⌯벳⌯ 저에게 이런곳을 알게해줘서 너모고마워요~~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>1</td>\n",
       "      <td>흥해라 워헤이븐!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>1</td>\n",
       "      <td>히사이시 조 선생님의 ost를 이렇게 피아노 솔로로 들으니 새롭게 들리네요!! 오늘...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>1</td>\n",
       "      <td>ㅏ 진짜 띵곡들만 모아놨다..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>1</td>\n",
       "      <td>ㅠㅠ 일반전 3vs3 모드가 사라진게 아쉬울따름이네요..! 대신 업그레이드 재화가 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>1</td>\n",
       "      <td>ㅠㅠ일하고 너무피곤해서 다 스킵하고 봤는데 형 영상보고 같이 울어버림</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                       kor_sentence\n",
       "197        0  부랴부랴 출근준비 하고 바쁘다고 할때 난 🧿롤🧿뱃🧿 떄문에 집에서 느긋하게 늦잠자면...\n",
       "204        0  슈퍼꾸랙 이상호리 정글 플레이서 꾸르르르잼 뱃하면서 구경해요 이상호 패가 정🧍‍♀️...\n",
       "216        0  🍽️롤🍽️뱃🍽️옷장에 후질근한 옷 이며 신발이며 다갓다 버리고 썌걸로 쫙 갈아 엎자...\n",
       "494        0  근데 하나같이 디자인 왤케 쉰내남? (메구우사 클래식, 프리미엄 제외) 틀딱겜 냄새...\n",
       "570        0                  ⌯비⌯제⌯이⌯벳⌯ 저에게 이런곳을 알게해줘서 너모고마워요~~\n",
       "...      ...                                                ...\n",
       "5005       1                                          흥해라 워헤이븐!\n",
       "5006       1  히사이시 조 선생님의 ost를 이렇게 피아노 솔로로 들으니 새롭게 들리네요!! 오늘...\n",
       "5007       1                                   ㅏ 진짜 띵곡들만 모아놨다..\n",
       "5008       1  ㅠㅠ 일반전 3vs3 모드가 사라진게 아쉬울따름이네요..! 대신 업그레이드 재화가 ...\n",
       "5009       1             ㅠㅠ일하고 너무피곤해서 다 스킵하고 봤는데 형 영상보고 같이 울어버림\n",
       "\n",
       "[90 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64dc86a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 수 : 4845\n"
     ]
    }
   ],
   "source": [
    "# 중복 제거\n",
    "data.drop_duplicates(subset=['kor_sentence'], inplace=True)\n",
    "print('총 샘플의 수 :',len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6a092d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['labels'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0d9cfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1620\n",
       "0    1618\n",
       "2    1607\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec598fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#추가\n",
    "blank_rows = data['labels'].astype(str).str.strip() == ''\n",
    "#기존\n",
    "data = data[~blank_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7878189c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1620\n",
       "0    1618\n",
       "2    1607\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "802c1005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAGYCAYAAACzlLNPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmf0lEQVR4nO3df1Dc9Z3H8dfKAkkYWAMMu+64UZxhUipctOghNDZkSCBUpJrr0R6WelcuxokmhwGjTK536ExB0zZwBzXGXEZiMKaduZKLZw8Dd4py5CeRtqS55LyiIZUN9g6XEOmCsPdHx+90wURJF+EDz8fMd8b9ft/fnc+2X5tnv+w32AKBQEAAAACGuWamFwAAAHA1iBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARrLP9AKmy/j4uN577z1FR0fLZrPN9HIAAMBnEAgEdPHiRbndbl1zzZXvtczZiHnvvffk8XhmehkAAOAq9Pb26vrrr7/izJyNmOjoaEm//w8hJiZmhlcDAAA+i8HBQXk8HuvP8SuZsxHz8Y+QYmJiiBgAAAzzWb4Kwhd7AQCAkYgYAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJPtUT3jjjTf0/e9/X52dnerr61NTU5PuueeeoJnTp0/rscceU1tbm8bHx3XzzTfrJz/5iZYsWSJJ8vv9Ki8v10svvaTh4WFlZ2frmWee0fXXX2+9x8DAgDZt2qSDBw9KkgoKClRXV6drr7326j/tLHXj46/M9BLmhHeeumumlwAA+BxNOWIuXbqkZcuW6a/+6q/0Z3/2Z5OO/8///I+WL1+ukpISPfHEE3I4HDp9+rQWLFhgzZSWlurll1/W/v37FRcXp7KyMuXn56uzs1NhYWGSpKKiIp0/f17Nzc2SpAceeEDFxcV6+eWXr/azAviMCOvQIa6B6TPliMnLy1NeXt5lj2/dulVf/epXtW3bNmvfTTfdZP2zz+fT7t27tXfvXq1atUqS1NjYKI/Ho9bWVuXm5ur06dNqbm7WkSNHlJ6eLknatWuXMjIydObMGS1dunSqywYAAHPMlCPmSsbHx/XKK69oy5Ytys3N1VtvvaXExERVVFRYP3Lq7OzU6OiocnJyrPPcbrdSUlLU0dGh3NxcHT58WA6HwwoYSbrjjjvkcDjU0dFBxADAPMPdwdCZS3cHQ/rF3v7+fg0NDempp57SmjVrdOjQId17771au3at2traJEler1cRERFavHhx0LlOp1Ner9eaSUhImPT+CQkJ1sxEfr9fg4ODQRsAAJi7Qn4nRpK+9rWv6ZFHHpEk3XLLLero6NCzzz6rFStWXPbcQCAgm81mvf7Df77czB+qrq7WE0888ccsHwAAGCSkd2Li4+Nlt9v1xS9+MWh/cnKyzp07J0lyuVwaGRnRwMBA0Ex/f7+cTqc1c+HChUnv//7771szE1VUVMjn81lbb29vKD4SAACYpUIaMREREbr99tt15syZoP1nz57VDTfcIElKS0tTeHi4WlparON9fX3q7u5WZmamJCkjI0M+n0/Hjh2zZo4ePSqfz2fNTBQZGamYmJigDQAAzF1T/nHS0NCQ3n77bet1T0+Purq6FBsbqyVLlujRRx/VN77xDX3lK1/RypUr1dzcrJdfflmvv/66JMnhcKikpERlZWWKi4tTbGysysvLlZqaaj2tlJycrDVr1mjdunXauXOnpN8/Yp2fn8+XegEAgKSriJgTJ05o5cqV1uvNmzdLku6//341NDTo3nvv1bPPPqvq6mpt2rRJS5cu1T//8z9r+fLl1jk1NTWy2+0qLCy0/rK7hoYG6++IkaQXX3xRmzZtsp5iKigoUH19/VV/UAAAMLfYAoFAYKYXMR0GBwflcDjk8/lm/Y+WeHQwNObSY4MzjWsydLguQ4NrMnRm+zU5lT+/+d1JAADASEQMAAAwEhEDAACMRMQAAAAjETEAAMBIRAwAADASEQMAAIxExAAAACMRMQAAwEhEDAAAMBIRAwAAjETEAAAAIxExAADASEQMAAAwEhEDAACMRMQAAAAjETEAAMBIRAwAADASEQMAAIxExAAAACMRMQAAwEhEDAAAMBIRAwAAjETEAAAAIxExAADASEQMAAAwEhEDAACMRMQAAAAjETEAAMBIRAwAADASEQMAAIxExAAAACMRMQAAwEhTjpg33nhDd999t9xut2w2mw4cOHDZ2fXr18tms6m2tjZov9/v18aNGxUfH6+oqCgVFBTo/PnzQTMDAwMqLi6Ww+GQw+FQcXGxPvjgg6kuFwAAzFFTjphLly5p2bJlqq+vv+LcgQMHdPToUbnd7knHSktL1dTUpP3796u9vV1DQ0PKz8/X2NiYNVNUVKSuri41NzerublZXV1dKi4unupyAQDAHGWf6gl5eXnKy8u74sxvfvMbPfzww3r11Vd11113BR3z+XzavXu39u7dq1WrVkmSGhsb5fF41NraqtzcXJ0+fVrNzc06cuSI0tPTJUm7du1SRkaGzpw5o6VLl0512QAAYI4J+XdixsfHVVxcrEcffVQ333zzpOOdnZ0aHR1VTk6Otc/tdislJUUdHR2SpMOHD8vhcFgBI0l33HGHHA6HNTOR3+/X4OBg0AYAAOaukEfM008/Lbvdrk2bNn3ica/Xq4iICC1evDhov9PplNfrtWYSEhImnZuQkGDNTFRdXW19f8bhcMjj8fyRnwQAAMxmIY2Yzs5O/cM//IMaGhpks9mmdG4gEAg655POnzjzhyoqKuTz+aytt7d3aosHAABGCWnEvPnmm+rv79eSJUtkt9tlt9v17rvvqqysTDfeeKMkyeVyaWRkRAMDA0Hn9vf3y+l0WjMXLlyY9P7vv/++NTNRZGSkYmJigjYAADB3hTRiiouL9Ytf/EJdXV3W5na79eijj+rVV1+VJKWlpSk8PFwtLS3WeX19feru7lZmZqYkKSMjQz6fT8eOHbNmjh49Kp/PZ80AAID5bcpPJw0NDentt9+2Xvf09Kirq0uxsbFasmSJ4uLigubDw8PlcrmsJ4ocDodKSkpUVlamuLg4xcbGqry8XKmpqdbTSsnJyVqzZo3WrVunnTt3SpIeeOAB5efn82QSAACQdBURc+LECa1cudJ6vXnzZknS/fffr4aGhs/0HjU1NbLb7SosLNTw8LCys7PV0NCgsLAwa+bFF1/Upk2brKeYCgoKPvXvpgEAAPPHlCMmKytLgUDgM8+/8847k/YtWLBAdXV1qquru+x5sbGxamxsnOryAADAPMHvTgIAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJCIGAAAYacoR88Ybb+juu++W2+2WzWbTgQMHrGOjo6N67LHHlJqaqqioKLndbn3729/We++9F/Qefr9fGzduVHx8vKKiolRQUKDz588HzQwMDKi4uFgOh0MOh0PFxcX64IMPrupDAgCAuWfKEXPp0iUtW7ZM9fX1k459+OGHOnnypL773e/q5MmT+ulPf6qzZ8+qoKAgaK60tFRNTU3av3+/2tvbNTQ0pPz8fI2NjVkzRUVF6urqUnNzs5qbm9XV1aXi4uKr+IgAAGAusk/1hLy8POXl5X3iMYfDoZaWlqB9dXV1+tM//VOdO3dOS5Yskc/n0+7du7V3716tWrVKktTY2CiPx6PW1lbl5ubq9OnTam5u1pEjR5Seni5J2rVrlzIyMnTmzBktXbp0qssGAABzzLR/J8bn88lms+naa6+VJHV2dmp0dFQ5OTnWjNvtVkpKijo6OiRJhw8flsPhsAJGku644w45HA5rBgAAzG9TvhMzFb/73e/0+OOPq6ioSDExMZIkr9eriIgILV68OGjW6XTK6/VaMwkJCZPeLyEhwZqZyO/3y+/3W68HBwdD9TEAAMAsNG13YkZHR/XNb35T4+PjeuaZZz51PhAIyGazWa//8J8vN/OHqqurrS8BOxwOeTyeq188AACY9aYlYkZHR1VYWKienh61tLRYd2EkyeVyaWRkRAMDA0Hn9Pf3y+l0WjMXLlyY9L7vv/++NTNRRUWFfD6ftfX29obwEwEAgNkm5BHzccD893//t1pbWxUXFxd0PC0tTeHh4UFfAO7r61N3d7cyMzMlSRkZGfL5fDp27Jg1c/ToUfl8PmtmosjISMXExARtAABg7pryd2KGhob09ttvW697enrU1dWl2NhYud1uff3rX9fJkyf1r//6rxobG7O+wxIbG6uIiAg5HA6VlJSorKxMcXFxio2NVXl5uVJTU62nlZKTk7VmzRqtW7dOO3fulCQ98MADys/P58kkAAAg6Soi5sSJE1q5cqX1evPmzZKk+++/X5WVlTp48KAk6ZZbbgk677XXXlNWVpYkqaamRna7XYWFhRoeHlZ2drYaGhoUFhZmzb/44ovatGmT9RRTQUHBJ/7dNAAAYH6acsRkZWUpEAhc9viVjn1swYIFqqurU11d3WVnYmNj1djYONXlAQCAeYLfnQQAAIxExAAAACMRMQAAwEhEDAAAMBIRAwAAjETEAAAAIxExAADASEQMAAAwEhEDAACMRMQAAAAjETEAAMBIRAwAADASEQMAAIxExAAAACMRMQAAwEhEDAAAMBIRAwAAjETEAAAAIxExAADASEQMAAAwEhEDAACMRMQAAAAjETEAAMBIRAwAADASEQMAAIxExAAAACMRMQAAwEhEDAAAMBIRAwAAjETEAAAAIxExAADASEQMAAAwEhEDAACMNOWIeeONN3T33XfL7XbLZrPpwIEDQccDgYAqKyvldru1cOFCZWVl6dSpU0Ezfr9fGzduVHx8vKKiolRQUKDz588HzQwMDKi4uFgOh0MOh0PFxcX64IMPpvwBAQDA3DTliLl06ZKWLVum+vr6Tzy+bds2bd++XfX19Tp+/LhcLpdWr16tixcvWjOlpaVqamrS/v371d7erqGhIeXn52tsbMyaKSoqUldXl5qbm9Xc3Kyuri4VFxdfxUcEAABzkX2qJ+Tl5SkvL+8TjwUCAdXW1mrr1q1au3atJGnPnj1yOp3at2+f1q9fL5/Pp927d2vv3r1atWqVJKmxsVEej0etra3Kzc3V6dOn1dzcrCNHjig9PV2StGvXLmVkZOjMmTNaunTp1X5eAAAwR4T0OzE9PT3yer3Kycmx9kVGRmrFihXq6OiQJHV2dmp0dDRoxu12KyUlxZo5fPiwHA6HFTCSdMcdd8jhcFgzE/n9fg0ODgZtAABg7gppxHi9XkmS0+kM2u90Oq1jXq9XERERWrx48RVnEhISJr1/QkKCNTNRdXW19f0Zh8Mhj8fzR38eAAAwe03L00k2my3odSAQmLRvookznzR/pfepqKiQz+eztt7e3qtYOQAAMEVII8blcknSpLsl/f391t0Zl8ulkZERDQwMXHHmwoULk97//fffn3SX52ORkZGKiYkJ2gAAwNwV0ohJTEyUy+VSS0uLtW9kZERtbW3KzMyUJKWlpSk8PDxopq+vT93d3dZMRkaGfD6fjh07Zs0cPXpUPp/PmgEAAPPblJ9OGhoa0ttvv2297unpUVdXl2JjY7VkyRKVlpaqqqpKSUlJSkpKUlVVlRYtWqSioiJJksPhUElJicrKyhQXF6fY2FiVl5crNTXVelopOTlZa9as0bp167Rz505J0gMPPKD8/HyeTAIAAJKuImJOnDihlStXWq83b94sSbr//vvV0NCgLVu2aHh4WBs2bNDAwIDS09N16NAhRUdHW+fU1NTIbrersLBQw8PDys7OVkNDg8LCwqyZF198UZs2bbKeYiooKLjs300DAADmH1sgEAjM9CKmw+DgoBwOh3w+36z/fsyNj78y00uYE9556q6ZXsKcwTUZOlyXocE1GTqz/Zqcyp/f/O4kAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJFCHjEfffSR/vZv/1aJiYlauHChbrrpJj355JMaHx+3ZgKBgCorK+V2u7Vw4UJlZWXp1KlTQe/j9/u1ceNGxcfHKyoqSgUFBTp//nyolwsAAAwV8oh5+umn9eyzz6q+vl6nT5/Wtm3b9P3vf191dXXWzLZt27R9+3bV19fr+PHjcrlcWr16tS5evGjNlJaWqqmpSfv371d7e7uGhoaUn5+vsbGxUC8ZAAAYyB7qNzx8+LC+9rWv6a677pIk3XjjjXrppZd04sQJSb+/C1NbW6utW7dq7dq1kqQ9e/bI6XRq3759Wr9+vXw+n3bv3q29e/dq1apVkqTGxkZ5PB61trYqNzc31MsGAACGCfmdmOXLl+vf//3fdfbsWUnSz3/+c7W3t+urX/2qJKmnp0der1c5OTnWOZGRkVqxYoU6OjokSZ2dnRodHQ2acbvdSklJsWYAAMD8FvI7MY899ph8Pp++8IUvKCwsTGNjY/re976nv/iLv5Akeb1eSZLT6Qw6z+l06t1337VmIiIitHjx4kkzH58/kd/vl9/vt14PDg6G7DMBAIDZJ+R3Yn784x+rsbFR+/bt08mTJ7Vnzx794Ac/0J49e4LmbDZb0OtAIDBp30RXmqmurpbD4bA2j8fzx30QAAAwq4U8Yh599FE9/vjj+uY3v6nU1FQVFxfrkUceUXV1tSTJ5XJJ0qQ7Kv39/dbdGZfLpZGREQ0MDFx2ZqKKigr5fD5r6+3tDfVHAwAAs0jII+bDDz/UNdcEv21YWJj1iHViYqJcLpdaWlqs4yMjI2pra1NmZqYkKS0tTeHh4UEzfX196u7utmYmioyMVExMTNAGAADmrpB/J+buu+/W9773PS1ZskQ333yz3nrrLW3fvl3f+c53JP3+x0ilpaWqqqpSUlKSkpKSVFVVpUWLFqmoqEiS5HA4VFJSorKyMsXFxSk2Nlbl5eVKTU21nlYCAADzW8gjpq6uTt/97ne1YcMG9ff3y+12a/369fq7v/s7a2bLli0aHh7Whg0bNDAwoPT0dB06dEjR0dHWTE1Njex2uwoLCzU8PKzs7Gw1NDQoLCws1EsGAAAGsgUCgcBML2I6DA4OyuFwyOfzzfofLd34+CszvYQ54Z2n7prpJcwZXJOhw3UZGlyToTPbr8mp/PnN704CAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARpqWiPnNb36jb33rW4qLi9OiRYt0yy23qLOz0zoeCARUWVkpt9uthQsXKisrS6dOnQp6D7/fr40bNyo+Pl5RUVEqKCjQ+fPnp2O5AADAQCGPmIGBAX35y19WeHi4/u3f/k2/+tWv9MMf/lDXXnutNbNt2zZt375d9fX1On78uFwul1avXq2LFy9aM6WlpWpqatL+/fvV3t6uoaEh5efna2xsLNRLBgAABrKH+g2ffvppeTwePf/889a+G2+80frnQCCg2tpabd26VWvXrpUk7dmzR06nU/v27dP69evl8/m0e/du7d27V6tWrZIkNTY2yuPxqLW1Vbm5uaFeNgAAMEzI78QcPHhQt912m/78z/9cCQkJuvXWW7Vr1y7reE9Pj7xer3Jycqx9kZGRWrFihTo6OiRJnZ2dGh0dDZpxu91KSUmxZiby+/0aHBwM2gAAwNwV8oj59a9/rR07digpKUmvvvqqHnzwQW3atEkvvPCCJMnr9UqSnE5n0HlOp9M65vV6FRERocWLF192ZqLq6mo5HA5r83g8of5oAABgFgl5xIyPj+tLX/qSqqqqdOutt2r9+vVat26dduzYETRns9mCXgcCgUn7JrrSTEVFhXw+n7X19vb+cR8EAADMaiGPmOuuu05f/OIXg/YlJyfr3LlzkiSXyyVJk+6o9Pf3W3dnXC6XRkZGNDAwcNmZiSIjIxUTExO0AQCAuSvkEfPlL39ZZ86cCdp39uxZ3XDDDZKkxMREuVwutbS0WMdHRkbU1tamzMxMSVJaWprCw8ODZvr6+tTd3W3NAACA+S3kTyc98sgjyszMVFVVlQoLC3Xs2DE999xzeu655yT9/sdIpaWlqqqqUlJSkpKSklRVVaVFixapqKhIkuRwOFRSUqKysjLFxcUpNjZW5eXlSk1NtZ5WAgAA81vII+b2229XU1OTKioq9OSTTyoxMVG1tbW67777rJktW7ZoeHhYGzZs0MDAgNLT03Xo0CFFR0dbMzU1NbLb7SosLNTw8LCys7PV0NCgsLCwUC8ZAAAYyBYIBAIzvYjpMDg4KIfDIZ/PN+u/H3Pj46/M9BLmhHeeumumlzBncE2GDtdlaHBNhs5svyan8uc3vzsJAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYKRpj5jq6mrZbDaVlpZa+wKBgCorK+V2u7Vw4UJlZWXp1KlTQef5/X5t3LhR8fHxioqKUkFBgc6fPz/dywUAAIaY1og5fvy4nnvuOf3Jn/xJ0P5t27Zp+/btqq+v1/Hjx+VyubR69WpdvHjRmiktLVVTU5P279+v9vZ2DQ0NKT8/X2NjY9O5ZAAAYIhpi5ihoSHdd9992rVrlxYvXmztDwQCqq2t1datW7V27VqlpKRoz549+vDDD7Vv3z5Jks/n0+7du/XDH/5Qq1at0q233qrGxkb98pe/VGtr63QtGQAAGGTaIuahhx7SXXfdpVWrVgXt7+npkdfrVU5OjrUvMjJSK1asUEdHhySps7NTo6OjQTNut1spKSnWzER+v1+Dg4NBGwAAmLvs0/Gm+/fv18mTJ3X8+PFJx7xeryTJ6XQG7Xc6nXr33XetmYiIiKA7OB/PfHz+RNXV1XriiSdCsXwAAGCAkN+J6e3t1d/8zd+osbFRCxYsuOyczWYLeh0IBCbtm+hKMxUVFfL5fNbW29s79cUDAABjhDxiOjs71d/fr7S0NNntdtntdrW1tekf//EfZbfbrTswE++o9Pf3W8dcLpdGRkY0MDBw2ZmJIiMjFRMTE7QBAIC5K+QRk52drV/+8pfq6uqytttuu0333Xefurq6dNNNN8nlcqmlpcU6Z2RkRG1tbcrMzJQkpaWlKTw8PGimr69P3d3d1gwAAJjfQv6dmOjoaKWkpATti4qKUlxcnLW/tLRUVVVVSkpKUlJSkqqqqrRo0SIVFRVJkhwOh0pKSlRWVqa4uDjFxsaqvLxcqampk74oDAAA5qdp+WLvp9myZYuGh4e1YcMGDQwMKD09XYcOHVJ0dLQ1U1NTI7vdrsLCQg0PDys7O1sNDQ0KCwubiSUDAIBZ5nOJmNdffz3otc1mU2VlpSorKy97zoIFC1RXV6e6urrpXRwAADASvzsJAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGCnkEVNdXa3bb79d0dHRSkhI0D333KMzZ84EzQQCAVVWVsrtdmvhwoXKysrSqVOngmb8fr82btyo+Ph4RUVFqaCgQOfPnw/1cgEAgKFCHjFtbW166KGHdOTIEbW0tOijjz5STk6OLl26ZM1s27ZN27dvV319vY4fPy6Xy6XVq1fr4sWL1kxpaamampq0f/9+tbe3a2hoSPn5+RobGwv1kgEAgIHsoX7D5ubmoNfPP/+8EhIS1NnZqa985SsKBAKqra3V1q1btXbtWknSnj175HQ6tW/fPq1fv14+n0+7d+/W3r17tWrVKklSY2OjPB6PWltblZubG+plAwAAw0z7d2J8Pp8kKTY2VpLU09Mjr9ernJwcayYyMlIrVqxQR0eHJKmzs1Ojo6NBM263WykpKdbMRH6/X4ODg0EbAACYu6Y1YgKBgDZv3qzly5crJSVFkuT1eiVJTqczaNbpdFrHvF6vIiIitHjx4svOTFRdXS2Hw2FtHo8n1B8HAADMItMaMQ8//LB+8Ytf6KWXXpp0zGazBb0OBAKT9k10pZmKigr5fD5r6+3tvfqFAwCAWW/aImbjxo06ePCgXnvtNV1//fXWfpfLJUmT7qj09/dbd2dcLpdGRkY0MDBw2ZmJIiMjFRMTE7QBAIC5K+QREwgE9PDDD+unP/2p/uM//kOJiYlBxxMTE+VyudTS0mLtGxkZUVtbmzIzMyVJaWlpCg8PD5rp6+tTd3e3NQMAAOa3kD+d9NBDD2nfvn36l3/5F0VHR1t3XBwOhxYuXCibzabS0lJVVVUpKSlJSUlJqqqq0qJFi1RUVGTNlpSUqKysTHFxcYqNjVV5eblSU1Otp5UAAMD8FvKI2bFjhyQpKysraP/zzz+vv/zLv5QkbdmyRcPDw9qwYYMGBgaUnp6uQ4cOKTo62pqvqamR3W5XYWGhhoeHlZ2drYaGBoWFhYV6yQAAwEAhj5hAIPCpMzabTZWVlaqsrLzszIIFC1RXV6e6uroQrg4AAMwV/O4kAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJFmfcQ888wzSkxM1IIFC5SWlqY333xzppcEAABmgVkdMT/+8Y9VWlqqrVu36q233tKdd96pvLw8nTt3bqaXBgAAZtisjpjt27erpKREf/3Xf63k5GTV1tbK4/Fox44dM700AAAww+wzvYDLGRkZUWdnpx5//PGg/Tk5Oero6Jg07/f75ff7rdc+n0+SNDg4OL0LDYFx/4czvYQ5wYT/rk3BNRk6XJehwTUZOrP9mvx4fYFA4FNnZ23E/Pa3v9XY2JicTmfQfqfTKa/XO2m+urpaTzzxxKT9Ho9n2taI2cVRO9MrACbjusRsY8o1efHiRTkcjivOzNqI+ZjNZgt6HQgEJu2TpIqKCm3evNl6PT4+rv/7v/9TXFzcJ87jsxscHJTH41Fvb69iYmJmejkA1yRmJa7L0AgEArp48aLcbvenzs7aiImPj1dYWNikuy79/f2T7s5IUmRkpCIjI4P2XXvttdO5xHknJiaGfzExq3BNYjbiuvzjfdodmI/N2i/2RkREKC0tTS0tLUH7W1palJmZOUOrAgAAs8WsvRMjSZs3b1ZxcbFuu+02ZWRk6LnnntO5c+f04IMPzvTSAADADJvVEfONb3xD//u//6snn3xSfX19SklJ0c9+9jPdcMMNM720eSUyMlJ///d/P+nHdcBM4ZrEbMR1+fmzBT7LM0wAAACzzKz9TgwAAMCVEDEAAMBIRAwAADASEQMAAIxExAAAACPN6kesAUCSzp8/rx07dqijo0Ner1c2m01Op1OZmZl68MEH+R1pwDzFnRhMSW9vr77zne/M9DIwj7S3tys5OVlNTU1atmyZvv3tb+tb3/qWli1bpgMHDujmm2/Wf/7nf870MjEPDQ8Pq729Xb/61a8mHfvd736nF154YQZWNb/w98RgSn7+85/rS1/6ksbGxmZ6KZgnbr/9di1fvlw1NTWfePyRRx5Re3u7jh8//jmvDPPZ2bNnlZOTo3Pnzslms+nOO+/USy+9pOuuu06SdOHCBbndbv63cpoRMQhy8ODBKx7/9a9/rbKyMv7FxOdm4cKF6urq0tKlSz/x+H/913/p1ltv1fDw8Oe8Msxn9957rz766CM9//zz+uCDD7R582Z1d3fr9ddf15IlS4iYzwnfiUGQe+65RzabTVdqW5vN9jmuCPPdddddp46OjstGzOHDh63/9wt8Xjo6OtTa2qr4+HjFx8fr4MGDeuihh3TnnXfqtddeU1RU1EwvcV4gYhDkuuuu049+9CPdc889n3i8q6tLaWlpn++iMK+Vl5frwQcfVGdnp1avXi2n0ymbzSav16uWlhb90z/9k2pra2d6mZhnhoeHZbcH/xH6ox/9SNdcc41WrFihffv2zdDK5hciBkHS0tJ08uTJy0bMp92lAUJtw4YNiouLU01NjXbu3Gndng8LC1NaWppeeOEFFRYWzvAqMd984Qtf0IkTJ5ScnBy0v66uToFAQAUFBTO0svmF78QgyJtvvqlLly5pzZo1n3j80qVLOnHihFasWPE5rwyQRkdH9dvf/laSFB8fr/Dw8BleEear6upqvfnmm/rZz372icc3bNigZ599VuPj45/zyuYXIgYAABiJvycGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYKT/B9kGTe9m41heAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['labels'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acae5fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블의 분포\n",
      "   labels  count\n",
      "0       0   1618\n",
      "1       1   1620\n",
      "2       2   1607\n"
     ]
    }
   ],
   "source": [
    "print('레이블의 분포')\n",
    "print(data.groupby('labels').size().reset_index(name='count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f16b7184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정의 비율 = 33.395%\n",
      "중립의 비율 = 33.437%\n",
      "부정의 비율 = 33.168%\n"
     ]
    }
   ],
   "source": [
    "print(f'긍정의 비율 = {round(data[\"labels\"].value_counts()[0]/len(data) * 100,3)}%')\n",
    "print(f'중립의 비율 = {round(data[\"labels\"].value_counts()[1]/len(data) * 100,3)}%')\n",
    "print(f'부정의 비율 = {round(data[\"labels\"].value_counts()[2]/len(data) * 100,3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98e04e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "본문의 개수: 4845\n",
      "레이블의 개수: 4845\n"
     ]
    }
   ],
   "source": [
    "X_data = data['kor_sentence']\n",
    "y_data = data['labels']\n",
    "print('본문의 개수: {}'.format(len(X_data)))\n",
    "print('레이블의 개수: {}'.format(len(y_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8148adbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.20, random_state=0, stratify=y_data)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.25, random_state=0, stratify=y_data)\n",
    "\n",
    "# 데이터 분할 부분 수정\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.2, random_state=0, stratify=y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5d3c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 개수 : 3876\n",
      "테스트 샘플의 개수 : 969\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플의 개수 :', len(X_train))\n",
    "print('테스트 샘플의 개수 :', len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da4fc90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------훈련 데이터의 비율-----------\n",
      "긍정 = 33.385%\n",
      "중립 = 33.437%\n",
      "부정 = 33.179%\n"
     ]
    }
   ],
   "source": [
    "print('--------훈련 데이터의 비율-----------')\n",
    "print(f'긍정 = {round(y_train.value_counts()[0]/len(y_train) * 100,3)}%')\n",
    "print(f'중립 = {round(y_train.value_counts()[1]/len(y_train) * 100,3)}%')\n",
    "print(f'부정 = {round(y_train.value_counts()[2]/len(y_train) * 100,3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b38a24a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------테스트 데이터의 비율-----------\n",
      "긍정 = 33.437%\n",
      "중립 = 33.437%\n",
      "부정 = 33.127%\n"
     ]
    }
   ],
   "source": [
    "print('--------테스트 데이터의 비율-----------')\n",
    "print(f'긍정 = {round(y_val.value_counts()[0]/len(y_val) * 100,3)}%')\n",
    "print(f'중립 = {round(y_val.value_counts()[1]/len(y_val) * 100,3)}%')\n",
    "print(f'부정 = {round(y_val.value_counts()[2]/len(y_val) * 100,3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac1542ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ceac494",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('klue/bert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76cfb74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_examples_to_features 함수 수정\n",
    "def convert_examples_to_features(examples, labels, max_seq_len, tokenizer):\n",
    "    input_ids, attention_masks, token_type_ids, data_labels = [], [], [], []\n",
    "\n",
    "    for example, label in tqdm(zip(examples, labels), total=len(examples)):\n",
    "        # input_id는 워드 임베딩을 위한 문장의 정수 인코딩\n",
    "        input_id = tokenizer.encode(example, max_length=max_seq_len, pad_to_max_length=True)\n",
    "\n",
    "        # attention_mask는 실제 단어가 위치하면 1, 패딩의 위치에는 0인 시퀀스.\n",
    "        padding_count = input_id.count(tokenizer.pad_token_id)\n",
    "        attention_mask = [1] * (max_seq_len - padding_count) + [0] * padding_count\n",
    "\n",
    "        # token_type_id은 세그먼트 인코딩\n",
    "        token_type_id = [0] * max_seq_len\n",
    "\n",
    "        assert len(input_id) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_id), max_seq_len)\n",
    "        assert len(attention_mask) == max_seq_len, \"Error with attention mask length {} vs {}\".format(len(attention_mask), max_seq_len)\n",
    "        assert len(token_type_id) == max_seq_len, \"Error with token type length {} vs {}\".format(len(token_type_id), max_seq_len)\n",
    "\n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        data_labels.append(label)\n",
    "\n",
    "    input_ids = np.array(input_ids, dtype=int)\n",
    "    attention_masks = np.array(attention_masks, dtype=int)\n",
    "    token_type_ids = np.array(token_type_ids, dtype=int)\n",
    "\n",
    "    data_labels = np.asarray(data_labels, dtype=np.int32)\n",
    "\n",
    "    return (input_ids, attention_masks, token_type_ids), data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "150b4fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3876 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/ubuntu/anaconda3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████| 3876/3876 [00:00<00:00, 4047.60it/s]\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y = convert_examples_to_features(X_train, y_train, max_seq_len=max_seq_len, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19e68102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3876/3876 [00:00<00:00, 4124.44it/s]\n",
      "100%|██████████| 969/969 [00:00<00:00, 4139.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# 수정된 데이터를 사용하여 학습 및 검증 데이터 생성\n",
    "train_X, train_y = convert_examples_to_features(X_train, y_train, max_seq_len=max_seq_len, tokenizer=tokenizer)\n",
    "val_X, val_y = convert_examples_to_features(X_val, y_val, max_seq_len=max_seq_len, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c0c55b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어에 대한 정수 인코딩 : [    2 25547  4388     5     3     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "어텐션 마스크 : [1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "세그먼트 인코딩 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "각 인코딩의 길이 : 128\n",
      "정수 인코딩 복원 : [CLS] 최애 노래! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "레이블 : 1\n"
     ]
    }
   ],
   "source": [
    "input_id = train_X[0][0]\n",
    "attention_mask = train_X[1][0]\n",
    "token_type_id = train_X[2][0]\n",
    "label = train_y[0]\n",
    "\n",
    "print('단어에 대한 정수 인코딩 :',input_id)\n",
    "print('어텐션 마스크 :',attention_mask)\n",
    "print('세그먼트 인코딩 :',token_type_id)\n",
    "print('각 인코딩의 길이 :', len(input_id))\n",
    "print('정수 인코딩 복원 :',tokenizer.decode(input_id))\n",
    "print('레이블 :',label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e00db344",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 07:07:05.726201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-17 07:07:05.729924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-17 07:07:05.731941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-17 07:07:05.734665: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-17 07:07:05.735253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA GPU를 사용합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "node zero\n",
      "2023-11-17 07:07:05.737310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-17 07:07:05.739292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-17 07:07:07.911884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-17 07:07:07.913437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-17 07:07:07.914695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-17 07:07:07.915901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13227 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# TPU를 사용할 수 있는지 확인합니다\n",
    "if 'COLAB_TPU_ADDR' in os.environ:\n",
    "    # TPU가 사용 가능한 경우 TPU를 설정합니다\n",
    "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
    "    tf.config.experimental_connect_to_cluster(resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
    "    print('TPU를 사용합니다.')\n",
    "else:\n",
    "    # TPU가 사용 불가능한 경우 CUDA GPU를 사용합니다\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    if len(physical_devices) == 0:\n",
    "        raise RuntimeError(\"GPU를 찾을 수 없습니다. TensorFlow가 올바르게 설치되어 있는지 확인하세요.\")\n",
    "\n",
    "    # 모든 GPU 메모리를 필요에 따라 동적으로 할당하도록 설정합니다\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "    # CUDA GPU를 사용하는 경우 문자열 \"/gpu:0\"을 전달합니다\n",
    "    strategy = tf.distribute.OneDeviceStrategy(\"/gpu:0\")\n",
    "    print('CUDA GPU를 사용합니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f30d4f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "  model = TFBertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=3, from_pt=True)\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "  model.compile(optimizer=optimizer, loss=loss, metrics = ['accuracy'])\n",
    "#   model.compile(optimizer=optimizer, loss=model.compute_loss, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b93d4c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFBertForSequenceClassification\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28cc5bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef5e9889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 07:07:09.823169: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_4465\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020FlatMapDataset:4\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - ETA: 0s - loss: 1.4732 - accuracy: 0.3480"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 07:08:50.639634: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_24624\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\021FlatMapDataset:27\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.37564, saving model to GPT4_분류모델(02).h5\n",
      "122/122 [==============================] - 113s 792ms/step - loss: 1.4732 - accuracy: 0.3480 - val_loss: 1.0975 - val_accuracy: 0.3756\n",
      "Epoch 2/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.1008 - accuracy: 0.3555\n",
      "Epoch 2: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 760ms/step - loss: 1.1008 - accuracy: 0.3555 - val_loss: 1.0986 - val_accuracy: 0.3571\n",
      "Epoch 3/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3393\n",
      "Epoch 3: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3393 - val_loss: 1.0986 - val_accuracy: 0.3571\n",
      "Epoch 4/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0983 - accuracy: 0.3333\n",
      "Epoch 4: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0983 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3571\n",
      "Epoch 5/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3506\n",
      "Epoch 5: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3506 - val_loss: 1.0986 - val_accuracy: 0.3571\n",
      "Epoch 6/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3449\n",
      "Epoch 6: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3449 - val_loss: 1.0986 - val_accuracy: 0.3571\n",
      "Epoch 7/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.1012 - accuracy: 0.3375\n",
      "Epoch 7: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.1012 - accuracy: 0.3375 - val_loss: 1.0986 - val_accuracy: 0.3509\n",
      "Epoch 8/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3333\n",
      "Epoch 8: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3509\n",
      "Epoch 9/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3349\n",
      "Epoch 9: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3349 - val_loss: 1.0986 - val_accuracy: 0.3509\n",
      "Epoch 10/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0983 - accuracy: 0.3261\n",
      "Epoch 10: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0983 - accuracy: 0.3261 - val_loss: 1.0986 - val_accuracy: 0.3509\n",
      "Epoch 11/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3331\n",
      "Epoch 11: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3331 - val_loss: 1.0986 - val_accuracy: 0.3509\n",
      "Epoch 12/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3398\n",
      "Epoch 12: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3398 - val_loss: 1.0986 - val_accuracy: 0.3509\n",
      "Epoch 13/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3364\n",
      "Epoch 13: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3364 - val_loss: 1.0986 - val_accuracy: 0.3509\n",
      "Epoch 14/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3341\n",
      "Epoch 14: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3341 - val_loss: 1.0986 - val_accuracy: 0.3509\n",
      "Epoch 15/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3271\n",
      "Epoch 15: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 763ms/step - loss: 1.0986 - accuracy: 0.3271 - val_loss: 1.0986 - val_accuracy: 0.3509\n",
      "Epoch 16/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3354\n",
      "Epoch 16: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3354 - val_loss: 1.0986 - val_accuracy: 0.3509\n",
      "Epoch 17/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3277\n",
      "Epoch 17: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3277 - val_loss: 1.0986 - val_accuracy: 0.3509\n",
      "Epoch 18/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0983 - accuracy: 0.3328\n",
      "Epoch 18: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0983 - accuracy: 0.3328 - val_loss: 1.0986 - val_accuracy: 0.3509\n",
      "Epoch 19/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.1018 - accuracy: 0.3344\n",
      "Epoch 19: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.1018 - accuracy: 0.3344 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 20/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3359\n",
      "Epoch 20: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3359 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 21/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3323\n",
      "Epoch 21: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3323 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 22/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3354\n",
      "Epoch 22: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3354 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 23/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3313\n",
      "Epoch 23: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3313 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 24/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3328\n",
      "Epoch 24: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3328 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 25/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3377\n",
      "Epoch 25: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3377 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 26/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3364\n",
      "Epoch 26: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3364 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 27/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3284\n",
      "Epoch 27: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3284 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 28/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3297\n",
      "Epoch 28: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 761ms/step - loss: 1.0986 - accuracy: 0.3297 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 29/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3331\n",
      "Epoch 29: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3331 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 30/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3367\n",
      "Epoch 30: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3367 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 31/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3398\n",
      "Epoch 31: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3398 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 32/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3302\n",
      "Epoch 32: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3302 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 33/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3300\n",
      "Epoch 33: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3300 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 34/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3367\n",
      "Epoch 34: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3367 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 35/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3289\n",
      "Epoch 35: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3289 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 36/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3349\n",
      "Epoch 36: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3349 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 37/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3336\n",
      "Epoch 37: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3336 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 38/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3305\n",
      "Epoch 38: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3305 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 39/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3326\n",
      "Epoch 39: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3326 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 40/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3318\n",
      "Epoch 40: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3318 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 41/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3336\n",
      "Epoch 41: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3336 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 42/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3326\n",
      "Epoch 42: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3326 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 43/200\n",
      " 41/122 [=========>....................] - ETA: 56s - loss: 1.0986 - accuracy: 0.3369"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 21\u001b[0m\n\u001b[1;32m     11\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[1;32m     12\u001b[0m     filepath\u001b[38;5;241m=\u001b[39mcheckpoint_path,\n\u001b[1;32m     13\u001b[0m     save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 검증 데이터 추가\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 학습 부분 수정\n",
    "# EarlyStopping 및 ModelCheckpoint 설정\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    min_delta=0.001,\n",
    "    patience=100, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint_path = \"GPT4_분류모델(02).h5\"\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(\n",
    "    train_X, train_y, epochs=200, batch_size=32, validation_data=(val_X, val_y),  # 검증 데이터 추가\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a07d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_X, test_y, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b085cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c70309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
