{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a8ebfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/ubuntu/anaconda3/lib/python3.10/site-packages (23.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8af310f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ubuntu/anaconda3/lib/python3.10/site-packages (4.24.0)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (0.19.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (0.11.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3df390e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/ubuntu/anaconda3/lib/python3.10/site-packages (2.14.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (12.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: xxhash in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (0.19.0)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1e76a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu==2.8.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (23.5.26)\n",
      "Requirement already satisfied: gast>=0.2.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (3.7.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.1.2)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (16.0.6)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (3.20.0)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (65.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (4.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.14.1)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (2.8.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (2.8.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.59.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-gpu==2.8.0) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-gpu==2.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "265ce3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.20 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (3.20.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install protobuf==3.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c89037b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import re\n",
    "import os\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5458e22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ìƒ˜í”Œì˜ ìˆ˜ : 5010\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('á„…á…¢á†«á„ƒá…¥á†·_5010á„€á…¢_GPT4.csv')\n",
    "print('ì´ ìƒ˜í”Œì˜ ìˆ˜ :',len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90855a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>sentence</th>\n",
       "      <th>ê²Œì‹œì¼</th>\n",
       "      <th>ì˜ìƒ ì¢‹ì•„ìš” ìˆ˜</th>\n",
       "      <th>kor_sentence</th>\n",
       "      <th>ì‘ì„±ì</th>\n",
       "      <th>ëŒ“ê¸€ ì‘ì„±ì¼</th>\n",
       "      <th>ëŒ“ê¸€ ì¢‹ì•„ìš” ìˆ˜</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ë¦¬ë‹ˆì§€W ì „ì„­ìµœì´ˆ ì§‘í–‰ê²€! 330ì–µ íˆ¬ìí•œ ìºë¦­ ì†Œê°œí•©ë‹ˆë‹¤ (ì„±ë¶ë™ì´ˆì½”íŒŒì´í˜•ë‹˜)  ...</td>\n",
       "      <td>2023-05-05T12:45:55Z</td>\n",
       "      <td>1048</td>\n",
       "      <td>ğŸ¥›ë¡¤ğŸ¥›ë±ƒğŸ¥›ì˜¬í•œí•´ ê°€ì¥ ì˜í•œì¸ì„ í•œê²Œ ì•„ë‹ê¹Œ ì‹¶ë‹¤.. ì‚¶ì˜ ì§ˆì´ ë‹¬ë¼ì ¸ ë²„ë ¸ìŠµë‹ˆë‹¤ ê³ ...</td>\n",
       "      <td>1M CYRUS</td>\n",
       "      <td>2023-11-06T17:52:52Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ë°°ê·¸ ì´í›„ ê°€ì¥ ì„±ê³µí•œ í•œêµ­ FPS (feat. ë„¥ìŠ¨)</td>\n",
       "      <td>2023-11-05T13:39:51Z</td>\n",
       "      <td>2977</td>\n",
       "      <td>ì›ê²©í¬ë§·ì€ ì§€ë£¡ìğŸ•·</td>\n",
       "      <td>JAY</td>\n",
       "      <td>2023-11-10T10:39:24Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[í”¼íŒŒ4] 1ì–µë¶€í„° 4600ì–µê¹Œì§€ ëª°ì•„ë³´ê¸° feat. ì¸ìƒê°•í™”</td>\n",
       "      <td>2022-12-06T09:11:47Z</td>\n",
       "      <td>4052</td>\n",
       "      <td>ì—¬ìº  ë¡¤ë¹„ì œì´ë“¤ ì™œì¼€ ëª»í•˜ëŠ”ë° ê¸”ì—½ëƒ ì§€ëŠ”ê²Œ ê¿€ì¸ì¤„ì•Œì•˜ëŠ”ë° ì´ê¸°ê¸°ë„ í•˜ë„¤ ğŸ‡¨ğŸ‡¬ë¡¤ğŸ‡¨ğŸ‡¬ë±ƒğŸ‡¨ğŸ‡¬</td>\n",
       "      <td>Neardie Born</td>\n",
       "      <td>2023-10-21T11:15:42Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>íŒ¨ì¹˜ í›„ í”¼íŒŒë¥¼ ë– ë‚©ë‹ˆë‹¤!... í”¼íŒŒ4</td>\n",
       "      <td>2023-06-27T08:30:00Z</td>\n",
       "      <td>106</td>\n",
       "      <td>í˜„í”¼ì¥ì¸ ì½”ëš±ì‰ ë°”í…€ì„ í‰ì •í•œë‹¤ ë°°í—¤ë‹¹ ì¼.85 ì ‘ì†í•´ì„œ í™•ì¸í•©ì‹œë‹¤ ?ë¹„?ì œ?ì´?ë²³?</td>\n",
       "      <td>the dale lee lowe jr family</td>\n",
       "      <td>2023-07-24T10:26:22Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ì•„ë‹ˆ; ë–¡ë½ë„ ì´ëŸ° ë–¡ë½ì´ ì—†ëŠ” ë¡œìŠ¤íŠ¸ì•„í¬ ê¸€ë¡œë²Œ ì„œë²„ ê·¼í™©;;</td>\n",
       "      <td>2023-06-11T12:00:39Z</td>\n",
       "      <td>5097</td>\n",
       "      <td>âŒ¯ë¹„âŒ¯ì œâŒ¯ì´âŒ¯ë²³âŒ¯ ì €ì—ê²Œ ì´ëŸ°ê³³ì„ ì•Œê²Œí•´ì¤˜ì„œ ë„ˆëª¨ê³ ë§ˆì›Œìš”~~</td>\n",
       "      <td>aaltu faaltu</td>\n",
       "      <td>2023-08-03T17:51:58Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>1</td>\n",
       "      <td>ì›Œí—¤ì´ë¸ - ê³µì‹ íŠ¸ë ˆì¼ëŸ¬ | ì˜ì›…ì  í”Œë ˆì´ë¥¼ ê²½í—˜í•˜ë¼!</td>\n",
       "      <td>2023-09-14T07:28:58Z</td>\n",
       "      <td>15</td>\n",
       "      <td>í¥í•´ë¼ ì›Œí—¤ì´ë¸!</td>\n",
       "      <td>í•œì„ ìƒ ìœ íŠœë¸Œ Gaming HanTeacher</td>\n",
       "      <td>2023-09-14T11:57:35Z</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>1</td>\n",
       "      <td>ì œ2ì˜ë‚˜ë¼ Cross Worlds OST 'ëì—†ëŠ” í•˜ëŠ˜'</td>\n",
       "      <td>2021-08-11T02:15:07Z</td>\n",
       "      <td>21</td>\n",
       "      <td>íˆì‚¬ì´ì‹œ ì¡° ì„ ìƒë‹˜ì˜ ostë¥¼ ì´ë ‡ê²Œ í”¼ì•„ë…¸ ì†”ë¡œë¡œ ë“¤ìœ¼ë‹ˆ ìƒˆë¡­ê²Œ ë“¤ë¦¬ë„¤ìš”!! ì˜¤ëŠ˜...</td>\n",
       "      <td>ê³µë‹´ â™ª</td>\n",
       "      <td>2021-10-06T07:34:27Z</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>1</td>\n",
       "      <td>ã€126ê³¡ã€ ìµœì‹  ìš°íƒ€ì´í…Œ ëª…ê³¡ë§Œ ëª¨ì•„ ë„£ì€ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ã€ë…¸ë˜ëª¨ìŒ/Playlistã€‘</td>\n",
       "      <td>2023-05-06T09:09:11Z</td>\n",
       "      <td>1072</td>\n",
       "      <td>ã… ì§„ì§œ ëµê³¡ë“¤ë§Œ ëª¨ì•„ë†¨ë‹¤..</td>\n",
       "      <td>ì¸ê°„</td>\n",
       "      <td>2023-09-04T06:35:47Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>1</td>\n",
       "      <td>ì¼ë°˜ì „ê³¼ ì¬í™”ë°¸ëŸ°ìŠ¤ ì¡°ì •! ì‹ ê·œ ìŠ¤í‚¨ ì—…ë°ì´íŠ¸ê¹Œì§€ [ë² ì¼ë“œ ì—‘ìŠ¤í¼íŠ¸ 6ì›”22ì¼ íŒ¨ì¹˜ë…¸íŠ¸]</td>\n",
       "      <td>2023-06-22T08:45:16Z</td>\n",
       "      <td>13</td>\n",
       "      <td>ã… ã…  ì¼ë°˜ì „ 3vs3 ëª¨ë“œê°€ ì‚¬ë¼ì§„ê²Œ ì•„ì‰¬ìš¸ë”°ë¦„ì´ë„¤ìš”..! ëŒ€ì‹  ì—…ê·¸ë ˆì´ë“œ ì¬í™”ê°€ ...</td>\n",
       "      <td>ë„¤ì¹´</td>\n",
       "      <td>2023-06-23T04:44:50Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>1</td>\n",
       "      <td>ë‚­ë§Œ ê·¸ ìì²´, ë¹„í‚¤ë‹ˆ ì•„ì¼ëœë“œ ê¹œì§ ì´ë²¤íŠ¸ [ë‹¤ì‹œ, ì—¬ë¦„ë°©í•™]</td>\n",
       "      <td>2023-07-26T16:32:16Z</td>\n",
       "      <td>274</td>\n",
       "      <td>ã… ã… ì¼í•˜ê³  ë„ˆë¬´í”¼ê³¤í•´ì„œ ë‹¤ ìŠ¤í‚µí•˜ê³  ë´¤ëŠ”ë° í˜• ì˜ìƒë³´ê³  ê°™ì´ ìš¸ì–´ë²„ë¦¼</td>\n",
       "      <td>ì§¸ì—‰</td>\n",
       "      <td>2023-07-27T22:57:43Z</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5010 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                           sentence  \\\n",
       "0          0  ë¦¬ë‹ˆì§€W ì „ì„­ìµœì´ˆ ì§‘í–‰ê²€! 330ì–µ íˆ¬ìí•œ ìºë¦­ ì†Œê°œí•©ë‹ˆë‹¤ (ì„±ë¶ë™ì´ˆì½”íŒŒì´í˜•ë‹˜)  ...   \n",
       "1          0                     ë°°ê·¸ ì´í›„ ê°€ì¥ ì„±ê³µí•œ í•œêµ­ FPS (feat. ë„¥ìŠ¨)   \n",
       "2          0                 [í”¼íŒŒ4] 1ì–µë¶€í„° 4600ì–µê¹Œì§€ ëª°ì•„ë³´ê¸° feat. ì¸ìƒê°•í™”   \n",
       "3          0                              íŒ¨ì¹˜ í›„ í”¼íŒŒë¥¼ ë– ë‚©ë‹ˆë‹¤!... í”¼íŒŒ4   \n",
       "4          0                ì•„ë‹ˆ; ë–¡ë½ë„ ì´ëŸ° ë–¡ë½ì´ ì—†ëŠ” ë¡œìŠ¤íŠ¸ì•„í¬ ê¸€ë¡œë²Œ ì„œë²„ ê·¼í™©;;   \n",
       "...      ...                                                ...   \n",
       "5005       1                    ì›Œí—¤ì´ë¸ - ê³µì‹ íŠ¸ë ˆì¼ëŸ¬ | ì˜ì›…ì  í”Œë ˆì´ë¥¼ ê²½í—˜í•˜ë¼!   \n",
       "5006       1                    ì œ2ì˜ë‚˜ë¼ Cross Worlds OST 'ëì—†ëŠ” í•˜ëŠ˜'   \n",
       "5007       1    ã€126ê³¡ã€ ìµœì‹  ìš°íƒ€ì´í…Œ ëª…ê³¡ë§Œ ëª¨ì•„ ë„£ì€ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ã€ë…¸ë˜ëª¨ìŒ/Playlistã€‘   \n",
       "5008       1  ì¼ë°˜ì „ê³¼ ì¬í™”ë°¸ëŸ°ìŠ¤ ì¡°ì •! ì‹ ê·œ ìŠ¤í‚¨ ì—…ë°ì´íŠ¸ê¹Œì§€ [ë² ì¼ë“œ ì—‘ìŠ¤í¼íŠ¸ 6ì›”22ì¼ íŒ¨ì¹˜ë…¸íŠ¸]   \n",
       "5009       1                ë‚­ë§Œ ê·¸ ìì²´, ë¹„í‚¤ë‹ˆ ì•„ì¼ëœë“œ ê¹œì§ ì´ë²¤íŠ¸ [ë‹¤ì‹œ, ì—¬ë¦„ë°©í•™]   \n",
       "\n",
       "                       ê²Œì‹œì¼  ì˜ìƒ ì¢‹ì•„ìš” ìˆ˜  \\\n",
       "0     2023-05-05T12:45:55Z      1048   \n",
       "1     2023-11-05T13:39:51Z      2977   \n",
       "2     2022-12-06T09:11:47Z      4052   \n",
       "3     2023-06-27T08:30:00Z       106   \n",
       "4     2023-06-11T12:00:39Z      5097   \n",
       "...                    ...       ...   \n",
       "5005  2023-09-14T07:28:58Z        15   \n",
       "5006  2021-08-11T02:15:07Z        21   \n",
       "5007  2023-05-06T09:09:11Z      1072   \n",
       "5008  2023-06-22T08:45:16Z        13   \n",
       "5009  2023-07-26T16:32:16Z       274   \n",
       "\n",
       "                                           kor_sentence  \\\n",
       "0     ğŸ¥›ë¡¤ğŸ¥›ë±ƒğŸ¥›ì˜¬í•œí•´ ê°€ì¥ ì˜í•œì¸ì„ í•œê²Œ ì•„ë‹ê¹Œ ì‹¶ë‹¤.. ì‚¶ì˜ ì§ˆì´ ë‹¬ë¼ì ¸ ë²„ë ¸ìŠµë‹ˆë‹¤ ê³ ...   \n",
       "1                                            ì›ê²©í¬ë§·ì€ ì§€ë£¡ìğŸ•·   \n",
       "2     ì—¬ìº  ë¡¤ë¹„ì œì´ë“¤ ì™œì¼€ ëª»í•˜ëŠ”ë° ê¸”ì—½ëƒ ì§€ëŠ”ê²Œ ê¿€ì¸ì¤„ì•Œì•˜ëŠ”ë° ì´ê¸°ê¸°ë„ í•˜ë„¤ ğŸ‡¨ğŸ‡¬ë¡¤ğŸ‡¨ğŸ‡¬ë±ƒğŸ‡¨ğŸ‡¬   \n",
       "3       í˜„í”¼ì¥ì¸ ì½”ëš±ì‰ ë°”í…€ì„ í‰ì •í•œë‹¤ ë°°í—¤ë‹¹ ì¼.85 ì ‘ì†í•´ì„œ í™•ì¸í•©ì‹œë‹¤ ?ë¹„?ì œ?ì´?ë²³?   \n",
       "4                     âŒ¯ë¹„âŒ¯ì œâŒ¯ì´âŒ¯ë²³âŒ¯ ì €ì—ê²Œ ì´ëŸ°ê³³ì„ ì•Œê²Œí•´ì¤˜ì„œ ë„ˆëª¨ê³ ë§ˆì›Œìš”~~   \n",
       "...                                                 ...   \n",
       "5005                                          í¥í•´ë¼ ì›Œí—¤ì´ë¸!   \n",
       "5006  íˆì‚¬ì´ì‹œ ì¡° ì„ ìƒë‹˜ì˜ ostë¥¼ ì´ë ‡ê²Œ í”¼ì•„ë…¸ ì†”ë¡œë¡œ ë“¤ìœ¼ë‹ˆ ìƒˆë¡­ê²Œ ë“¤ë¦¬ë„¤ìš”!! ì˜¤ëŠ˜...   \n",
       "5007                                   ã… ì§„ì§œ ëµê³¡ë“¤ë§Œ ëª¨ì•„ë†¨ë‹¤..   \n",
       "5008  ã… ã…  ì¼ë°˜ì „ 3vs3 ëª¨ë“œê°€ ì‚¬ë¼ì§„ê²Œ ì•„ì‰¬ìš¸ë”°ë¦„ì´ë„¤ìš”..! ëŒ€ì‹  ì—…ê·¸ë ˆì´ë“œ ì¬í™”ê°€ ...   \n",
       "5009             ã… ã… ì¼í•˜ê³  ë„ˆë¬´í”¼ê³¤í•´ì„œ ë‹¤ ìŠ¤í‚µí•˜ê³  ë´¤ëŠ”ë° í˜• ì˜ìƒë³´ê³  ê°™ì´ ìš¸ì–´ë²„ë¦¼   \n",
       "\n",
       "                                ì‘ì„±ì                ëŒ“ê¸€ ì‘ì„±ì¼  ëŒ“ê¸€ ì¢‹ì•„ìš” ìˆ˜  \n",
       "0                          1M CYRUS  2023-11-06T17:52:52Z         0  \n",
       "1                               JAY  2023-11-10T10:39:24Z         0  \n",
       "2                      Neardie Born  2023-10-21T11:15:42Z         0  \n",
       "3      the dale lee lowe jr family   2023-07-24T10:26:22Z         0  \n",
       "4                      aaltu faaltu  2023-08-03T17:51:58Z         0  \n",
       "...                             ...                   ...       ...  \n",
       "5005      í•œì„ ìƒ ìœ íŠœë¸Œ Gaming HanTeacher  2023-09-14T11:57:35Z         1  \n",
       "5006                           ê³µë‹´ â™ª  2021-10-06T07:34:27Z         3  \n",
       "5007                             ì¸ê°„  2023-09-04T06:35:47Z         0  \n",
       "5008                             ë„¤ì¹´  2023-06-23T04:44:50Z         0  \n",
       "5009                             ì§¸ì—‰  2023-07-27T22:57:43Z         2  \n",
       "\n",
       "[5010 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe38bc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>sentence</th>\n",
       "      <th>ê²Œì‹œì¼</th>\n",
       "      <th>ì˜ìƒ ì¢‹ì•„ìš” ìˆ˜</th>\n",
       "      <th>kor_sentence</th>\n",
       "      <th>ì‘ì„±ì</th>\n",
       "      <th>ëŒ“ê¸€ ì‘ì„±ì¼</th>\n",
       "      <th>ëŒ“ê¸€ ì¢‹ì•„ìš” ìˆ˜</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ë¦¬ë‹ˆì§€W ì „ì„­ìµœì´ˆ ì§‘í–‰ê²€! 330ì–µ íˆ¬ìí•œ ìºë¦­ ì†Œê°œí•©ë‹ˆë‹¤ (ì„±ë¶ë™ì´ˆì½”íŒŒì´í˜•ë‹˜)  ...</td>\n",
       "      <td>2023-05-05T12:45:55Z</td>\n",
       "      <td>1048</td>\n",
       "      <td>ğŸ¥›ë¡¤ğŸ¥›ë±ƒğŸ¥›ì˜¬í•œí•´ ê°€ì¥ ì˜í•œì¸ì„ í•œê²Œ ì•„ë‹ê¹Œ ì‹¶ë‹¤.. ì‚¶ì˜ ì§ˆì´ ë‹¬ë¼ì ¸ ë²„ë ¸ìŠµë‹ˆë‹¤ ê³ ...</td>\n",
       "      <td>1M CYRUS</td>\n",
       "      <td>2023-11-06T17:52:52Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ë°°ê·¸ ì´í›„ ê°€ì¥ ì„±ê³µí•œ í•œêµ­ FPS (feat. ë„¥ìŠ¨)</td>\n",
       "      <td>2023-11-05T13:39:51Z</td>\n",
       "      <td>2977</td>\n",
       "      <td>ì›ê²©í¬ë§·ì€ ì§€ë£¡ìğŸ•·</td>\n",
       "      <td>JAY</td>\n",
       "      <td>2023-11-10T10:39:24Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[í”¼íŒŒ4] 1ì–µë¶€í„° 4600ì–µê¹Œì§€ ëª°ì•„ë³´ê¸° feat. ì¸ìƒê°•í™”</td>\n",
       "      <td>2022-12-06T09:11:47Z</td>\n",
       "      <td>4052</td>\n",
       "      <td>ì—¬ìº  ë¡¤ë¹„ì œì´ë“¤ ì™œì¼€ ëª»í•˜ëŠ”ë° ê¸”ì—½ëƒ ì§€ëŠ”ê²Œ ê¿€ì¸ì¤„ì•Œì•˜ëŠ”ë° ì´ê¸°ê¸°ë„ í•˜ë„¤ ğŸ‡¨ğŸ‡¬ë¡¤ğŸ‡¨ğŸ‡¬ë±ƒğŸ‡¨ğŸ‡¬</td>\n",
       "      <td>Neardie Born</td>\n",
       "      <td>2023-10-21T11:15:42Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>íŒ¨ì¹˜ í›„ í”¼íŒŒë¥¼ ë– ë‚©ë‹ˆë‹¤!... í”¼íŒŒ4</td>\n",
       "      <td>2023-06-27T08:30:00Z</td>\n",
       "      <td>106</td>\n",
       "      <td>í˜„í”¼ì¥ì¸ ì½”ëš±ì‰ ë°”í…€ì„ í‰ì •í•œë‹¤ ë°°í—¤ë‹¹ ì¼.85 ì ‘ì†í•´ì„œ í™•ì¸í•©ì‹œë‹¤ ?ë¹„?ì œ?ì´?ë²³?</td>\n",
       "      <td>the dale lee lowe jr family</td>\n",
       "      <td>2023-07-24T10:26:22Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ì•„ë‹ˆ; ë–¡ë½ë„ ì´ëŸ° ë–¡ë½ì´ ì—†ëŠ” ë¡œìŠ¤íŠ¸ì•„í¬ ê¸€ë¡œë²Œ ì„œë²„ ê·¼í™©;;</td>\n",
       "      <td>2023-06-11T12:00:39Z</td>\n",
       "      <td>5097</td>\n",
       "      <td>âŒ¯ë¹„âŒ¯ì œâŒ¯ì´âŒ¯ë²³âŒ¯ ì €ì—ê²Œ ì´ëŸ°ê³³ì„ ì•Œê²Œí•´ì¤˜ì„œ ë„ˆëª¨ê³ ë§ˆì›Œìš”~~</td>\n",
       "      <td>aaltu faaltu</td>\n",
       "      <td>2023-08-03T17:51:58Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                           sentence  \\\n",
       "0       0  ë¦¬ë‹ˆì§€W ì „ì„­ìµœì´ˆ ì§‘í–‰ê²€! 330ì–µ íˆ¬ìí•œ ìºë¦­ ì†Œê°œí•©ë‹ˆë‹¤ (ì„±ë¶ë™ì´ˆì½”íŒŒì´í˜•ë‹˜)  ...   \n",
       "1       0                     ë°°ê·¸ ì´í›„ ê°€ì¥ ì„±ê³µí•œ í•œêµ­ FPS (feat. ë„¥ìŠ¨)   \n",
       "2       0                 [í”¼íŒŒ4] 1ì–µë¶€í„° 4600ì–µê¹Œì§€ ëª°ì•„ë³´ê¸° feat. ì¸ìƒê°•í™”   \n",
       "3       0                              íŒ¨ì¹˜ í›„ í”¼íŒŒë¥¼ ë– ë‚©ë‹ˆë‹¤!... í”¼íŒŒ4   \n",
       "4       0                ì•„ë‹ˆ; ë–¡ë½ë„ ì´ëŸ° ë–¡ë½ì´ ì—†ëŠ” ë¡œìŠ¤íŠ¸ì•„í¬ ê¸€ë¡œë²Œ ì„œë²„ ê·¼í™©;;   \n",
       "\n",
       "                    ê²Œì‹œì¼  ì˜ìƒ ì¢‹ì•„ìš” ìˆ˜  \\\n",
       "0  2023-05-05T12:45:55Z      1048   \n",
       "1  2023-11-05T13:39:51Z      2977   \n",
       "2  2022-12-06T09:11:47Z      4052   \n",
       "3  2023-06-27T08:30:00Z       106   \n",
       "4  2023-06-11T12:00:39Z      5097   \n",
       "\n",
       "                                        kor_sentence  \\\n",
       "0  ğŸ¥›ë¡¤ğŸ¥›ë±ƒğŸ¥›ì˜¬í•œí•´ ê°€ì¥ ì˜í•œì¸ì„ í•œê²Œ ì•„ë‹ê¹Œ ì‹¶ë‹¤.. ì‚¶ì˜ ì§ˆì´ ë‹¬ë¼ì ¸ ë²„ë ¸ìŠµë‹ˆë‹¤ ê³ ...   \n",
       "1                                         ì›ê²©í¬ë§·ì€ ì§€ë£¡ìğŸ•·   \n",
       "2  ì—¬ìº  ë¡¤ë¹„ì œì´ë“¤ ì™œì¼€ ëª»í•˜ëŠ”ë° ê¸”ì—½ëƒ ì§€ëŠ”ê²Œ ê¿€ì¸ì¤„ì•Œì•˜ëŠ”ë° ì´ê¸°ê¸°ë„ í•˜ë„¤ ğŸ‡¨ğŸ‡¬ë¡¤ğŸ‡¨ğŸ‡¬ë±ƒğŸ‡¨ğŸ‡¬   \n",
       "3    í˜„í”¼ì¥ì¸ ì½”ëš±ì‰ ë°”í…€ì„ í‰ì •í•œë‹¤ ë°°í—¤ë‹¹ ì¼.85 ì ‘ì†í•´ì„œ í™•ì¸í•©ì‹œë‹¤ ?ë¹„?ì œ?ì´?ë²³?   \n",
       "4                  âŒ¯ë¹„âŒ¯ì œâŒ¯ì´âŒ¯ë²³âŒ¯ ì €ì—ê²Œ ì´ëŸ°ê³³ì„ ì•Œê²Œí•´ì¤˜ì„œ ë„ˆëª¨ê³ ë§ˆì›Œìš”~~   \n",
       "\n",
       "                             ì‘ì„±ì                ëŒ“ê¸€ ì‘ì„±ì¼  ëŒ“ê¸€ ì¢‹ì•„ìš” ìˆ˜  \n",
       "0                       1M CYRUS  2023-11-06T17:52:52Z         0  \n",
       "1                            JAY  2023-11-10T10:39:24Z         0  \n",
       "2                   Neardie Born  2023-10-21T11:15:42Z         0  \n",
       "3   the dale lee lowe jr family   2023-07-24T10:26:22Z         0  \n",
       "4                   aaltu faaltu  2023-08-03T17:51:58Z         0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09fdc038",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['sentence', 'ê²Œì‹œì¼', 'ì˜ìƒ ì¢‹ì•„ìš” ìˆ˜', 'ì‘ì„±ì', 'ëŒ“ê¸€ ì‘ì„±ì¼', 'ëŒ“ê¸€ ì¢‹ì•„ìš” ìˆ˜'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d44878ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>kor_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ğŸ¥›ë¡¤ğŸ¥›ë±ƒğŸ¥›ì˜¬í•œí•´ ê°€ì¥ ì˜í•œì¸ì„ í•œê²Œ ì•„ë‹ê¹Œ ì‹¶ë‹¤.. ì‚¶ì˜ ì§ˆì´ ë‹¬ë¼ì ¸ ë²„ë ¸ìŠµë‹ˆë‹¤ ê³ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ì›ê²©í¬ë§·ì€ ì§€ë£¡ìğŸ•·</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>ì—¬ìº  ë¡¤ë¹„ì œì´ë“¤ ì™œì¼€ ëª»í•˜ëŠ”ë° ê¸”ì—½ëƒ ì§€ëŠ”ê²Œ ê¿€ì¸ì¤„ì•Œì•˜ëŠ”ë° ì´ê¸°ê¸°ë„ í•˜ë„¤ ğŸ‡¨ğŸ‡¬ë¡¤ğŸ‡¨ğŸ‡¬ë±ƒğŸ‡¨ğŸ‡¬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>í˜„í”¼ì¥ì¸ ì½”ëš±ì‰ ë°”í…€ì„ í‰ì •í•œë‹¤ ë°°í—¤ë‹¹ ì¼.85 ì ‘ì†í•´ì„œ í™•ì¸í•©ì‹œë‹¤ ?ë¹„?ì œ?ì´?ë²³?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>âŒ¯ë¹„âŒ¯ì œâŒ¯ì´âŒ¯ë²³âŒ¯ ì €ì—ê²Œ ì´ëŸ°ê³³ì„ ì•Œê²Œí•´ì¤˜ì„œ ë„ˆëª¨ê³ ë§ˆì›Œìš”~~</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                       kor_sentence\n",
       "0       0  ğŸ¥›ë¡¤ğŸ¥›ë±ƒğŸ¥›ì˜¬í•œí•´ ê°€ì¥ ì˜í•œì¸ì„ í•œê²Œ ì•„ë‹ê¹Œ ì‹¶ë‹¤.. ì‚¶ì˜ ì§ˆì´ ë‹¬ë¼ì ¸ ë²„ë ¸ìŠµë‹ˆë‹¤ ê³ ...\n",
       "1       0                                         ì›ê²©í¬ë§·ì€ ì§€ë£¡ìğŸ•·\n",
       "2       0  ì—¬ìº  ë¡¤ë¹„ì œì´ë“¤ ì™œì¼€ ëª»í•˜ëŠ”ë° ê¸”ì—½ëƒ ì§€ëŠ”ê²Œ ê¿€ì¸ì¤„ì•Œì•˜ëŠ”ë° ì´ê¸°ê¸°ë„ í•˜ë„¤ ğŸ‡¨ğŸ‡¬ë¡¤ğŸ‡¨ğŸ‡¬ë±ƒğŸ‡¨ğŸ‡¬\n",
       "3       0    í˜„í”¼ì¥ì¸ ì½”ëš±ì‰ ë°”í…€ì„ í‰ì •í•œë‹¤ ë°°í—¤ë‹¹ ì¼.85 ì ‘ì†í•´ì„œ í™•ì¸í•©ì‹œë‹¤ ?ë¹„?ì œ?ì´?ë²³?\n",
       "4       0                  âŒ¯ë¹„âŒ¯ì œâŒ¯ì´âŒ¯ë²³âŒ¯ ì €ì—ê²Œ ì´ëŸ°ê³³ì„ ì•Œê²Œí•´ì¤˜ì„œ ë„ˆëª¨ê³ ë§ˆì›Œìš”~~"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b251528a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê²°ì¸¡ê°’ ì—¬ë¶€ : False\n"
     ]
    }
   ],
   "source": [
    "print('ê²°ì¸¡ê°’ ì—¬ë¶€ :',data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5003489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kor_sentence ì—´ì˜ ìœ ë‹ˆí¬í•œ ê°’ : 4845\n"
     ]
    }
   ],
   "source": [
    "print('kor_sentence ì—´ì˜ ìœ ë‹ˆí¬í•œ ê°’ :',data['kor_sentence'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7319ade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3a85442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê²°ì¸¡ê°’ ì—¬ë¶€ : False\n"
     ]
    }
   ],
   "source": [
    "print('ê²°ì¸¡ê°’ ì—¬ë¶€ :',data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2f5f6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kor_sentence ì—´ì˜ ìœ ë‹ˆí¬í•œ ê°’ : 4845\n"
     ]
    }
   ],
   "source": [
    "print('kor_sentence ì—´ì˜ ìœ ë‹ˆí¬í•œ ê°’ :',data['kor_sentence'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f7e5a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¤‘ë³µëœ í–‰ì„ ë³´ëŠ” ì½”ë“œ\n",
    "duplicate = data[data.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f5e984f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>kor_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0</td>\n",
       "      <td>ë¶€ë´ë¶€ë´ ì¶œê·¼ì¤€ë¹„ í•˜ê³  ë°”ì˜ë‹¤ê³  í• ë•Œ ë‚œ ğŸ§¿ë¡¤ğŸ§¿ë±ƒğŸ§¿ ë–„ë¬¸ì— ì§‘ì—ì„œ ëŠê¸‹í•˜ê²Œ ëŠ¦ì ìë©´...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0</td>\n",
       "      <td>ìŠˆí¼ê¾¸ë™ ì´ìƒí˜¸ë¦¬ ì •ê¸€ í”Œë ˆì´ì„œ ê¾¸ë¥´ë¥´ë¥´ì¼ ë±ƒí•˜ë©´ì„œ êµ¬ê²½í•´ìš” ì´ìƒí˜¸ íŒ¨ê°€ ì •ğŸ§â€â™€ï¸...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0</td>\n",
       "      <td>ğŸ½ï¸ë¡¤ğŸ½ï¸ë±ƒğŸ½ï¸ì˜·ì¥ì— í›„ì§ˆê·¼í•œ ì˜· ì´ë©° ì‹ ë°œì´ë©° ë‹¤ê°“ë‹¤ ë²„ë¦¬ê³  ìŒê±¸ë¡œ ì«™ ê°ˆì•„ ì—ì...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0</td>\n",
       "      <td>ê·¼ë° í•˜ë‚˜ê°™ì´ ë””ìì¸ ì™¤ì¼€ ì‰°ë‚´ë‚¨? (ë©”êµ¬ìš°ì‚¬ í´ë˜ì‹, í”„ë¦¬ë¯¸ì—„ ì œì™¸) í‹€ë”±ê²œ ëƒ„ìƒˆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>0</td>\n",
       "      <td>âŒ¯ë¹„âŒ¯ì œâŒ¯ì´âŒ¯ë²³âŒ¯ ì €ì—ê²Œ ì´ëŸ°ê³³ì„ ì•Œê²Œí•´ì¤˜ì„œ ë„ˆëª¨ê³ ë§ˆì›Œìš”~~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>1</td>\n",
       "      <td>í¥í•´ë¼ ì›Œí—¤ì´ë¸!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>1</td>\n",
       "      <td>íˆì‚¬ì´ì‹œ ì¡° ì„ ìƒë‹˜ì˜ ostë¥¼ ì´ë ‡ê²Œ í”¼ì•„ë…¸ ì†”ë¡œë¡œ ë“¤ìœ¼ë‹ˆ ìƒˆë¡­ê²Œ ë“¤ë¦¬ë„¤ìš”!! ì˜¤ëŠ˜...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>1</td>\n",
       "      <td>ã… ì§„ì§œ ëµê³¡ë“¤ë§Œ ëª¨ì•„ë†¨ë‹¤..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>1</td>\n",
       "      <td>ã… ã…  ì¼ë°˜ì „ 3vs3 ëª¨ë“œê°€ ì‚¬ë¼ì§„ê²Œ ì•„ì‰¬ìš¸ë”°ë¦„ì´ë„¤ìš”..! ëŒ€ì‹  ì—…ê·¸ë ˆì´ë“œ ì¬í™”ê°€ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>1</td>\n",
       "      <td>ã… ã… ì¼í•˜ê³  ë„ˆë¬´í”¼ê³¤í•´ì„œ ë‹¤ ìŠ¤í‚µí•˜ê³  ë´¤ëŠ”ë° í˜• ì˜ìƒë³´ê³  ê°™ì´ ìš¸ì–´ë²„ë¦¼</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                       kor_sentence\n",
       "197        0  ë¶€ë´ë¶€ë´ ì¶œê·¼ì¤€ë¹„ í•˜ê³  ë°”ì˜ë‹¤ê³  í• ë•Œ ë‚œ ğŸ§¿ë¡¤ğŸ§¿ë±ƒğŸ§¿ ë–„ë¬¸ì— ì§‘ì—ì„œ ëŠê¸‹í•˜ê²Œ ëŠ¦ì ìë©´...\n",
       "204        0  ìŠˆí¼ê¾¸ë™ ì´ìƒí˜¸ë¦¬ ì •ê¸€ í”Œë ˆì´ì„œ ê¾¸ë¥´ë¥´ë¥´ì¼ ë±ƒí•˜ë©´ì„œ êµ¬ê²½í•´ìš” ì´ìƒí˜¸ íŒ¨ê°€ ì •ğŸ§â€â™€ï¸...\n",
       "216        0  ğŸ½ï¸ë¡¤ğŸ½ï¸ë±ƒğŸ½ï¸ì˜·ì¥ì— í›„ì§ˆê·¼í•œ ì˜· ì´ë©° ì‹ ë°œì´ë©° ë‹¤ê°“ë‹¤ ë²„ë¦¬ê³  ìŒê±¸ë¡œ ì«™ ê°ˆì•„ ì—ì...\n",
       "494        0  ê·¼ë° í•˜ë‚˜ê°™ì´ ë””ìì¸ ì™¤ì¼€ ì‰°ë‚´ë‚¨? (ë©”êµ¬ìš°ì‚¬ í´ë˜ì‹, í”„ë¦¬ë¯¸ì—„ ì œì™¸) í‹€ë”±ê²œ ëƒ„ìƒˆ...\n",
       "570        0                  âŒ¯ë¹„âŒ¯ì œâŒ¯ì´âŒ¯ë²³âŒ¯ ì €ì—ê²Œ ì´ëŸ°ê³³ì„ ì•Œê²Œí•´ì¤˜ì„œ ë„ˆëª¨ê³ ë§ˆì›Œìš”~~\n",
       "...      ...                                                ...\n",
       "5005       1                                          í¥í•´ë¼ ì›Œí—¤ì´ë¸!\n",
       "5006       1  íˆì‚¬ì´ì‹œ ì¡° ì„ ìƒë‹˜ì˜ ostë¥¼ ì´ë ‡ê²Œ í”¼ì•„ë…¸ ì†”ë¡œë¡œ ë“¤ìœ¼ë‹ˆ ìƒˆë¡­ê²Œ ë“¤ë¦¬ë„¤ìš”!! ì˜¤ëŠ˜...\n",
       "5007       1                                   ã… ì§„ì§œ ëµê³¡ë“¤ë§Œ ëª¨ì•„ë†¨ë‹¤..\n",
       "5008       1  ã… ã…  ì¼ë°˜ì „ 3vs3 ëª¨ë“œê°€ ì‚¬ë¼ì§„ê²Œ ì•„ì‰¬ìš¸ë”°ë¦„ì´ë„¤ìš”..! ëŒ€ì‹  ì—…ê·¸ë ˆì´ë“œ ì¬í™”ê°€ ...\n",
       "5009       1             ã… ã… ì¼í•˜ê³  ë„ˆë¬´í”¼ê³¤í•´ì„œ ë‹¤ ìŠ¤í‚µí•˜ê³  ë´¤ëŠ”ë° í˜• ì˜ìƒë³´ê³  ê°™ì´ ìš¸ì–´ë²„ë¦¼\n",
       "\n",
       "[90 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64dc86a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ìƒ˜í”Œì˜ ìˆ˜ : 4845\n"
     ]
    }
   ],
   "source": [
    "# ì¤‘ë³µ ì œê±°\n",
    "data.drop_duplicates(subset=['kor_sentence'], inplace=True)\n",
    "print('ì´ ìƒ˜í”Œì˜ ìˆ˜ :',len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6a092d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['labels'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0d9cfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1620\n",
       "0    1618\n",
       "2    1607\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec598fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ì¶”ê°€\n",
    "blank_rows = data['labels'].astype(str).str.strip() == ''\n",
    "#ê¸°ì¡´\n",
    "data = data[~blank_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7878189c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1620\n",
       "0    1618\n",
       "2    1607\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "802c1005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['labels'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acae5fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë ˆì´ë¸”ì˜ ë¶„í¬\n",
      "   labels  count\n",
      "0       0   1618\n",
      "1       1   1620\n",
      "2       2   1607\n"
     ]
    }
   ],
   "source": [
    "print('ë ˆì´ë¸”ì˜ ë¶„í¬')\n",
    "print(data.groupby('labels').size().reset_index(name='count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f16b7184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê¸ì •ì˜ ë¹„ìœ¨ = 33.395%\n",
      "ì¤‘ë¦½ì˜ ë¹„ìœ¨ = 33.437%\n",
      "ë¶€ì •ì˜ ë¹„ìœ¨ = 33.168%\n"
     ]
    }
   ],
   "source": [
    "print(f'ê¸ì •ì˜ ë¹„ìœ¨ = {round(data[\"labels\"].value_counts()[0]/len(data) * 100,3)}%')\n",
    "print(f'ì¤‘ë¦½ì˜ ë¹„ìœ¨ = {round(data[\"labels\"].value_counts()[1]/len(data) * 100,3)}%')\n",
    "print(f'ë¶€ì •ì˜ ë¹„ìœ¨ = {round(data[\"labels\"].value_counts()[2]/len(data) * 100,3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98e04e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë³¸ë¬¸ì˜ ê°œìˆ˜: 4845\n",
      "ë ˆì´ë¸”ì˜ ê°œìˆ˜: 4845\n"
     ]
    }
   ],
   "source": [
    "X_data = data['kor_sentence']\n",
    "y_data = data['labels']\n",
    "print('ë³¸ë¬¸ì˜ ê°œìˆ˜: {}'.format(len(X_data)))\n",
    "print('ë ˆì´ë¸”ì˜ ê°œìˆ˜: {}'.format(len(y_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8148adbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.20, random_state=0, stratify=y_data)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.25, random_state=0, stratify=y_data)\n",
    "\n",
    "# ë°ì´í„° ë¶„í•  ë¶€ë¶„ ìˆ˜ì •\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.2, random_state=0, stratify=y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5d3c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í›ˆë ¨ ìƒ˜í”Œì˜ ê°œìˆ˜ : 3876\n",
      "í…ŒìŠ¤íŠ¸ ìƒ˜í”Œì˜ ê°œìˆ˜ : 969\n"
     ]
    }
   ],
   "source": [
    "print('í›ˆë ¨ ìƒ˜í”Œì˜ ê°œìˆ˜ :', len(X_train))\n",
    "print('í…ŒìŠ¤íŠ¸ ìƒ˜í”Œì˜ ê°œìˆ˜ :', len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da4fc90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------í›ˆë ¨ ë°ì´í„°ì˜ ë¹„ìœ¨-----------\n",
      "ê¸ì • = 33.385%\n",
      "ì¤‘ë¦½ = 33.437%\n",
      "ë¶€ì • = 33.179%\n"
     ]
    }
   ],
   "source": [
    "print('--------í›ˆë ¨ ë°ì´í„°ì˜ ë¹„ìœ¨-----------')\n",
    "print(f'ê¸ì • = {round(y_train.value_counts()[0]/len(y_train) * 100,3)}%')\n",
    "print(f'ì¤‘ë¦½ = {round(y_train.value_counts()[1]/len(y_train) * 100,3)}%')\n",
    "print(f'ë¶€ì • = {round(y_train.value_counts()[2]/len(y_train) * 100,3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b38a24a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ë¹„ìœ¨-----------\n",
      "ê¸ì • = 33.437%\n",
      "ì¤‘ë¦½ = 33.437%\n",
      "ë¶€ì • = 33.127%\n"
     ]
    }
   ],
   "source": [
    "print('--------í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ë¹„ìœ¨-----------')\n",
    "print(f'ê¸ì • = {round(y_val.value_counts()[0]/len(y_val) * 100,3)}%')\n",
    "print(f'ì¤‘ë¦½ = {round(y_val.value_counts()[1]/len(y_val) * 100,3)}%')\n",
    "print(f'ë¶€ì • = {round(y_val.value_counts()[2]/len(y_val) * 100,3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac1542ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ceac494",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('klue/bert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76cfb74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_examples_to_features í•¨ìˆ˜ ìˆ˜ì •\n",
    "def convert_examples_to_features(examples, labels, max_seq_len, tokenizer):\n",
    "    input_ids, attention_masks, token_type_ids, data_labels = [], [], [], []\n",
    "\n",
    "    for example, label in tqdm(zip(examples, labels), total=len(examples)):\n",
    "        # input_idëŠ” ì›Œë“œ ì„ë² ë”©ì„ ìœ„í•œ ë¬¸ì¥ì˜ ì •ìˆ˜ ì¸ì½”ë”©\n",
    "        input_id = tokenizer.encode(example, max_length=max_seq_len, pad_to_max_length=True)\n",
    "\n",
    "        # attention_maskëŠ” ì‹¤ì œ ë‹¨ì–´ê°€ ìœ„ì¹˜í•˜ë©´ 1, íŒ¨ë”©ì˜ ìœ„ì¹˜ì—ëŠ” 0ì¸ ì‹œí€€ìŠ¤.\n",
    "        padding_count = input_id.count(tokenizer.pad_token_id)\n",
    "        attention_mask = [1] * (max_seq_len - padding_count) + [0] * padding_count\n",
    "\n",
    "        # token_type_idì€ ì„¸ê·¸ë¨¼íŠ¸ ì¸ì½”ë”©\n",
    "        token_type_id = [0] * max_seq_len\n",
    "\n",
    "        assert len(input_id) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_id), max_seq_len)\n",
    "        assert len(attention_mask) == max_seq_len, \"Error with attention mask length {} vs {}\".format(len(attention_mask), max_seq_len)\n",
    "        assert len(token_type_id) == max_seq_len, \"Error with token type length {} vs {}\".format(len(token_type_id), max_seq_len)\n",
    "\n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        data_labels.append(label)\n",
    "\n",
    "    input_ids = np.array(input_ids, dtype=int)\n",
    "    attention_masks = np.array(attention_masks, dtype=int)\n",
    "    token_type_ids = np.array(token_type_ids, dtype=int)\n",
    "\n",
    "    data_labels = np.asarray(data_labels, dtype=np.int32)\n",
    "\n",
    "    return (input_ids, attention_masks, token_type_ids), data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "150b4fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3876 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/ubuntu/anaconda3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3876/3876 [00:00<00:00, 4047.60it/s]\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y = convert_examples_to_features(X_train, y_train, max_seq_len=max_seq_len, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19e68102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3876/3876 [00:00<00:00, 4124.44it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 969/969 [00:00<00:00, 4139.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# ìˆ˜ì •ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ë° ê²€ì¦ ë°ì´í„° ìƒì„±\n",
    "train_X, train_y = convert_examples_to_features(X_train, y_train, max_seq_len=max_seq_len, tokenizer=tokenizer)\n",
    "val_X, val_y = convert_examples_to_features(X_val, y_val, max_seq_len=max_seq_len, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c0c55b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹¨ì–´ì— ëŒ€í•œ ì •ìˆ˜ ì¸ì½”ë”© : [    2 25547  4388     5     3     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "ì–´í…ì…˜ ë§ˆìŠ¤í¬ : [1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "ì„¸ê·¸ë¨¼íŠ¸ ì¸ì½”ë”© : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "ê° ì¸ì½”ë”©ì˜ ê¸¸ì´ : 128\n",
      "ì •ìˆ˜ ì¸ì½”ë”© ë³µì› : [CLS] ìµœì•  ë…¸ë˜! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "ë ˆì´ë¸” : 1\n"
     ]
    }
   ],
   "source": [
    "input_id = train_X[0][0]\n",
    "attention_mask = train_X[1][0]\n",
    "token_type_id = train_X[2][0]\n",
    "label = train_y[0]\n",
    "\n",
    "print('ë‹¨ì–´ì— ëŒ€í•œ ì •ìˆ˜ ì¸ì½”ë”© :',input_id)\n",
    "print('ì–´í…ì…˜ ë§ˆìŠ¤í¬ :',attention_mask)\n",
    "print('ì„¸ê·¸ë¨¼íŠ¸ ì¸ì½”ë”© :',token_type_id)\n",
    "print('ê° ì¸ì½”ë”©ì˜ ê¸¸ì´ :', len(input_id))\n",
    "print('ì •ìˆ˜ ì¸ì½”ë”© ë³µì› :',tokenizer.decode(input_id))\n",
    "print('ë ˆì´ë¸” :',label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e00db344",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 07:07:05.726201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-17 07:07:05.729924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-17 07:07:05.731941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-17 07:07:05.734665: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-17 07:07:05.735253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA GPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "node zero\n",
      "2023-11-17 07:07:05.737310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-17 07:07:05.739292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-17 07:07:07.911884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-17 07:07:07.913437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-17 07:07:07.914695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-17 07:07:07.915901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13227 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# TPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤\n",
    "if 'COLAB_TPU_ADDR' in os.environ:\n",
    "    # TPUê°€ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° TPUë¥¼ ì„¤ì •í•©ë‹ˆë‹¤\n",
    "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
    "    tf.config.experimental_connect_to_cluster(resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
    "    print('TPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.')\n",
    "else:\n",
    "    # TPUê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•œ ê²½ìš° CUDA GPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    if len(physical_devices) == 0:\n",
    "        raise RuntimeError(\"GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. TensorFlowê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "    # ëª¨ë“  GPU ë©”ëª¨ë¦¬ë¥¼ í•„ìš”ì— ë”°ë¼ ë™ì ìœ¼ë¡œ í• ë‹¹í•˜ë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "    # CUDA GPUë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ë¬¸ìì—´ \"/gpu:0\"ì„ ì „ë‹¬í•©ë‹ˆë‹¤\n",
    "    strategy = tf.distribute.OneDeviceStrategy(\"/gpu:0\")\n",
    "    print('CUDA GPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f30d4f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "  model = TFBertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=3, from_pt=True)\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "  model.compile(optimizer=optimizer, loss=loss, metrics = ['accuracy'])\n",
    "#   model.compile(optimizer=optimizer, loss=model.compute_loss, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b93d4c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFBertForSequenceClassification\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28cc5bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef5e9889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 07:07:09.823169: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_4465\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020FlatMapDataset:4\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - ETA: 0s - loss: 1.4732 - accuracy: 0.3480"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 07:08:50.639634: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_24624\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\021FlatMapDataset:27\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.37564, saving model to GPT4_ë¶„ë¥˜ëª¨ë¸(02).h5\n",
      "122/122 [==============================] - 113s 792ms/step - loss: 1.4732 - accuracy: 0.3480 - val_loss: 1.0975 - val_accuracy: 0.3756\n",
      "Epoch 2/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.1008 - accuracy: 0.3555\n",
      "Epoch 2: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 760ms/step - loss: 1.1008 - accuracy: 0.3555 - val_loss: 1.0986 - val_accuracy: 0.3571\n",
      "Epoch 3/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3393\n",
      "Epoch 3: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3393 - val_loss: 1.0986 - val_accuracy: 0.3571\n",
      "Epoch 4/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0983 - accuracy: 0.3333\n",
      "Epoch 4: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0983 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3571\n",
      "Epoch 5/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3506\n",
      "Epoch 5: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3506 - val_loss: 1.0986 - val_accuracy: 0.3571\n",
      "Epoch 6/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3449\n",
      "Epoch 6: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3449 - val_loss: 1.0986 - val_accuracy: 0.3571\n",
      "Epoch 7/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.1012 - accuracy: 0.3375\n",
      "Epoch 7: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.1012 - accuracy: 0.3375 - val_loss: 1.0986 - val_accuracy: 0.3509\n",
      "Epoch 8/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3333\n",
      "Epoch 8: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3509\n",
      "Epoch 9/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3349\n",
      "Epoch 9: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3349 - val_loss: 1.0986 - val_accuracy: 0.3509\n",
      "Epoch 10/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0983 - accuracy: 0.3261\n",
      "Epoch 10: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0983 - accuracy: 0.3261 - val_loss: 1.0986 - val_accuracy: 0.3509\n",
      "Epoch 11/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3331\n",
      "Epoch 11: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3331 - val_loss: 1.0986 - val_accuracy: 0.3509\n",
      "Epoch 12/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3398\n",
      "Epoch 12: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3398 - val_loss: 1.0986 - val_accuracy: 0.3509\n",
      "Epoch 13/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3364\n",
      "Epoch 13: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3364 - val_loss: 1.0986 - val_accuracy: 0.3509\n",
      "Epoch 14/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3341\n",
      "Epoch 14: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3341 - val_loss: 1.0986 - val_accuracy: 0.3509\n",
      "Epoch 15/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3271\n",
      "Epoch 15: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 763ms/step - loss: 1.0986 - accuracy: 0.3271 - val_loss: 1.0986 - val_accuracy: 0.3509\n",
      "Epoch 16/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3354\n",
      "Epoch 16: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3354 - val_loss: 1.0986 - val_accuracy: 0.3509\n",
      "Epoch 17/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3277\n",
      "Epoch 17: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3277 - val_loss: 1.0986 - val_accuracy: 0.3509\n",
      "Epoch 18/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0983 - accuracy: 0.3328\n",
      "Epoch 18: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0983 - accuracy: 0.3328 - val_loss: 1.0986 - val_accuracy: 0.3509\n",
      "Epoch 19/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.1018 - accuracy: 0.3344\n",
      "Epoch 19: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.1018 - accuracy: 0.3344 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 20/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3359\n",
      "Epoch 20: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3359 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 21/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3323\n",
      "Epoch 21: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3323 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 22/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3354\n",
      "Epoch 22: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3354 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 23/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3313\n",
      "Epoch 23: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3313 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 24/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3328\n",
      "Epoch 24: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3328 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 25/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3377\n",
      "Epoch 25: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3377 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 26/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3364\n",
      "Epoch 26: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3364 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 27/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3284\n",
      "Epoch 27: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3284 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 28/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3297\n",
      "Epoch 28: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 761ms/step - loss: 1.0986 - accuracy: 0.3297 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 29/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3331\n",
      "Epoch 29: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3331 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 30/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3367\n",
      "Epoch 30: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3367 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 31/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3398\n",
      "Epoch 31: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3398 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 32/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3302\n",
      "Epoch 32: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3302 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 33/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3300\n",
      "Epoch 33: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3300 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 34/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3367\n",
      "Epoch 34: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3367 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 35/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3289\n",
      "Epoch 35: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3289 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 36/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3349\n",
      "Epoch 36: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3349 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 37/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3336\n",
      "Epoch 37: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3336 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 38/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3305\n",
      "Epoch 38: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3305 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 39/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3326\n",
      "Epoch 39: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3326 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 40/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3318\n",
      "Epoch 40: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3318 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 41/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3336\n",
      "Epoch 41: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3336 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 42/200\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3326\n",
      "Epoch 42: val_accuracy did not improve from 0.37564\n",
      "122/122 [==============================] - 93s 762ms/step - loss: 1.0986 - accuracy: 0.3326 - val_loss: 1.0986 - val_accuracy: 0.3395\n",
      "Epoch 43/200\n",
      " 41/122 [=========>....................] - ETA: 56s - loss: 1.0986 - accuracy: 0.3369"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 21\u001b[0m\n\u001b[1;32m     11\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[1;32m     12\u001b[0m     filepath\u001b[38;5;241m=\u001b[39mcheckpoint_path,\n\u001b[1;32m     13\u001b[0m     save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# ëª¨ë¸ í•™ìŠµ\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# ê²€ì¦ ë°ì´í„° ì¶”ê°€\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ í•™ìŠµ ë¶€ë¶„ ìˆ˜ì •\n",
    "# EarlyStopping ë° ModelCheckpoint ì„¤ì •\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    min_delta=0.001,\n",
    "    patience=100, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint_path = \"GPT4_ë¶„ë¥˜ëª¨ë¸(02).h5\"\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ\n",
    "model.fit(\n",
    "    train_X, train_y, epochs=200, batch_size=32, validation_data=(val_X, val_y),  # ê²€ì¦ ë°ì´í„° ì¶”ê°€\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a07d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_X, test_y, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b085cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c70309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
