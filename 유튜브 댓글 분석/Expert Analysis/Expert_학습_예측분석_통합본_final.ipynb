{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8259873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/ubuntu/anaconda3/lib/python3.10/site-packages (23.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eed87a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ubuntu/anaconda3/lib/python3.10/site-packages (4.24.0)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (0.11.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da5a5a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/ubuntu/anaconda3/lib/python3.10/site-packages (2.15.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (12.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (0.5)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: xxhash in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.18.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (0.19.4)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c0171b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu==2.8.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (23.5.26)\n",
      "Requirement already satisfied: gast>=0.2.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (3.7.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.1.2)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (16.0.6)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (3.20.0)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (65.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (4.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.14.1)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (2.8.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (2.8.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.59.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-gpu==2.8.0) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-gpu==2.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1803d790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.20 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (3.20.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install protobuf==3.20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17938ba9",
   "metadata": {},
   "source": [
    "# 데이터셋 로드 및 구조 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1007b5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-29 15:24:36--  https://raw.githubusercontent.com/ukairia777/finance_sentiment_corpus/main/finance_data.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1319001 (1.3M) [text/plain]\n",
      "Saving to: ‘finance_data.csv’\n",
      "\n",
      "finance_data.csv    100%[===================>]   1.26M  --.-KB/s    in 0.05s   \n",
      "\n",
      "2023-11-29 15:24:36 (27.3 MB/s) - ‘finance_data.csv’ saved [1319001/1319001]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !wget https://raw.githubusercontent.com/ukairia777/finance_sentiment_corpus/main/finance_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "376c1cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cc6a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('finance_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "282e2510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 개수 : 4846\n"
     ]
    }
   ],
   "source": [
    "print('샘플의 개수 :', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19e7d5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>sentence</th>\n",
       "      <th>kor_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran, the company has no plans to...</td>\n",
       "      <td>Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company's updated strategy fo...</td>\n",
       "      <td>2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     labels                                           sentence  \\\n",
       "0   neutral  According to Gran, the company has no plans to...   \n",
       "1   neutral  Technopolis plans to develop in stages an area...   \n",
       "2  negative  The international electronic industry company ...   \n",
       "3  positive  With the new production plant the company woul...   \n",
       "4  positive  According to the company's updated strategy fo...   \n",
       "\n",
       "                                        kor_sentence  \n",
       "0  Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...  \n",
       "1  테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...  \n",
       "2  국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...  \n",
       "3  새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...  \n",
       "4  2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7618b54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>sentence</th>\n",
       "      <th>kor_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>According to Gran, the company has no plans to...</td>\n",
       "      <td>Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>According to the company's updated strategy fo...</td>\n",
       "      <td>2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                           sentence  \\\n",
       "0       0  According to Gran, the company has no plans to...   \n",
       "1       0  Technopolis plans to develop in stages an area...   \n",
       "2       2  The international electronic industry company ...   \n",
       "3       1  With the new production plant the company woul...   \n",
       "4       1  According to the company's updated strategy fo...   \n",
       "\n",
       "                                        kor_sentence  \n",
       "0  Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...  \n",
       "1  테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...  \n",
       "2  국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...  \n",
       "3  새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...  \n",
       "4  2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['labels'] = df['labels'].replace(['neutral', 'positive', 'negative'],[0, 1, 2])\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb7d866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('finance_data.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b28e919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efc3dda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98c533c18434ac5b1916ba5d3bf689d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d8410e43664e53a478e6b67afb7f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818ac183409144c7b5625a83b9b03c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_data = load_dataset(\n",
    "        \"csv\",\n",
    "        data_files={\n",
    "            \"train\": \"finance_data.csv\",\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f71a3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'sentence', 'kor_sentence'],\n",
       "        num_rows: 4846\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4180a49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = all_data['train'].train_test_split(0.2)\n",
    "train_cs = cs[\"train\"]\n",
    "test_cs = cs[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c5c1d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'sentence', 'kor_sentence'],\n",
       "    num_rows: 3876\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bf6cad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'sentence', 'kor_sentence'],\n",
       "    num_rows: 970\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab2a6c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터를 다시 8:2로 분리 후 훈련 데이터와 검증 데이터로 저장\n",
    "cs = train_cs.train_test_split(0.2)\n",
    "train_cs = cs[\"train\"]\n",
    "valid_cs = cs[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "431ad826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'sentence', 'kor_sentence'],\n",
       "    num_rows: 3100\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 데이터\n",
    "train_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66a106e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'sentence', 'kor_sentence'],\n",
       "    num_rows: 776\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 검증 데이터\n",
    "valid_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5cc29d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'sentence', 'kor_sentence'],\n",
       "    num_rows: 970\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터\n",
    "test_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14ea452e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두번째 샘플 출력 : 최초 예상 총액은 1744900 유로, 최종 수상 금액은 1744900 유로였다.\n",
      "두번째 샘플의 레이블 출력 : 0\n"
     ]
    }
   ],
   "source": [
    "print('두번째 샘플 출력 :', train_cs['kor_sentence'][1])\n",
    "print('두번째 샘플의 레이블 출력 :', train_cs['labels'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec574647",
   "metadata": {},
   "source": [
    "# 데이터셋 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b61d0991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "# BERT 사용을 위함\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# for padding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 전처리 및 평가 지표\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af2b63c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터, 검증 데이터, 테스트 데이터에 대해서 `[CLS] 문장 [SEP]` 구조를 만듭니다.\n",
    "\n",
    "train_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', train_cs['kor_sentence']))\n",
    "validation_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', valid_cs['kor_sentence']))\n",
    "test_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', test_cs['kor_sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebcecf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_cs['labels']\n",
    "validation_labels = valid_cs['labels']\n",
    "test_labels = test_cs['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b4f89b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] 고객들은 결제하기 위해 카드를 판독기 앞에서 흔들며 이는 교통 시스템에 사용되는 \"터치 앤 고\" 카드와 비슷하다. [SEP]',\n",
       " '[CLS] 크로스컨트리, 알파인 및 노르딕 워킹 폴, 플로어볼 스틱, 안테나 라돔과 같은 산업용 및 소비재를 위한 고급 복합 제품을 설계, 제조 및 마케팅한다. [SEP]',\n",
       " '[CLS] 노르데아 은행(NDA)과 삼포 은행은 핀란드 부동산 투자 회사인 스폰다(SDA1V)가 100만 유로(USD125.4m)의 국내 채권을 발행할 수 있도록 지원했다고 금요일 밝혔다. [SEP]',\n",
       " '[CLS] 전 세계 20여 개국에 50개 가까운 서비스 지점 네트워크를 더욱 보완하기 위해 일본에서 더 많은 직원을 모집했다. [SEP]',\n",
       " '[CLS] 2009년에 2억 3천 5백만 유로의 순매출액을 기록한 이 그룹은 33개국에서 2,000명 이상의 직원을 고용하고 있다. [SEP]']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0362990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47f4ec2",
   "metadata": {},
   "source": [
    "# Electra 토크나이저를 이용한 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be24c61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6e02b374d0469db173a90c38bcb79f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/263k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ca839967044b70a4c2ca468572c664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/61.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import ElectraTokenizer\n",
    "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6658ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "\n",
    "def data_to_tensor (sentences, labels):\n",
    "  # 정수 인코딩 과정. 각 텍스트를 토큰화한 후에 Vocabulary에 맵핑되는 정수 시퀀스로 변환한다.\n",
    "  # ex) ['안녕하세요'] ==> ['안', '녕', '하세요'] ==> [231, 52, 45]\n",
    "  tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "  # pad_sequences는 패딩을 위한 모듈. 주어진 최대 길이를 위해서 뒤에서 0으로 채워준다.\n",
    "  # ex) [231, 52, 45] ==> [231, 52, 45, 0, 0, 0]\n",
    "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "  attention_masks = []\n",
    "\n",
    "  for seq in input_ids:\n",
    "      seq_mask = [float(i > 0) for i in seq]\n",
    "      attention_masks.append(seq_mask)\n",
    "\n",
    "  tensor_inputs = torch.tensor(input_ids)\n",
    "  tensor_labels = torch.tensor(labels)\n",
    "  tensor_masks = torch.tensor(attention_masks)\n",
    "\n",
    "  return tensor_inputs, tensor_labels, tensor_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14d40d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, train_labels, train_masks = data_to_tensor(train_sentences, train_labels)\n",
    "validation_inputs, validation_labels, validation_masks = data_to_tensor(validation_sentences, validation_labels)\n",
    "test_inputs, test_labels, test_masks = data_to_tensor(test_sentences, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc795711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    2,    23,  4217,  4501,  4629,  4234,  6945,  4007,  4417,  4047,\n",
      "         2969,  4183,  4223,  6312,  7900,  4556,  2024,  4112,  7127,  4073,\n",
      "         6884,  6887,  6427,    18,    20,  4172,  8533,  4192, 18294,  4172,\n",
      "         8533,  4239,  6509,  4398,  4176,    18,     3,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(train_inputs[0])\n",
    "print(train_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69117909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0358463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP]'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7f0c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca1d3a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 크기: 3100\n",
      "검증 데이터의 크기: 776\n",
      "테스트 데이터의 크기: 970\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터의 크기:', len(train_labels))\n",
    "print('검증 데이터의 크기:', len(validation_labels))\n",
    "print('테스트 데이터의 크기:', len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0907bd",
   "metadata": {},
   "source": [
    "# GPU가 정상 셋팅되었는지 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6cb5d46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('No GPU available, using the CPU instead.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45d57354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0f6434",
   "metadata": {},
   "source": [
    "# 모델 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb14f6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb7a6da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import ElectraForSequenceClassification\n",
    "\n",
    "model = ElectraForSequenceClassification.from_pretrained(\n",
    "    \"monologg/koelectra-base-v3-discriminator\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "358022e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(35000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a039e19d",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f04b00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b3a41e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4c5fe85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-6)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2c80e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:30<00:27,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 97.21076613664627 Accuracy: tensor(0.5844, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:57<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 179.32465201616287 Accuracy: tensor(0.5861, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:26,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 72.94436454772949 Accuracy: tensor(0.6956, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 128.3172515630722 Accuracy: tensor(0.7387, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 44.46016299724579 Accuracy: tensor(0.8537, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 82.29570123553276 Accuracy: tensor(0.8523, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 31.374643951654434 Accuracy: tensor(0.8931, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 61.313307628035545 Accuracy: tensor(0.8935, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 25.344293408095837 Accuracy: tensor(0.9137, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 49.02085709199309 Accuracy: tensor(0.9113, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 17.137811925262213 Accuracy: tensor(0.9512, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 35.542063135653734 Accuracy: tensor(0.9458, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 16.06640086695552 Accuracy: tensor(0.9525, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 28.0621085036546 Accuracy: tensor(0.9568, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 9.504472635686398 Accuracy: tensor(0.9750, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 21.6094886995852 Accuracy: tensor(0.9700, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 9.627570260316133 Accuracy: tensor(0.9775, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16.475483139045537 Accuracy: tensor(0.9810, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 7.855872171930969 Accuracy: tensor(0.9825, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13.979101436212659 Accuracy: tensor(0.9832, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 5.354265107773244 Accuracy: tensor(0.9887, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12.32697840128094 Accuracy: tensor(0.9861, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 6.092891167849302 Accuracy: tensor(0.9869, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12.291142050176859 Accuracy: tensor(0.9848, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 3.977579241618514 Accuracy: tensor(0.9906, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.12947318283841 Accuracy: tensor(0.9890, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 4.642630290705711 Accuracy: tensor(0.9900, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8.255922310054302 Accuracy: tensor(0.9894, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 4.20106314914301 Accuracy: tensor(0.9887, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7.135359385982156 Accuracy: tensor(0.9897, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:26,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 2.2118033063597977 Accuracy: tensor(0.9956, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5.277279716916382 Accuracy: tensor(0.9945, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 3.500015781726688 Accuracy: tensor(0.9925, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7.631282634101808 Accuracy: tensor(0.9890, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 2.8420076579786837 Accuracy: tensor(0.9925, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5.567261562682688 Accuracy: tensor(0.9935, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 1.8623927161097527 Accuracy: tensor(0.9969, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.7080767878796905 Accuracy: tensor(0.9961, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 1.913673116825521 Accuracy: tensor(0.9956, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.035715084755793 Accuracy: tensor(0.9971, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 1.6063605837989599 Accuracy: tensor(0.9969, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.633270266233012 Accuracy: tensor(0.9942, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 2.370152189512737 Accuracy: tensor(0.9937, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.2943902051774785 Accuracy: tensor(0.9939, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 1.1914371588500217 Accuracy: tensor(0.9975, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.6124528656946495 Accuracy: tensor(0.9948, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 2.2417718049837276 Accuracy: tensor(0.9950, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.702212000847794 Accuracy: tensor(0.9961, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 1.8278334381757304 Accuracy: tensor(0.9956, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.9541853590635583 Accuracy: tensor(0.9961, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 2.716720261843875 Accuracy: tensor(0.9925, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.4659421967808157 Accuracy: tensor(0.9952, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 2.5557058149715886 Accuracy: tensor(0.9931, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.014461063430645 Accuracy: tensor(0.9948, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 1.7095801020041108 Accuracy: tensor(0.9962, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.027977389341686 Accuracy: tensor(0.9981, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 1.1186249422607943 Accuracy: tensor(0.9981, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.8361357641406357 Accuracy: tensor(0.9968, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 1.7603570224018767 Accuracy: tensor(0.9956, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.2109638697002083 Accuracy: tensor(0.9971, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.8708170194295235 Accuracy: tensor(0.9962, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.7633123506675474 Accuracy: tensor(0.9952, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 1.8560181193170138 Accuracy: tensor(0.9956, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.5729412866639905 Accuracy: tensor(0.9942, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.9797596671851352 Accuracy: tensor(0.9981, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.0424428757978603 Accuracy: tensor(0.9977, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 1.008299752837047 Accuracy: tensor(0.9969, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1377356848097406 Accuracy: tensor(0.9971, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 1.9335772921331227 Accuracy: tensor(0.9944, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.603743296524044 Accuracy: tensor(0.9955, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.35976942646084353 Accuracy: tensor(0.9994, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.42751361138653 Accuracy: tensor(0.9961, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 1.435547968663741 Accuracy: tensor(0.9956, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.089555174461566 Accuracy: tensor(0.9955, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 1.0513850670540705 Accuracy: tensor(0.9969, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.0548849033075385 Accuracy: tensor(0.9968, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.6804765678243712 Accuracy: tensor(0.9994, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3449221643386409 Accuracy: tensor(0.9984, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.5993714582873508 Accuracy: tensor(0.9981, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.631927368347533 Accuracy: tensor(0.9961, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 1.0383315036306158 Accuracy: tensor(0.9975, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5937452703947201 Accuracy: tensor(0.9974, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 1.4968627606285736 Accuracy: tensor(0.9969, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1117993563530035 Accuracy: tensor(0.9977, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 1.6294977582292631 Accuracy: tensor(0.9944, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.923851094674319 Accuracy: tensor(0.9948, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.757092518848367 Accuracy: tensor(0.9975, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8711956421029754 Accuracy: tensor(0.9974, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.4368240591720678 Accuracy: tensor(0.9994, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4314039726159535 Accuracy: tensor(0.9977, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.7997571309097111 Accuracy: tensor(0.9981, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.7055454624351114 Accuracy: tensor(0.9974, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.4432719195901882 Accuracy: tensor(0.9981, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9133487714861985 Accuracy: tensor(0.9984, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.3721532537601888 Accuracy: tensor(0.9987, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.48281964799389243 Accuracy: tensor(0.9994, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.17959332454483956 Accuracy: tensor(1., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5435033631219994 Accuracy: tensor(0.9987, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 100/194 [00:28<00:27,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 0.28852935624308884 Accuracy: tensor(0.9994, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:55<00:00,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.7419208855426405 Accuracy: tensor(0.9968, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for i in range(epochs):\n",
    "  total_loss = 0.0\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  batches = 0\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  for input_ids_batch, attention_masks_batch, y_batch in tqdm(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    y_batch = y_batch.to(device)\n",
    "    y_pred = model(input_ids_batch.to(device),\n",
    "                   attention_mask=attention_masks_batch.to(device))[0]\n",
    "    loss = F.cross_entropy(y_pred, y_batch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "\n",
    "    _, predicted = torch.max(y_pred, 1)\n",
    "    correct += (predicted == y_batch).sum()\n",
    "    total += len(y_batch)\n",
    "\n",
    "    batches += 1\n",
    "    if batches % 100 == 0:\n",
    "      print(\"Batch Loss:\", total_loss, \"Accuracy:\", correct.float() / total)\n",
    "  \n",
    "  losses.append(total_loss)\n",
    "  accuracies.append(correct.float() / total)\n",
    "  print(\"Train Loss:\", total_loss, \"Accuracy:\", correct.float() / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cd1eed9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([179.32465201616287,\n",
       "  128.3172515630722,\n",
       "  82.29570123553276,\n",
       "  61.313307628035545,\n",
       "  49.02085709199309,\n",
       "  35.542063135653734,\n",
       "  28.0621085036546,\n",
       "  21.6094886995852,\n",
       "  16.475483139045537,\n",
       "  13.979101436212659,\n",
       "  12.32697840128094,\n",
       "  12.291142050176859,\n",
       "  9.12947318283841,\n",
       "  8.255922310054302,\n",
       "  7.135359385982156,\n",
       "  5.277279716916382,\n",
       "  7.631282634101808,\n",
       "  5.567261562682688,\n",
       "  4.7080767878796905,\n",
       "  3.035715084755793,\n",
       "  4.633270266233012,\n",
       "  4.2943902051774785,\n",
       "  3.6124528656946495,\n",
       "  3.702212000847794,\n",
       "  2.9541853590635583,\n",
       "  3.4659421967808157,\n",
       "  4.014461063430645,\n",
       "  2.027977389341686,\n",
       "  2.8361357641406357,\n",
       "  2.2109638697002083,\n",
       "  2.7633123506675474,\n",
       "  4.5729412866639905,\n",
       "  2.0424428757978603,\n",
       "  2.1377356848097406,\n",
       "  2.603743296524044,\n",
       "  2.42751361138653,\n",
       "  3.089555174461566,\n",
       "  2.0548849033075385,\n",
       "  1.3449221643386409,\n",
       "  2.631927368347533,\n",
       "  1.5937452703947201,\n",
       "  2.1117993563530035,\n",
       "  2.923851094674319,\n",
       "  1.8711956421029754,\n",
       "  1.4314039726159535,\n",
       "  1.7055454624351114,\n",
       "  0.9133487714861985,\n",
       "  0.48281964799389243,\n",
       "  0.5435033631219994,\n",
       "  1.7419208855426405],\n",
       " [tensor(0.5861, device='cuda:0'),\n",
       "  tensor(0.7387, device='cuda:0'),\n",
       "  tensor(0.8523, device='cuda:0'),\n",
       "  tensor(0.8935, device='cuda:0'),\n",
       "  tensor(0.9113, device='cuda:0'),\n",
       "  tensor(0.9458, device='cuda:0'),\n",
       "  tensor(0.9568, device='cuda:0'),\n",
       "  tensor(0.9700, device='cuda:0'),\n",
       "  tensor(0.9810, device='cuda:0'),\n",
       "  tensor(0.9832, device='cuda:0'),\n",
       "  tensor(0.9861, device='cuda:0'),\n",
       "  tensor(0.9848, device='cuda:0'),\n",
       "  tensor(0.9890, device='cuda:0'),\n",
       "  tensor(0.9894, device='cuda:0'),\n",
       "  tensor(0.9897, device='cuda:0'),\n",
       "  tensor(0.9945, device='cuda:0'),\n",
       "  tensor(0.9890, device='cuda:0'),\n",
       "  tensor(0.9935, device='cuda:0'),\n",
       "  tensor(0.9961, device='cuda:0'),\n",
       "  tensor(0.9971, device='cuda:0'),\n",
       "  tensor(0.9942, device='cuda:0'),\n",
       "  tensor(0.9939, device='cuda:0'),\n",
       "  tensor(0.9948, device='cuda:0'),\n",
       "  tensor(0.9961, device='cuda:0'),\n",
       "  tensor(0.9961, device='cuda:0'),\n",
       "  tensor(0.9952, device='cuda:0'),\n",
       "  tensor(0.9948, device='cuda:0'),\n",
       "  tensor(0.9981, device='cuda:0'),\n",
       "  tensor(0.9968, device='cuda:0'),\n",
       "  tensor(0.9971, device='cuda:0'),\n",
       "  tensor(0.9952, device='cuda:0'),\n",
       "  tensor(0.9942, device='cuda:0'),\n",
       "  tensor(0.9977, device='cuda:0'),\n",
       "  tensor(0.9971, device='cuda:0'),\n",
       "  tensor(0.9955, device='cuda:0'),\n",
       "  tensor(0.9961, device='cuda:0'),\n",
       "  tensor(0.9955, device='cuda:0'),\n",
       "  tensor(0.9968, device='cuda:0'),\n",
       "  tensor(0.9984, device='cuda:0'),\n",
       "  tensor(0.9961, device='cuda:0'),\n",
       "  tensor(0.9974, device='cuda:0'),\n",
       "  tensor(0.9977, device='cuda:0'),\n",
       "  tensor(0.9948, device='cuda:0'),\n",
       "  tensor(0.9974, device='cuda:0'),\n",
       "  tensor(0.9977, device='cuda:0'),\n",
       "  tensor(0.9974, device='cuda:0'),\n",
       "  tensor(0.9984, device='cuda:0'),\n",
       "  tensor(0.9994, device='cuda:0'),\n",
       "  tensor(0.9987, device='cuda:0'),\n",
       "  tensor(0.9968, device='cuda:0')])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses, accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3a6529",
   "metadata": {},
   "source": [
    "# 테스트 데이터에 대한 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e044adc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:05<00:00, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.8340, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "accum_logits, accum_label_ids = [], []\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "for input_ids_batch, attention_masks_batch, y_batch in tqdm(test_loader):\n",
    "    y_batch = y_batch.to(device)\n",
    "    y_pred = model(input_ids_batch.to(device),\n",
    "                   attention_mask=attention_masks_batch.to(device)\n",
    "                  )[0]\n",
    "    _, predicted = torch.max(y_pred, 1)\n",
    "    for b in y_pred.cpu().detach().numpy():\n",
    "        # 3개의 값 중 가장 큰 값을 예측한 인덱스로 결정\n",
    "        # ex) [ 3.5134246  -0.30875662 -2.111316  ] ==> 0\n",
    "        accum_logits.append(np.argmax(b))\n",
    "\n",
    "    for b in y_batch.cpu().detach().numpy():\n",
    "        accum_label_ids.append(b)\n",
    "    \n",
    "    test_correct += (predicted == y_batch).sum()\n",
    "    test_total += len(y_batch)\n",
    "\n",
    "print(\"Accuracy:\", test_correct.float() / test_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58694f80",
   "metadata": {},
   "source": [
    "# 메트릭 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad1292ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(predictions, labels):\n",
    "    y_pred = predictions\n",
    "    y_true = labels\n",
    "\n",
    "    # 사용 가능한 메트릭들을 사용한다.\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1_macro_average = f1_score(y_true=y_true, y_pred=y_pred, average='macro', zero_division=0)\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro', zero_division=0)\n",
    "    f1_weighted_average = f1_score(y_true=y_true, y_pred=y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    # 메트릭 결과에 대해서 리턴\n",
    "    metrics = {'accuracy': accuracy,\n",
    "               'f1_macro': f1_macro_average,\n",
    "               'f1_micro': f1_micro_average,\n",
    "               'f1_weighted': f1_weighted_average}\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "928fd820",
   "metadata": {},
   "outputs": [],
   "source": [
    "accum_logits = np.array(accum_logits)\n",
    "accum_label_ids = np.array(accum_label_ids)\n",
    "results = metrics(accum_logits, accum_label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f85c5d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8340\n",
      "F1 (Macro) Score: 0.8098\n",
      "F1 (Micro) Score: 0.8340\n",
      "F1 (Weighted) Score: 0.8337\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {0:.4f}\".format(results['accuracy']))\n",
    "print(\"F1 (Macro) Score: {0:.4f}\".format(results['f1_macro']))\n",
    "print(\"F1 (Micro) Score: {0:.4f}\".format(results['f1_micro']))\n",
    "print(\"F1 (Weighted) Score: {0:.4f}\".format(results['f1_weighted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "97fd8b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장하기\n",
    "torch.save(model.state_dict(), \"model_expert.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fde743",
   "metadata": {},
   "source": [
    "# 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ce0cb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1d962634",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./4th_Add Data Colums.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d3d27320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>name</th>\n",
       "      <th>theme</th>\n",
       "      <th>동영상 제목</th>\n",
       "      <th>댓글</th>\n",
       "      <th>댓글 작성일</th>\n",
       "      <th>PRO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>메이플</td>\n",
       "      <td>BM</td>\n",
       "      <td>환산10만 루미 장비 및 보스 레이드 [메이플스토리, 뚝이]</td>\n",
       "      <td>환산10만할라면 현질얼마해야되나요</td>\n",
       "      <td>2023-10-07T06:58:56Z</td>\n",
       "      <td>환산10만할라면 현질얼마해야되나요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>메이플</td>\n",
       "      <td>BM</td>\n",
       "      <td>환불사태 전에는 진짜 게임이 게임이 아니었네;;; [메이플스토리]</td>\n",
       "      <td>11:00 채팅창 보니까 쉘로 넘겼다는 말 하나도 없네;;;</td>\n",
       "      <td>2023-06-20T13:11:19Z</td>\n",
       "      <td>채팅창 보니까 쉘로 넘겼다는 말 하나도 없네</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>메이플</td>\n",
       "      <td>BM</td>\n",
       "      <td>환불사태 전에는 진짜 게임이 게임이 아니었네;;; [메이플스토리]</td>\n",
       "      <td>영상제목  ㄹㅇ 웃음벨이네 ㅋㅋㅋㅋㅋㅋㅋ</td>\n",
       "      <td>2023-03-18T01:42:56Z</td>\n",
       "      <td>영상제목  ㄹㅇ 웃음벨이네 ㅋㅋㅋㅋㅋㅋㅋ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>메이플</td>\n",
       "      <td>BM</td>\n",
       "      <td>환불사태 전에는 진짜 게임이 게임이 아니었네;;; [메이플스토리]</td>\n",
       "      <td>그리고 2년지나고 이재야 생겨난 큐브 천장</td>\n",
       "      <td>2023-04-14T10:01:43Z</td>\n",
       "      <td>그리고 2년지나고 이재야 생겨난 큐브 천장</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>메이플</td>\n",
       "      <td>BM</td>\n",
       "      <td>환불사태 전에는 진짜 게임이 게임이 아니었네;;; [메이플스토리]</td>\n",
       "      <td>근데 청묘님 진짜 메이플 어떻게 시작하신거지 ㄷㄷ</td>\n",
       "      <td>2023-03-22T19:55:52Z</td>\n",
       "      <td>근데 청묘님 진짜 메이플 어떻게 시작하신거지 ㄷㄷ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  labels name theme                                동영상 제목  \\\n",
       "0         메이플    BM     환산10만 루미 장비 및 보스 레이드 [메이플스토리, 뚝이]   \n",
       "1         메이플    BM  환불사태 전에는 진짜 게임이 게임이 아니었네;;; [메이플스토리]   \n",
       "2         메이플    BM  환불사태 전에는 진짜 게임이 게임이 아니었네;;; [메이플스토리]   \n",
       "3         메이플    BM  환불사태 전에는 진짜 게임이 게임이 아니었네;;; [메이플스토리]   \n",
       "4         메이플    BM  환불사태 전에는 진짜 게임이 게임이 아니었네;;; [메이플스토리]   \n",
       "\n",
       "                                  댓글                댓글 작성일  \\\n",
       "0                 환산10만할라면 현질얼마해야되나요  2023-10-07T06:58:56Z   \n",
       "1  11:00 채팅창 보니까 쉘로 넘겼다는 말 하나도 없네;;;  2023-06-20T13:11:19Z   \n",
       "2             영상제목  ㄹㅇ 웃음벨이네 ㅋㅋㅋㅋㅋㅋㅋ  2023-03-18T01:42:56Z   \n",
       "3            그리고 2년지나고 이재야 생겨난 큐브 천장  2023-04-14T10:01:43Z   \n",
       "4        근데 청묘님 진짜 메이플 어떻게 시작하신거지 ㄷㄷ  2023-03-22T19:55:52Z   \n",
       "\n",
       "                           PRO  \n",
       "0           환산10만할라면 현질얼마해야되나요  \n",
       "1  채팅창 보니까 쉘로 넘겼다는 말 하나도 없네     \n",
       "2       영상제목  ㄹㅇ 웃음벨이네 ㅋㅋㅋㅋㅋㅋㅋ  \n",
       "3      그리고 2년지나고 이재야 생겨난 큐브 천장  \n",
       "4  근데 청묘님 진짜 메이플 어떻게 시작하신거지 ㄷㄷ  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3c549850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61220 entries, 0 to 61219\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   labels  50161 non-null  object\n",
      " 1   name    61220 non-null  object\n",
      " 2   theme   61220 non-null  object\n",
      " 3   동영상 제목  61220 non-null  object\n",
      " 4   댓글      61220 non-null  object\n",
      " 5   댓글 작성일  61220 non-null  object\n",
      " 6   PRO     61220 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "67bbb642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8bc412d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:89: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-classification\", model=model.cuda(), tokenizer=tokenizer, device=0, max_length=512,\n",
    "                return_all_scores=True, function_to_apply='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2bbd60bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'LABEL_0' : '중립', 'LABEL_1' : '긍정', 'LABEL_2' : '부정'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "194e3d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prediction(text):\n",
    "#   result = pipe(text)\n",
    "\n",
    "#   return [label_dict[result[0]['label']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d20da2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(text):\n",
    "    results = pipe(text)\n",
    "    # 가장 높은 점수를 가진 레이블을 찾습니다.\n",
    "    highest_score_label = max(results[0], key=lambda x: x['score'])['label']\n",
    "    return label_dict[highest_score_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "45dca0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   0%|          | 0/123 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/ubuntu/anaconda3/lib/python3.10/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Predicting: 100%|██████████| 123/123 [09:11<00:00,  4.48s/it]\n"
     ]
    }
   ],
   "source": [
    "# df[\"PRO\"] 열을 500개씩 나누어 처리\n",
    "chunks = np.array_split(df['PRO'], np.ceil(len(df) / 500))\n",
    "\n",
    "# 각 청크에 대해 예측 수행 및 진행 상황을 tqdm으로 표시\n",
    "predicted_labels = []\n",
    "for chunk in tqdm(chunks, desc=\"Predicting\"):\n",
    "    predicted_labels.extend(chunk.apply(prediction))\n",
    "\n",
    "# 예측된 레이블을 새로운 열에 저장\n",
    "df['예측 결과_전문가'] = predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "31123e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "중립    54204\n",
       "부정     4544\n",
       "긍정     2472\n",
       "Name: 예측 결과_전문가, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['예측 결과_전문가'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6936c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>name</th>\n",
       "      <th>theme</th>\n",
       "      <th>동영상 제목</th>\n",
       "      <th>댓글</th>\n",
       "      <th>댓글 작성일</th>\n",
       "      <th>PRO</th>\n",
       "      <th>예측 결과_전문가</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>메이플</td>\n",
       "      <td>BM</td>\n",
       "      <td>환산10만 루미 장비 및 보스 레이드 [메이플스토리, 뚝이]</td>\n",
       "      <td>환산10만할라면 현질얼마해야되나요</td>\n",
       "      <td>2023-10-07T06:58:56Z</td>\n",
       "      <td>환산10만할라면 현질얼마해야되나요</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>메이플</td>\n",
       "      <td>BM</td>\n",
       "      <td>환불사태 전에는 진짜 게임이 게임이 아니었네;;; [메이플스토리]</td>\n",
       "      <td>11:00 채팅창 보니까 쉘로 넘겼다는 말 하나도 없네;;;</td>\n",
       "      <td>2023-06-20T13:11:19Z</td>\n",
       "      <td>채팅창 보니까 쉘로 넘겼다는 말 하나도 없네</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>메이플</td>\n",
       "      <td>BM</td>\n",
       "      <td>환불사태 전에는 진짜 게임이 게임이 아니었네;;; [메이플스토리]</td>\n",
       "      <td>영상제목  ㄹㅇ 웃음벨이네 ㅋㅋㅋㅋㅋㅋㅋ</td>\n",
       "      <td>2023-03-18T01:42:56Z</td>\n",
       "      <td>영상제목  ㄹㅇ 웃음벨이네 ㅋㅋㅋㅋㅋㅋㅋ</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>메이플</td>\n",
       "      <td>BM</td>\n",
       "      <td>환불사태 전에는 진짜 게임이 게임이 아니었네;;; [메이플스토리]</td>\n",
       "      <td>그리고 2년지나고 이재야 생겨난 큐브 천장</td>\n",
       "      <td>2023-04-14T10:01:43Z</td>\n",
       "      <td>그리고 2년지나고 이재야 생겨난 큐브 천장</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>메이플</td>\n",
       "      <td>BM</td>\n",
       "      <td>환불사태 전에는 진짜 게임이 게임이 아니었네;;; [메이플스토리]</td>\n",
       "      <td>근데 청묘님 진짜 메이플 어떻게 시작하신거지 ㄷㄷ</td>\n",
       "      <td>2023-03-22T19:55:52Z</td>\n",
       "      <td>근데 청묘님 진짜 메이플 어떻게 시작하신거지 ㄷㄷ</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61215</th>\n",
       "      <td></td>\n",
       "      <td>리니지</td>\n",
       "      <td>운영</td>\n",
       "      <td>\" 2023 신버전 밸런스 패치 및 몽환의섬 업데이트 \" - [ 2023 리니지 L...</td>\n",
       "      <td>잼있겠다.. ㅠㅠ 나도 하고싶다</td>\n",
       "      <td>2023-06-30T03:48:27Z</td>\n",
       "      <td>잼있겠다    나도 하고싶다</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61216</th>\n",
       "      <td></td>\n",
       "      <td>리니지</td>\n",
       "      <td>운영</td>\n",
       "      <td>\" 2023 신버전 밸런스 패치 및 몽환의섬 업데이트 \" - [ 2023 리니지 L...</td>\n",
       "      <td>저녀석 잡는거 다시보여주세용ㅋㅋ 오랫만에보니재밋넹</td>\n",
       "      <td>2023-06-01T14:26:42Z</td>\n",
       "      <td>저녀석 잡는거 다시보여주세용ㅋㅋ 오랫만에보니재밋넹</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61217</th>\n",
       "      <td></td>\n",
       "      <td>리니지</td>\n",
       "      <td>운영</td>\n",
       "      <td>\" 2023 신버전 밸런스 패치 및 몽환의섬 업데이트 \" - [ 2023 리니지 L...</td>\n",
       "      <td>저도 요정 하고있는데 스톰샷 마법이 클릭하면 안배워지고  자꾸 땅에 떨어지는데 어떻...</td>\n",
       "      <td>2023-07-08T13:04:39Z</td>\n",
       "      <td>저도 요정 하고있는데 스톰샷 마법이 클릭하면 안배워지고  자꾸 땅에 떨어지는데 어떻...</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61218</th>\n",
       "      <td></td>\n",
       "      <td>리니지</td>\n",
       "      <td>운영</td>\n",
       "      <td>\" 2023 신버전 밸런스 패치 및 몽환의섬 업데이트 \" - [ 2023 리니지 L...</td>\n",
       "      <td>형 가디언 잡는거 보여줘...</td>\n",
       "      <td>2023-07-14T09:14:21Z</td>\n",
       "      <td>형 가디언 잡는거 보여줘</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61219</th>\n",
       "      <td></td>\n",
       "      <td>리니지</td>\n",
       "      <td>운영</td>\n",
       "      <td>\" 2023 신버전 밸런스 패치 및 몽환의섬 업데이트 \" - [ 2023 리니지 L...</td>\n",
       "      <td>혹시 이거 하려면 워크3다운받아서 하는건가요??</td>\n",
       "      <td>2023-07-26T14:02:58Z</td>\n",
       "      <td>혹시 이거 하려면 워크3다운받아서 하는건가요</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61220 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels name theme                                             동영상 제목  \\\n",
       "0             메이플    BM                  환산10만 루미 장비 및 보스 레이드 [메이플스토리, 뚝이]   \n",
       "1             메이플    BM               환불사태 전에는 진짜 게임이 게임이 아니었네;;; [메이플스토리]   \n",
       "2             메이플    BM               환불사태 전에는 진짜 게임이 게임이 아니었네;;; [메이플스토리]   \n",
       "3             메이플    BM               환불사태 전에는 진짜 게임이 게임이 아니었네;;; [메이플스토리]   \n",
       "4             메이플    BM               환불사태 전에는 진짜 게임이 게임이 아니었네;;; [메이플스토리]   \n",
       "...      ...  ...   ...                                                ...   \n",
       "61215         리니지    운영  \" 2023 신버전 밸런스 패치 및 몽환의섬 업데이트 \" - [ 2023 리니지 L...   \n",
       "61216         리니지    운영  \" 2023 신버전 밸런스 패치 및 몽환의섬 업데이트 \" - [ 2023 리니지 L...   \n",
       "61217         리니지    운영  \" 2023 신버전 밸런스 패치 및 몽환의섬 업데이트 \" - [ 2023 리니지 L...   \n",
       "61218         리니지    운영  \" 2023 신버전 밸런스 패치 및 몽환의섬 업데이트 \" - [ 2023 리니지 L...   \n",
       "61219         리니지    운영  \" 2023 신버전 밸런스 패치 및 몽환의섬 업데이트 \" - [ 2023 리니지 L...   \n",
       "\n",
       "                                                      댓글  \\\n",
       "0                                     환산10만할라면 현질얼마해야되나요   \n",
       "1                      11:00 채팅창 보니까 쉘로 넘겼다는 말 하나도 없네;;;   \n",
       "2                                 영상제목  ㄹㅇ 웃음벨이네 ㅋㅋㅋㅋㅋㅋㅋ   \n",
       "3                                그리고 2년지나고 이재야 생겨난 큐브 천장   \n",
       "4                            근데 청묘님 진짜 메이플 어떻게 시작하신거지 ㄷㄷ   \n",
       "...                                                  ...   \n",
       "61215                                  잼있겠다.. ㅠㅠ 나도 하고싶다   \n",
       "61216                        저녀석 잡는거 다시보여주세용ㅋㅋ 오랫만에보니재밋넹   \n",
       "61217  저도 요정 하고있는데 스톰샷 마법이 클릭하면 안배워지고  자꾸 땅에 떨어지는데 어떻...   \n",
       "61218                                   형 가디언 잡는거 보여줘...   \n",
       "61219                         혹시 이거 하려면 워크3다운받아서 하는건가요??   \n",
       "\n",
       "                     댓글 작성일  \\\n",
       "0      2023-10-07T06:58:56Z   \n",
       "1      2023-06-20T13:11:19Z   \n",
       "2      2023-03-18T01:42:56Z   \n",
       "3      2023-04-14T10:01:43Z   \n",
       "4      2023-03-22T19:55:52Z   \n",
       "...                     ...   \n",
       "61215  2023-06-30T03:48:27Z   \n",
       "61216  2023-06-01T14:26:42Z   \n",
       "61217  2023-07-08T13:04:39Z   \n",
       "61218  2023-07-14T09:14:21Z   \n",
       "61219  2023-07-26T14:02:58Z   \n",
       "\n",
       "                                                     PRO 예측 결과_전문가  \n",
       "0                                     환산10만할라면 현질얼마해야되나요        중립  \n",
       "1                            채팅창 보니까 쉘로 넘겼다는 말 하나도 없네           중립  \n",
       "2                                 영상제목  ㄹㅇ 웃음벨이네 ㅋㅋㅋㅋㅋㅋㅋ        중립  \n",
       "3                                그리고 2년지나고 이재야 생겨난 큐브 천장        중립  \n",
       "4                            근데 청묘님 진짜 메이플 어떻게 시작하신거지 ㄷㄷ        중립  \n",
       "...                                                  ...       ...  \n",
       "61215                                    잼있겠다    나도 하고싶다        중립  \n",
       "61216                        저녀석 잡는거 다시보여주세용ㅋㅋ 오랫만에보니재밋넹        중립  \n",
       "61217  저도 요정 하고있는데 스톰샷 마법이 클릭하면 안배워지고  자꾸 땅에 떨어지는데 어떻...        중립  \n",
       "61218                                   형 가디언 잡는거 보여줘           중립  \n",
       "61219                         혹시 이거 하려면 워크3다운받아서 하는건가요          중립  \n",
       "\n",
       "[61220 rows x 8 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0a1f4ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('231201_expert_final.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ac02bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f9698d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
