{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/ubuntu/anaconda3/lib/python3.10/site-packages (22.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.3.1\n",
      "    Uninstalling pip-22.3.1:\n",
      "      Successfully uninstalled pip-22.3.1\n",
      "Successfully installed pip-23.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ubuntu/anaconda3/lib/python3.10/site-packages (4.24.0)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (0.11.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (12.0.0)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading pyarrow_hotfix-0.5-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (4.64.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting huggingface-hub>=0.18.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (28 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.5-py3-none-any.whl (7.8 kB)\n",
      "Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.7/225.7 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.7/300.7 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, pyarrow-hotfix, multidict, fsspec, frozenlist, dill, async-timeout, yarl, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.11.0\n",
      "    Uninstalling fsspec-2022.11.0:\n",
      "      Successfully uninstalled fsspec-2022.11.0\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.6\n",
      "    Uninstalling dill-0.3.6:\n",
      "      Successfully uninstalled dill-0.3.6\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.10.1\n",
      "    Uninstalling huggingface-hub-0.10.1:\n",
      "      Successfully uninstalled huggingface-hub-0.10.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.4.1 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.4.1 requires pyqtwebengine<5.16, which is not installed.\n",
      "distributed 2022.7.0 requires tornado<6.2,>=6.0.3, but you have tornado 6.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiohttp-3.9.0 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.15.0 dill-0.3.7 frozenlist-1.4.0 fsspec-2023.10.0 huggingface-hub-0.19.4 multidict-6.0.4 multiprocess-0.70.15 pyarrow-hotfix-0.5 xxhash-3.4.1 yarl-1.9.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu==2.8.0\n",
      "  Downloading tensorflow_gpu-2.8.0-cp310-cp310-manylinux2010_x86_64.whl (497.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m875.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=0.4.0 (from tensorflow-gpu==2.8.0)\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-gpu==2.8.0)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=1.12 (from tensorflow-gpu==2.8.0)\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast>=0.2.1 (from tensorflow-gpu==2.8.0)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-gpu==2.8.0)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (3.7.0)\n",
      "Collecting keras-preprocessing>=1.1.1 (from tensorflow-gpu==2.8.0)\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=9.0.1 (from tensorflow-gpu==2.8.0)\n",
      "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.23.5)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-gpu==2.8.0)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf>=3.9.2 (from tensorflow-gpu==2.8.0)\n",
      "  Downloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (65.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-gpu==2.8.0)\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (4.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.14.1)\n",
      "Collecting tensorboard<2.9,>=2.8 (from tensorflow-gpu==2.8.0)\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tf-estimator-nightly==2.8.0.dev2021122109 (from tensorflow-gpu==2.8.0)\n",
      "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting keras<2.9,>=2.8.0rc0 (from tensorflow-gpu==2.8.0)\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-gpu==2.8.0)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (14 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-gpu==2.8.0)\n",
      "  Downloading grpcio-1.59.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-gpu==2.8.0) (0.38.4)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0)\n",
      "  Downloading google_auth-2.23.4-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0)\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.28.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0)\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0)\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.2.2)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0)\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0)\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading grpcio-1.59.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.34.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.23.4-py2.py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.3/183.3 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Installing collected packages: tf-estimator-nightly, tensorboard-plugin-wit, libclang, keras, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, rsa, protobuf, opt-einsum, oauthlib, keras-preprocessing, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow-gpu\n",
      "Successfully installed absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.2 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.23.4 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.59.3 keras-2.8.0 keras-preprocessing-1.1.2 libclang-16.0.6 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.25.1 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-gpu-2.8.0 tensorflow-io-gcs-filesystem-0.34.0 termcolor-2.3.0 tf-estimator-nightly-2.8.0.dev2021122109\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-gpu==2.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf==3.20\n",
      "  Downloading protobuf-3.20.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.1\n",
      "    Uninstalling protobuf-4.25.1:\n",
      "      Successfully uninstalled protobuf-4.25.1\n",
      "Successfully installed protobuf-3.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install protobuf==3.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Qww_V4GzhgoS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import re\n",
    "import os\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wC6Rnt6iCxB",
    "outputId": "23d687d4-646b-4afa-f8ac-e5ce7a210c67"
   },
   "outputs": [],
   "source": [
    "# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/finance_sentiment_corpus/main/finance_data.csv\", filename=\"finance_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1aP870z3iRc_",
    "outputId": "84b0007f-0732-4872-e647-d01c5334efe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 수 : 5275\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('train data_self.csv')\n",
    "print('총 샘플의 수 :',len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "9eEIdsG4iZYf",
    "outputId": "222a027b-fd6c-4820-c662-7cb50f59377e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>동영상 제목</th>\n",
       "      <th>댓글</th>\n",
       "      <th>댓글 작성일</th>\n",
       "      <th>PRO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>휘재가 추천하는 PC MMORPG TOP 10 / 메난민 필독 영상</td>\n",
       "      <td>이야 오랜만에 이영상을다시보니 휘재는 섭종예언자인가 ???????????</td>\n",
       "      <td>2023-02-26T12:26:21Z</td>\n",
       "      <td>이야 오랜만에 이영상을다시보니 휘재는 섭종예언자인가</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>훈민정음을 스킬로 사용하는 국산 게임! 검은사막 아침의 나라 &amp; 각성 우사 리뷰</td>\n",
       "      <td>이쁜쓰레기 각성우사 ㅠㅠ</td>\n",
       "      <td>2023-06-10T18:09:59Z</td>\n",
       "      <td>이쁜쓰레기 각성우사 ㅠㅠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>효율적인 과금</td>\n",
       "      <td>그렇게 먼 미래에 마누라는 25강 장기백을 사달라고 하게되는데...</td>\n",
       "      <td>2023-06-05T18:01:09Z</td>\n",
       "      <td>그렇게 먼 미래에 마누라는 25강 장기백을 사달라고 하게되는데</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>환상이 이루어지는 나라로 당신을 초대합니다. 제2의 나라: Cross Worlds</td>\n",
       "      <td>USZW8L</td>\n",
       "      <td>2021-06-09T18:51:34Z</td>\n",
       "      <td>USZW8L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>환상이 이루어지는 나라로 당신을 초대합니다. 제2의 나라: Cross Worlds</td>\n",
       "      <td>MMRPRM 친구코드 부탁드려요☺️</td>\n",
       "      <td>2021-06-09T03:02:21Z</td>\n",
       "      <td>MMRPRM 친구코드 부탁드려요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5270</th>\n",
       "      <td>2</td>\n",
       "      <td>넷마블에서 신의탑IP로 게임을 출시한다고? - 신의탑:새로운세계. 이거 믿어도 될까...</td>\n",
       "      <td>아직도 가로게임을 추구하시네요;; 그만큼 모바일게임에 대해 지식이 없다는 말입니다....</td>\n",
       "      <td>2023-07-21T15:47:16Z</td>\n",
       "      <td>아직도 가로게임을 추구하시네요   그만큼 모바일게임에 대해 지식이 없다는 말입니다 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5271</th>\n",
       "      <td>2</td>\n",
       "      <td>코드네임: EZ - S1O1 시즌 트레일러 | VEILED EXPERTS</td>\n",
       "      <td>게임이 시발 사람이 없으면 없는 대로 매칭을 시켜 주던가 아니면 ai모드를 따로 쳐...</td>\n",
       "      <td>2023-10-21T07:54:00Z</td>\n",
       "      <td>게임이 시발 사람이 없으면 없는 대로 매칭을 시켜 주던가 아니면 ai모드를 따로 쳐...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5272</th>\n",
       "      <td>2</td>\n",
       "      <td>리니지에서 성 먹으면 진짜 떼돈 버나요? 핵과금러 총집합하는 공성전을 간접 체험해 보자</td>\n",
       "      <td>옛날이야기야?\\n 전에는 진짜 그만큼 벌었다는 소리네...</td>\n",
       "      <td>2023-08-19T03:04:58Z</td>\n",
       "      <td>옛날이야기야   전에는 진짜 그만큼 벌었다는 소리네</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5273</th>\n",
       "      <td>2</td>\n",
       "      <td>패치 후 피파를 떠납니다!... 피파4</td>\n",
       "      <td>발음 ㅈ같이하는건 컨셉이죠?</td>\n",
       "      <td>2023-06-28T15:53:12Z</td>\n",
       "      <td>발음 ㅈ같이하는건 컨셉이죠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5274</th>\n",
       "      <td>2</td>\n",
       "      <td>초월적 힘, 6차 전직 | 메이플스토리 NEW AGE</td>\n",
       "      <td>그만하라면 그만할게여.. 𐑧비𐑧제𐑧이𐑧뱃𐑧 단언컨데 재미는 보장함</td>\n",
       "      <td>2023-10-01T10:45:46Z</td>\n",
       "      <td>그만하라면 그만할게여    비 제 이 뱃  단언컨데 재미는 보장함</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5275 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     labels                                             동영상 제목  \\\n",
       "0         0              휘재가 추천하는 PC MMORPG TOP 10 / 메난민 필독 영상   \n",
       "1         0       훈민정음을 스킬로 사용하는 국산 게임! 검은사막 아침의 나라 & 각성 우사 리뷰   \n",
       "2         0                                            효율적인 과금   \n",
       "3         0      환상이 이루어지는 나라로 당신을 초대합니다. 제2의 나라: Cross Worlds   \n",
       "4         0      환상이 이루어지는 나라로 당신을 초대합니다. 제2의 나라: Cross Worlds   \n",
       "...     ...                                                ...   \n",
       "5270      2  넷마블에서 신의탑IP로 게임을 출시한다고? - 신의탑:새로운세계. 이거 믿어도 될까...   \n",
       "5271      2           코드네임: EZ - S1O1 시즌 트레일러 | VEILED EXPERTS   \n",
       "5272      2   리니지에서 성 먹으면 진짜 떼돈 버나요? 핵과금러 총집합하는 공성전을 간접 체험해 보자   \n",
       "5273      2                              패치 후 피파를 떠납니다!... 피파4   \n",
       "5274      2                      초월적 힘, 6차 전직 | 메이플스토리 NEW AGE   \n",
       "\n",
       "                                                     댓글                댓글 작성일  \\\n",
       "0              이야 오랜만에 이영상을다시보니 휘재는 섭종예언자인가 ???????????  2023-02-26T12:26:21Z   \n",
       "1                                         이쁜쓰레기 각성우사 ㅠㅠ  2023-06-10T18:09:59Z   \n",
       "2                 그렇게 먼 미래에 마누라는 25강 장기백을 사달라고 하게되는데...  2023-06-05T18:01:09Z   \n",
       "3                                                USZW8L  2021-06-09T18:51:34Z   \n",
       "4                                   MMRPRM 친구코드 부탁드려요☺️  2021-06-09T03:02:21Z   \n",
       "...                                                 ...                   ...   \n",
       "5270  아직도 가로게임을 추구하시네요;; 그만큼 모바일게임에 대해 지식이 없다는 말입니다....  2023-07-21T15:47:16Z   \n",
       "5271  게임이 시발 사람이 없으면 없는 대로 매칭을 시켜 주던가 아니면 ai모드를 따로 쳐...  2023-10-21T07:54:00Z   \n",
       "5272                   옛날이야기야?\\n 전에는 진짜 그만큼 벌었다는 소리네...  2023-08-19T03:04:58Z   \n",
       "5273                                    발음 ㅈ같이하는건 컨셉이죠?  2023-06-28T15:53:12Z   \n",
       "5274               그만하라면 그만할게여.. 𐑧비𐑧제𐑧이𐑧뱃𐑧 단언컨데 재미는 보장함  2023-10-01T10:45:46Z   \n",
       "\n",
       "                                                    PRO  \n",
       "0              이야 오랜만에 이영상을다시보니 휘재는 섭종예언자인가              \n",
       "1                                         이쁜쓰레기 각성우사 ㅠㅠ  \n",
       "2                 그렇게 먼 미래에 마누라는 25강 장기백을 사달라고 하게되는데     \n",
       "3                                                USZW8L  \n",
       "4                                   MMRPRM 친구코드 부탁드려요    \n",
       "...                                                 ...  \n",
       "5270  아직도 가로게임을 추구하시네요   그만큼 모바일게임에 대해 지식이 없다는 말입니다 ...  \n",
       "5271  게임이 시발 사람이 없으면 없는 대로 매칭을 시켜 주던가 아니면 ai모드를 따로 쳐...  \n",
       "5272                    옛날이야기야   전에는 진짜 그만큼 벌었다는 소리네     \n",
       "5273                                    발음 ㅈ같이하는건 컨셉이죠   \n",
       "5274               그만하라면 그만할게여    비 제 이 뱃  단언컨데 재미는 보장함  \n",
       "\n",
       "[5275 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "t9XJj_iziaYh",
    "outputId": "eabc6763-3d47-4b01-8b70-2e2cf1888a79"
   },
   "outputs": [],
   "source": [
    "# data['labels'] = data['labels'].replace(['neutral', 'positive', 'negative'],[0, 1, 2])\n",
    "# data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "RNyrW0ynix3O"
   },
   "outputs": [],
   "source": [
    "# '동영상 제목', '댓글 작성일', '댓글' 컬럼 삭제\n",
    "data = data.drop(['동영상 제목', '댓글 작성일', '댓글'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "5Pz9t4U2i35Q",
    "outputId": "e950d978-63d4-49d7-c6e7-f55fe8f251e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>PRO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>이야 오랜만에 이영상을다시보니 휘재는 섭종예언자인가</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>이쁜쓰레기 각성우사 ㅠㅠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>그렇게 먼 미래에 마누라는 25강 장기백을 사달라고 하게되는데</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>USZW8L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>MMRPRM 친구코드 부탁드려요</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  labels                                       PRO\n",
       "0      0  이야 오랜만에 이영상을다시보니 휘재는 섭종예언자인가            \n",
       "1      0                             이쁜쓰레기 각성우사 ㅠㅠ\n",
       "2      0     그렇게 먼 미래에 마누라는 25강 장기백을 사달라고 하게되는데   \n",
       "3      0                                    USZW8L\n",
       "4      0                       MMRPRM 친구코드 부탁드려요  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>kor_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>이야 오랜만에 이영상을다시보니 휘재는 섭종예언자인가</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>이쁜쓰레기 각성우사 ㅠㅠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>그렇게 먼 미래에 마누라는 25강 장기백을 사달라고 하게되는데</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>USZW8L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>MMRPRM 친구코드 부탁드려요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5270</th>\n",
       "      <td>2</td>\n",
       "      <td>아직도 가로게임을 추구하시네요   그만큼 모바일게임에 대해 지식이 없다는 말입니다 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5271</th>\n",
       "      <td>2</td>\n",
       "      <td>게임이 시발 사람이 없으면 없는 대로 매칭을 시켜 주던가 아니면 ai모드를 따로 쳐...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5272</th>\n",
       "      <td>2</td>\n",
       "      <td>옛날이야기야   전에는 진짜 그만큼 벌었다는 소리네</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5273</th>\n",
       "      <td>2</td>\n",
       "      <td>발음 ㅈ같이하는건 컨셉이죠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5274</th>\n",
       "      <td>2</td>\n",
       "      <td>그만하라면 그만할게여    비 제 이 뱃  단언컨데 재미는 보장함</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5275 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     labels                                       kor_sentence\n",
       "0         0           이야 오랜만에 이영상을다시보니 휘재는 섭종예언자인가            \n",
       "1         0                                      이쁜쓰레기 각성우사 ㅠㅠ\n",
       "2         0              그렇게 먼 미래에 마누라는 25강 장기백을 사달라고 하게되는데   \n",
       "3         0                                             USZW8L\n",
       "4         0                                MMRPRM 친구코드 부탁드려요  \n",
       "...     ...                                                ...\n",
       "5270      2  아직도 가로게임을 추구하시네요   그만큼 모바일게임에 대해 지식이 없다는 말입니다 ...\n",
       "5271      2  게임이 시발 사람이 없으면 없는 대로 매칭을 시켜 주던가 아니면 ai모드를 따로 쳐...\n",
       "5272      2                    옛날이야기야   전에는 진짜 그만큼 벌었다는 소리네   \n",
       "5273      2                                    발음 ㅈ같이하는건 컨셉이죠 \n",
       "5274      2               그만하라면 그만할게여    비 제 이 뱃  단언컨데 재미는 보장함\n",
       "\n",
       "[5275 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'PRO' 칼럼을 'kor_sentence'로 변경\n",
    "data.rename(columns={'PRO': 'kor_sentence'}, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b7EW631ui4OA",
    "outputId": "b1e1a6ed-f426-4586-cd9b-20b7af122dab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5275 entries, 0 to 5274\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   labels        5275 non-null   object\n",
      " 1   kor_sentence  5275 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 82.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     5275\n",
       "unique       4\n",
       "top          0\n",
       "freq      1700\n",
       "Name: labels, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['labels'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1700\n",
       "2    1700\n",
       "1    1700\n",
       "      175\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈 문자열과 숫자로 변환할 수 없는 값을 NaN으로 대체\n",
    "data['labels'] = pd.to_numeric(data['labels'], errors='coerce')\n",
    "\n",
    "# NaN 값을 원하는 기본값으로 대체\n",
    "data['labels'].fillna(10, inplace=True)\n",
    "\n",
    "# 최종적으로 int로 형변환\n",
    "data['labels'] = data['labels'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1700\n",
       "2     1700\n",
       "1     1700\n",
       "10     175\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>kor_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>이야 오랜만에 이영상을다시보니 휘재는 섭종예언자인가</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>이쁜쓰레기 각성우사 ㅠㅠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>그렇게 먼 미래에 마누라는 25강 장기백을 사달라고 하게되는데</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>USZW8L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>MMRPRM 친구코드 부탁드려요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5270</th>\n",
       "      <td>2</td>\n",
       "      <td>아직도 가로게임을 추구하시네요   그만큼 모바일게임에 대해 지식이 없다는 말입니다 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5271</th>\n",
       "      <td>2</td>\n",
       "      <td>게임이 시발 사람이 없으면 없는 대로 매칭을 시켜 주던가 아니면 ai모드를 따로 쳐...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5272</th>\n",
       "      <td>2</td>\n",
       "      <td>옛날이야기야   전에는 진짜 그만큼 벌었다는 소리네</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5273</th>\n",
       "      <td>2</td>\n",
       "      <td>발음 ㅈ같이하는건 컨셉이죠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5274</th>\n",
       "      <td>2</td>\n",
       "      <td>그만하라면 그만할게여    비 제 이 뱃  단언컨데 재미는 보장함</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                       kor_sentence\n",
       "0          0           이야 오랜만에 이영상을다시보니 휘재는 섭종예언자인가            \n",
       "1          0                                      이쁜쓰레기 각성우사 ㅠㅠ\n",
       "2          0              그렇게 먼 미래에 마누라는 25강 장기백을 사달라고 하게되는데   \n",
       "3          0                                             USZW8L\n",
       "4          0                                MMRPRM 친구코드 부탁드려요  \n",
       "...      ...                                                ...\n",
       "5270       2  아직도 가로게임을 추구하시네요   그만큼 모바일게임에 대해 지식이 없다는 말입니다 ...\n",
       "5271       2  게임이 시발 사람이 없으면 없는 대로 매칭을 시켜 주던가 아니면 ai모드를 따로 쳐...\n",
       "5272       2                    옛날이야기야   전에는 진짜 그만큼 벌었다는 소리네   \n",
       "5273       2                                    발음 ㅈ같이하는건 컨셉이죠 \n",
       "5274       2               그만하라면 그만할게여    비 제 이 뱃  단언컨데 재미는 보장함\n",
       "\n",
       "[5100 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data['labels'] != 10]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JkvjJa1Ji7Eo",
    "outputId": "ab2e76cb-c617-45c4-da22-683985e79108"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측값 여부 : False\n"
     ]
    }
   ],
   "source": [
    "print('결측값 여부 :',data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UoAyW4Lii8xX",
    "outputId": "df771080-bc2f-414f-a73b-0f15a213eb13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kor_sentence 열의 유니크한 값 : 4904\n"
     ]
    }
   ],
   "source": [
    "print('kor_sentence 열의 유니크한 값 :',data['kor_sentence'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "cks_QRBfjKBU"
   },
   "outputs": [],
   "source": [
    "duplicate = data[data.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "ZwkZ7T0BjL7d",
    "outputId": "71c8b1dc-5b31-40e3-8beb-7818f7ca8d89"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>kor_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>이제 바연 안할꺼예여 ㅠㅠ 보고싶어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>민교씨 이제 그마가자 승오바 올인 박는다  비 제 이 뱃</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>땅호리 슈퍼 꾸랙 플레이 개재밋넼ㅋㅋㅋ 배  팅하고 보니까 응원하게되네  롤 뱃</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0</td>\n",
       "      <td>ㅋㅋㅋㅋㅋㅋㅋㅋ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0</td>\n",
       "      <td>만렙이 999였다지요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5250</th>\n",
       "      <td>2</td>\n",
       "      <td>의상펄질만 하고 현질 안해도 300공 넘김 갓 겜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5257</th>\n",
       "      <td>2</td>\n",
       "      <td>근데 저때 현질했으면 정무형이 불쌍하게 여겨서 금카팩같은거 뽑아서 대박 나지않았을까</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5261</th>\n",
       "      <td>2</td>\n",
       "      <td>하   3년동안 키운계정 페이스북연동이였는데 제가 한동안 공부에 집중하느라 생각도 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5266</th>\n",
       "      <td>2</td>\n",
       "      <td>진심 ㅈ같은게 댓글들 보면 모배가 어쩌구 컴배가 저쩌구 이러는거 역겨움 뭐 모배 지...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5271</th>\n",
       "      <td>2</td>\n",
       "      <td>게임이 시발 사람이 없으면 없는 대로 매칭을 시켜 주던가 아니면 ai모드를 따로 쳐...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                       kor_sentence\n",
       "18         0                             이제 바연 안할꺼예여 ㅠㅠ 보고싶어요  \n",
       "21         0                   민교씨 이제 그마가자 승오바 올인 박는다  비 제 이 뱃 \n",
       "24         0      땅호리 슈퍼 꾸랙 플레이 개재밋넼ㅋㅋㅋ 배  팅하고 보니까 응원하게되네  롤 뱃 \n",
       "73         0                                           ㅋㅋㅋㅋㅋㅋㅋㅋ\n",
       "190        0                                       만렙이 999였다지요 \n",
       "...      ...                                                ...\n",
       "5250       2                        의상펄질만 하고 현질 안해도 300공 넘김 갓 겜\n",
       "5257       2    근데 저때 현질했으면 정무형이 불쌍하게 여겨서 금카팩같은거 뽑아서 대박 나지않았을까 \n",
       "5261       2  하   3년동안 키운계정 페이스북연동이였는데 제가 한동안 공부에 집중하느라 생각도 ...\n",
       "5266       2  진심 ㅈ같은게 댓글들 보면 모배가 어쩌구 컴배가 저쩌구 이러는거 역겨움 뭐 모배 지...\n",
       "5271       2  게임이 시발 사람이 없으면 없는 대로 매칭을 시켜 주던가 아니면 ai모드를 따로 쳐...\n",
       "\n",
       "[183 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "prnB1Yg5jBt2",
    "outputId": "b0e72b35-ed7d-4c31-e781-5378cff76361"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 수 : 4904\n"
     ]
    }
   ],
   "source": [
    "# 중복 제거\n",
    "data.drop_duplicates(subset=['kor_sentence'], inplace=True)\n",
    "print('총 샘플의 수 :',len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "StnulPDqjuKX",
    "outputId": "1d679065-7cc0-433d-91be-fe7464ace638"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['labels'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dP_BFHlojwiN",
    "outputId": "c081665b-4f69-4d15-b02e-9566bfc57bd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블의 분포\n",
      "   labels  count\n",
      "0       0   1627\n",
      "1       1   1662\n",
      "2       2   1615\n"
     ]
    }
   ],
   "source": [
    "print('레이블의 분포')\n",
    "print(data.groupby('labels').size().reset_index(name='count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CfQdxYqMj3o8",
    "outputId": "e3adf4ef-9e82-4ac7-a624-6fe56f9c3df7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중립의 비율 = 33.177%\n",
      "긍정의 비율 = 33.891%\n",
      "부정의 비율 = 32.932%\n"
     ]
    }
   ],
   "source": [
    "print(f'중립의 비율 = {round(data[\"labels\"].value_counts()[0]/len(data) * 100,3)}%')\n",
    "print(f'긍정의 비율 = {round(data[\"labels\"].value_counts()[1]/len(data) * 100,3)}%')\n",
    "print(f'부정의 비율 = {round(data[\"labels\"].value_counts()[2]/len(data) * 100,3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "jKKmVrDRk46e",
    "outputId": "07e6e8cc-7760-484b-eb3b-087ae964cb51"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>kor_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>이야 오랜만에 이영상을다시보니 휘재는 섭종예언자인가</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>이쁜쓰레기 각성우사 ㅠㅠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>그렇게 먼 미래에 마누라는 25강 장기백을 사달라고 하게되는데</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>USZW8L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>MMRPRM 친구코드 부탁드려요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5269</th>\n",
       "      <td>2</td>\n",
       "      <td>매구 우사 아무리 너프해봐라ㅋㅋㅋ     신캐로 갈아타면 그만이야</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5270</th>\n",
       "      <td>2</td>\n",
       "      <td>아직도 가로게임을 추구하시네요   그만큼 모바일게임에 대해 지식이 없다는 말입니다 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5272</th>\n",
       "      <td>2</td>\n",
       "      <td>옛날이야기야   전에는 진짜 그만큼 벌었다는 소리네</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5273</th>\n",
       "      <td>2</td>\n",
       "      <td>발음 ㅈ같이하는건 컨셉이죠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5274</th>\n",
       "      <td>2</td>\n",
       "      <td>그만하라면 그만할게여    비 제 이 뱃  단언컨데 재미는 보장함</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4904 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                       kor_sentence\n",
       "0          0           이야 오랜만에 이영상을다시보니 휘재는 섭종예언자인가            \n",
       "1          0                                      이쁜쓰레기 각성우사 ㅠㅠ\n",
       "2          0              그렇게 먼 미래에 마누라는 25강 장기백을 사달라고 하게되는데   \n",
       "3          0                                             USZW8L\n",
       "4          0                                MMRPRM 친구코드 부탁드려요  \n",
       "...      ...                                                ...\n",
       "5269       2              매구 우사 아무리 너프해봐라ㅋㅋㅋ     신캐로 갈아타면 그만이야 \n",
       "5270       2  아직도 가로게임을 추구하시네요   그만큼 모바일게임에 대해 지식이 없다는 말입니다 ...\n",
       "5272       2                    옛날이야기야   전에는 진짜 그만큼 벌었다는 소리네   \n",
       "5273       2                                    발음 ㅈ같이하는건 컨셉이죠 \n",
       "5274       2               그만하라면 그만할게여    비 제 이 뱃  단언컨데 재미는 보장함\n",
       "\n",
       "[4904 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l8foVC2rkJtF",
    "outputId": "e5526eb9-1b41-4bd4-fc85-752670824790"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "본문의 개수: 4904\n",
      "레이블의 개수: 4904\n"
     ]
    }
   ],
   "source": [
    "X_data = data['kor_sentence']\n",
    "y_data = data['labels']\n",
    "print('본문의 개수: {}'.format(len(X_data)))\n",
    "print('레이블의 개수: {}'.format(len(y_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "qmFecWmSkHiu"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=0, stratify=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HiPJQoBql2T_",
    "outputId": "012118ee-7e39-4d9a-fe40-0aad31cc89d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 개수 : 3923\n",
      "테스트 샘플의 개수 : 981\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플의 개수 :', len(X_train))\n",
    "print('테스트 샘플의 개수 :', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-gTg1Z2kYK2",
    "outputId": "c2162a05-dac7-47b5-d30d-5b9cb91a538e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------훈련 데이터의 비율-----------\n",
      "중립 = 33.189%\n",
      "긍정 = 33.877%\n",
      "부정 = 32.934%\n"
     ]
    }
   ],
   "source": [
    "print('--------훈련 데이터의 비율-----------')\n",
    "print(f'중립 = {round(y_train.value_counts()[0]/len(y_train) * 100,3)}%')\n",
    "print(f'긍정 = {round(y_train.value_counts()[1]/len(y_train) * 100,3)}%')\n",
    "print(f'부정 = {round(y_train.value_counts()[2]/len(y_train) * 100,3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6E_XYZIVkcP3",
    "outputId": "2aae17b0-fe59-46e9-b2dc-0287d03e63a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------테스트 데이터의 비율-----------\n",
      "중립 = 33.129%\n",
      "긍정 = 33.945%\n",
      "부정 = 32.926%\n"
     ]
    }
   ],
   "source": [
    "print('--------테스트 데이터의 비율-----------')\n",
    "print(f'중립 = {round(y_test.value_counts()[0]/len(y_test) * 100,3)}%')\n",
    "print(f'긍정 = {round(y_test.value_counts()[1]/len(y_test) * 100,3)}%')\n",
    "print(f'부정 = {round(y_test.value_counts()[2]/len(y_test) * 100,3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "WqLBfWmypQ6Y"
   },
   "outputs": [],
   "source": [
    "max_seq_len = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "f54e09e1acae4d28bbddcf27f0eadd55",
      "2171c39ae28b45d8ba3129cc1610e52f",
      "db6df438a1cb460487931c1c9f5498dd",
      "a47e27bdd7fb4ea39d77341ae161c8c8",
      "13b5d6ec770a4ef2a29dc9e354f0a5e4",
      "e2b4c0ebddbb4c26aa121c0aec986957",
      "374269e944984fa6b0e7be0a9b7771ee",
      "f149704594904529b3ffce9432d49fa7",
      "97e2c78205234ff0929b3e887e6dfd46",
      "43e0937b09934e8d81de9d5bd21152ba",
      "c3aa08f8f15447d0933fff8adcdb09bf",
      "d668f036c5934d80a2b07d95f6432f0c",
      "855b3aa3c9574fb491e06709952b2f89",
      "1d6c0ce65f804337969d49c07722c886",
      "d220bf12546244efa0652985ab2b3053",
      "b9fda1875e9a429f83ea4602832a79cf",
      "f2f6fa4ca9d94cc18d1d3569191cc2fc",
      "2a1f20425ba9433eb72beabc6c179543",
      "5883cb8d54e445a3a5b322806571f4e7",
      "63e26f8985ac4227a5633d724be0a9b2",
      "1b151d1b646f46acac755fa1288580c8",
      "1cd22e9c4f014e69a6f1206012fddb8c",
      "8723a9a082cb4893a6805bae8241d977",
      "753c832e90654b54aab4fc228f0ac2d2",
      "73dfeace493049ab93cc2032eec05390",
      "317d76f349d547fb8fc458961d6af56e",
      "e2af00816f8346bc81062993427a3dad",
      "e0bca5090f5640a89f83b850823c01df",
      "08662b5cf05644e2a2829cee2713a1be",
      "73904cb7aaca4c20965c56a3215fa848",
      "dce60906b70044169297d5d2618b2461",
      "d0ae8de401f94ffe87bdd9439f9136c2",
      "cb5d3e8bd5ef4aa6a4155088545a3d0c",
      "47f3d82231b54c0e948063e35ed27bbd",
      "c42e69c4808949fb9c48546ae09e0621",
      "ae06861e12c0469eab67b07d93d5ca9f",
      "8dd32717940249b880b4290d57110cb8",
      "1ac36ddd5d054d9d8d79a3643753f5b8",
      "07e43b56c69a4d9d875efc7b71a4899f",
      "98dfab65718b4e0d9704b00dc283c7ba",
      "20b60f13afde495092f035b7fb8737e9",
      "9e7e95d8c696434989cee60ad5db6509",
      "670b7fdf8ce9480ba404f973c7c15649",
      "48fcf028aa8142efa520d6b04fc9a69d",
      "97d7ae458fda43f695365b242f4b562b",
      "0f4b1da5893148e78fe567d61ba231e4",
      "d6a1c66def434ee2ae83f2e2c9ad28a8",
      "911d5b008fab4808a6ff95d0291bbbba",
      "b87418a2e0af464b8324cd03caea58a3",
      "0f44031b6cd4459d8f03cd4ac96f332d",
      "6b9a5cce10a1418bb1cb63c079c91a79",
      "7e90994f2d614906a24b33a1f0766325",
      "c19183ce5143404a99ccd6977289ecd5",
      "821c221cb1a3456d942d112818b32aed",
      "56b1b65d98414340b2a13a25497296c9"
     ]
    },
    "id": "h7qMQ_RVpUTv",
    "outputId": "c765d045-9c78-4527-c297-4e34b32a49b3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dffd10fd36394581997465aad3a66db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767d7a857fb24c9fb403a0c637ffc02c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0b92edf7ce4446ba6733f5e5a630ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2f6c1c0b4e42ccaca9652071e7d6f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('klue/bert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "6Lx0JeclpCd3"
   },
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, labels, max_seq_len, tokenizer):\n",
    "\n",
    "    input_ids, attention_masks, token_type_ids, data_labels = [], [], [], []\n",
    "\n",
    "    for example, label in tqdm(zip(examples, labels), total=len(examples)):\n",
    "        # input_id는 워드 임베딩을 위한 문장의 정수 인코딩\n",
    "        input_id = tokenizer.encode(example, max_length=max_seq_len, pad_to_max_length=True)\n",
    "\n",
    "        # attention_mask는 실제 단어가 위치하면 1, 패딩의 위치에는 0인 시퀀스.\n",
    "        padding_count = input_id.count(tokenizer.pad_token_id)\n",
    "        attention_mask = [1] * (max_seq_len - padding_count) + [0] * padding_count\n",
    "\n",
    "        # token_type_id은 세그먼트 인코딩\n",
    "        token_type_id = [0] * max_seq_len\n",
    "\n",
    "        assert len(input_id) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_id), max_seq_len)\n",
    "        assert len(attention_mask) == max_seq_len, \"Error with attention mask length {} vs {}\".format(len(attention_mask), max_seq_len)\n",
    "        assert len(token_type_id) == max_seq_len, \"Error with token type length {} vs {}\".format(len(token_type_id), max_seq_len)\n",
    "\n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        data_labels.append(label)\n",
    "\n",
    "    input_ids = np.array(input_ids, dtype=int)\n",
    "    attention_masks = np.array(attention_masks, dtype=int)\n",
    "    token_type_ids = np.array(token_type_ids, dtype=int)\n",
    "\n",
    "    data_labels = np.asarray(data_labels, dtype=np.int32)\n",
    "\n",
    "    return (input_ids, attention_masks, token_type_ids), data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K6GwA8ropGXJ",
    "outputId": "77324d21-e34c-4a64-b635-a650b9e4c70a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3923 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/ubuntu/anaconda3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████| 3923/3923 [00:01<00:00, 3577.67it/s]\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y = convert_examples_to_features(X_train, y_train, max_seq_len=max_seq_len, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FSUWW7XFphCU",
    "outputId": "2dffdb0f-f0ff-46af-b18d-ab75a5b27504"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 981/981 [00:00<00:00, 4369.09it/s]\n"
     ]
    }
   ],
   "source": [
    "test_X, test_y = convert_examples_to_features(X_test, y_test, max_seq_len=max_seq_len, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M9H0TQaUpl6q",
    "outputId": "1ff82442-9130-4b80-9941-d0b205dc29a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어에 대한 정수 인코딩 : [    2  7073 23823 10675  2259   594  2664     3     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "어텐션 마스크 : [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "세그먼트 인코딩 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "각 인코딩의 길이 : 128\n",
      "정수 인코딩 복원 : [CLS] 영웅 나옴 보스는 고룡 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "레이블 : 0\n"
     ]
    }
   ],
   "source": [
    "input_id = train_X[0][0]\n",
    "attention_mask = train_X[1][0]\n",
    "token_type_id = train_X[2][0]\n",
    "label = train_y[0]\n",
    "\n",
    "print('단어에 대한 정수 인코딩 :',input_id)\n",
    "print('어텐션 마스크 :',attention_mask)\n",
    "print('세그먼트 인코딩 :',token_type_id)\n",
    "print('각 인코딩의 길이 :', len(input_id))\n",
    "print('정수 인코딩 복원 :',tokenizer.decode(input_id))\n",
    "print('레이블 :',label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ltdAJTeIp1_b",
    "outputId": "8803b4d0-b4f7-40f5-87e6-21cb0fc49dd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA GPU를 사용합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 12:44:29.506636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-21 12:44:30.233003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-21 12:44:30.235693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-21 12:44:30.238808: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-21 12:44:30.239321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-21 12:44:30.241316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-21 12:44:30.243319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-21 12:46:37.731078: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-21 12:46:37.732669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-21 12:46:37.733949: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-21 12:46:37.735211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13227 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# TPU를 사용할 수 있는지 확인합니다\n",
    "if 'COLAB_TPU_ADDR' in os.environ:\n",
    "    # TPU가 사용 가능한 경우 TPU를 설정합니다\n",
    "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
    "    tf.config.experimental_connect_to_cluster(resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
    "    print('TPU를 사용합니다.')\n",
    "else:\n",
    "    # TPU가 사용 불가능한 경우 CUDA GPU를 사용합니다\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    if len(physical_devices) == 0:\n",
    "        raise RuntimeError(\"GPU를 찾을 수 없습니다. TensorFlow가 올바르게 설치되어 있는지 확인하세요.\")\n",
    "\n",
    "    # 모든 GPU 메모리를 필요에 따라 동적으로 할당하도록 설정합니다\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "    # CUDA GPU를 사용하는 경우 문자열 \"/gpu:0\"을 전달합니다\n",
    "    strategy = tf.distribute.OneDeviceStrategy(\"/gpu:0\")\n",
    "    print('CUDA GPU를 사용합니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bl2kHoBup9Di",
    "outputId": "ab3416de-da5f-4cc7-9f96-03099c375f59"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "  model = TFBertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=3, from_pt=True)\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "  #model.compile(optimizer=optimizer, loss=model.compute_loss, metrics = ['accuracy'])\n",
    "  model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFBertForSequenceClassification\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 12:51:55.396946: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_12367\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\021FlatMapDataset:21\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - ETA: 0s - loss: 0.9656 - accuracy: 0.5497"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 12:53:18.244223: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_32406\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\021FlatMapDataset:44\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.60637, saving model to best_model_self(1).h5\n",
      "99/99 [==============================] - 93s 817ms/step - loss: 0.9656 - accuracy: 0.5497 - val_loss: 0.8810 - val_accuracy: 0.6064\n",
      "Epoch 2/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.7234 - accuracy: 0.7094\n",
      "Epoch 2: val_accuracy did not improve from 0.60637\n",
      "99/99 [==============================] - 77s 780ms/step - loss: 0.7234 - accuracy: 0.7094 - val_loss: 0.9220 - val_accuracy: 0.5962\n",
      "Epoch 3/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.4156 - accuracy: 0.8515\n",
      "Epoch 3: val_accuracy did not improve from 0.60637\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.4156 - accuracy: 0.8515 - val_loss: 1.1478 - val_accuracy: 0.6000\n",
      "Epoch 4/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.2325 - accuracy: 0.9194\n",
      "Epoch 4: val_accuracy improved from 0.60637 to 0.62548, saving model to best_model_self(1).h5\n",
      "99/99 [==============================] - 85s 855ms/step - loss: 0.2325 - accuracy: 0.9194 - val_loss: 1.3615 - val_accuracy: 0.6255\n",
      "Epoch 5/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.9646\n",
      "Epoch 5: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 781ms/step - loss: 0.1037 - accuracy: 0.9646 - val_loss: 1.5664 - val_accuracy: 0.5949\n",
      "Epoch 6/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 0.9796\n",
      "Epoch 6: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0712 - accuracy: 0.9796 - val_loss: 1.7078 - val_accuracy: 0.5796\n",
      "Epoch 7/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9866\n",
      "Epoch 7: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0449 - accuracy: 0.9866 - val_loss: 1.9617 - val_accuracy: 0.5949\n",
      "Epoch 8/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.9876\n",
      "Epoch 8: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0373 - accuracy: 0.9876 - val_loss: 2.0386 - val_accuracy: 0.5911\n",
      "Epoch 9/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9879\n",
      "Epoch 9: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0432 - accuracy: 0.9879 - val_loss: 2.3157 - val_accuracy: 0.5580\n",
      "Epoch 10/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0660 - accuracy: 0.9796\n",
      "Epoch 10: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0660 - accuracy: 0.9796 - val_loss: 2.0436 - val_accuracy: 0.6153\n",
      "Epoch 11/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.9853\n",
      "Epoch 11: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0489 - accuracy: 0.9853 - val_loss: 1.9973 - val_accuracy: 0.6051\n",
      "Epoch 12/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 0.9853\n",
      "Epoch 12: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 783ms/step - loss: 0.0443 - accuracy: 0.9853 - val_loss: 2.0117 - val_accuracy: 0.5962\n",
      "Epoch 13/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9911\n",
      "Epoch 13: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 783ms/step - loss: 0.0284 - accuracy: 0.9911 - val_loss: 2.0061 - val_accuracy: 0.5975\n",
      "Epoch 14/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9933\n",
      "Epoch 14: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 2.2230 - val_accuracy: 0.5885\n",
      "Epoch 15/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9879\n",
      "Epoch 15: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0328 - accuracy: 0.9879 - val_loss: 2.5295 - val_accuracy: 0.5732\n",
      "Epoch 16/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9873\n",
      "Epoch 16: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0338 - accuracy: 0.9873 - val_loss: 2.2691 - val_accuracy: 0.6000\n",
      "Epoch 17/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9901\n",
      "Epoch 17: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0269 - accuracy: 0.9901 - val_loss: 2.2534 - val_accuracy: 0.5860\n",
      "Epoch 18/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0424 - accuracy: 0.9863\n",
      "Epoch 18: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 783ms/step - loss: 0.0424 - accuracy: 0.9863 - val_loss: 2.1355 - val_accuracy: 0.5911\n",
      "Epoch 19/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9959\n",
      "Epoch 19: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 783ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 2.3485 - val_accuracy: 0.6013\n",
      "Epoch 20/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9930\n",
      "Epoch 20: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0186 - accuracy: 0.9930 - val_loss: 2.5674 - val_accuracy: 0.5911\n",
      "Epoch 21/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9892\n",
      "Epoch 21: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0326 - accuracy: 0.9892 - val_loss: 2.1489 - val_accuracy: 0.5847\n",
      "Epoch 22/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0921 - accuracy: 0.9704\n",
      "Epoch 22: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0921 - accuracy: 0.9704 - val_loss: 1.9033 - val_accuracy: 0.6089\n",
      "Epoch 23/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9879\n",
      "Epoch 23: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 783ms/step - loss: 0.0318 - accuracy: 0.9879 - val_loss: 2.0457 - val_accuracy: 0.6229\n",
      "Epoch 24/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9952\n",
      "Epoch 24: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0144 - accuracy: 0.9952 - val_loss: 2.3268 - val_accuracy: 0.6025\n",
      "Epoch 25/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9959\n",
      "Epoch 25: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 2.6697 - val_accuracy: 0.5834\n",
      "Epoch 26/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9920\n",
      "Epoch 26: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0221 - accuracy: 0.9920 - val_loss: 2.4009 - val_accuracy: 0.5936\n",
      "Epoch 27/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9939\n",
      "Epoch 27: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 783ms/step - loss: 0.0182 - accuracy: 0.9939 - val_loss: 2.4604 - val_accuracy: 0.5924\n",
      "Epoch 28/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9962\n",
      "Epoch 28: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 783ms/step - loss: 0.0137 - accuracy: 0.9962 - val_loss: 2.5267 - val_accuracy: 0.5898\n",
      "Epoch 29/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9904\n",
      "Epoch 29: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0291 - accuracy: 0.9904 - val_loss: 2.6266 - val_accuracy: 0.5936\n",
      "Epoch 30/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.9911\n",
      "Epoch 30: val_accuracy did not improve from 0.62548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0305 - accuracy: 0.9911 - val_loss: 2.2224 - val_accuracy: 0.6115\n",
      "Epoch 31/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9936\n",
      "Epoch 31: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0178 - accuracy: 0.9936 - val_loss: 2.4170 - val_accuracy: 0.6076\n",
      "Epoch 32/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9955\n",
      "Epoch 32: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0193 - accuracy: 0.9955 - val_loss: 2.4969 - val_accuracy: 0.5847\n",
      "Epoch 33/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9968\n",
      "Epoch 33: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 2.5289 - val_accuracy: 0.6140\n",
      "Epoch 34/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9978\n",
      "Epoch 34: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0059 - accuracy: 0.9978 - val_loss: 2.9050 - val_accuracy: 0.5962\n",
      "Epoch 35/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9930\n",
      "Epoch 35: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0264 - accuracy: 0.9930 - val_loss: 2.6916 - val_accuracy: 0.5885\n",
      "Epoch 36/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9939\n",
      "Epoch 36: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0165 - accuracy: 0.9939 - val_loss: 2.8903 - val_accuracy: 0.5962\n",
      "Epoch 37/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9914\n",
      "Epoch 37: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0292 - accuracy: 0.9914 - val_loss: 2.7874 - val_accuracy: 0.5758\n",
      "Epoch 38/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9914\n",
      "Epoch 38: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0330 - accuracy: 0.9914 - val_loss: 2.1911 - val_accuracy: 0.6000\n",
      "Epoch 39/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9968\n",
      "Epoch 39: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 2.3822 - val_accuracy: 0.5987\n",
      "Epoch 40/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9943\n",
      "Epoch 40: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 2.4112 - val_accuracy: 0.5987\n",
      "Epoch 41/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9949\n",
      "Epoch 41: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0200 - accuracy: 0.9949 - val_loss: 2.2471 - val_accuracy: 0.6013\n",
      "Epoch 42/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9955\n",
      "Epoch 42: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0143 - accuracy: 0.9955 - val_loss: 2.4762 - val_accuracy: 0.6000\n",
      "Epoch 43/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9908\n",
      "Epoch 43: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0291 - accuracy: 0.9908 - val_loss: 2.4489 - val_accuracy: 0.5975\n",
      "Epoch 44/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9968\n",
      "Epoch 44: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 2.6803 - val_accuracy: 0.5885\n",
      "Epoch 45/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9962\n",
      "Epoch 45: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 2.6540 - val_accuracy: 0.5834\n",
      "Epoch 46/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9949\n",
      "Epoch 46: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 2.3479 - val_accuracy: 0.6038\n",
      "Epoch 47/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9927\n",
      "Epoch 47: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 2.3040 - val_accuracy: 0.6115\n",
      "Epoch 48/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9981\n",
      "Epoch 51: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 2.6075 - val_accuracy: 0.6038\n",
      "Epoch 52/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9981\n",
      "Epoch 52: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0048 - accuracy: 0.9981 - val_loss: 2.7428 - val_accuracy: 0.5987\n",
      "Epoch 53/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9981\n",
      "Epoch 53: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 77s 782ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 2.9573 - val_accuracy: 0.5911\n",
      "Epoch 54/200\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9975\n",
      "Epoch 54: val_accuracy did not improve from 0.62548\n",
      "99/99 [==============================] - 78s 784ms/step - loss: 0.0090 - accuracy: 0.9975 - val_loss: 2.8205 - val_accuracy: 0.6140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca3c564a00>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EarlyStopping 설정\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    min_delta=0.001,\n",
    "    patience=30,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# ModelCheckpoint 설정\n",
    "checkpoint_path = \"best_model_self(2).h5\"\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',  # val_loss를 기준으로 성능을 평가합니다\n",
    "    mode='max',  # 'min' 모드로 설정하여 val_loss가 최소일 때 모델을 저장합니다\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(\n",
    "    train_X, train_y, epochs=200, batch_size=32, validation_split=0.2,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7zQ3dpqz1UaN",
    "outputId": "f782d935-4cba-4b7f-c01d-38c5a0896254"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 14:01:56.863912: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_68313\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\022FlatMapDataset:647\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step - loss: 1.3610 - accuracy: 0.5963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3610438108444214, 0.5963302850723267]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_X, test_y, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model_self(1).h5\n",
    "# 1/1 [==============================] - 8s 8s/step - loss: 1.3610 - accuracy: 0.5963\n",
    "# [1.3610438108444214, 0.5963302850723267]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model_self(2).h5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model_self(3).h5\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "BERT finance sentiment analysis_kor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07e43b56c69a4d9d875efc7b71a4899f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "08662b5cf05644e2a2829cee2713a1be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f44031b6cd4459d8f03cd4ac96f332d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0f4b1da5893148e78fe567d61ba231e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13b5d6ec770a4ef2a29dc9e354f0a5e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3aa08f8f15447d0933fff8adcdb09bf",
      "placeholder": "​",
      "style": "IPY_MODEL_43e0937b09934e8d81de9d5bd21152ba",
      "value": " 243k/243k [00:00&lt;00:00, 1.58MB/s]"
     }
    },
    "1ac36ddd5d054d9d8d79a3643753f5b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48fcf028aa8142efa520d6b04fc9a69d",
      "placeholder": "​",
      "style": "IPY_MODEL_670b7fdf8ce9480ba404f973c7c15649",
      "value": " 483k/483k [00:00&lt;00:00, 1.60MB/s]"
     }
    },
    "1b151d1b646f46acac755fa1288580c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1cd22e9c4f014e69a6f1206012fddb8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d6c0ce65f804337969d49c07722c886": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a1f20425ba9433eb72beabc6c179543",
      "placeholder": "​",
      "style": "IPY_MODEL_f2f6fa4ca9d94cc18d1d3569191cc2fc",
      "value": "Downloading: 100%"
     }
    },
    "20b60f13afde495092f035b7fb8737e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2171c39ae28b45d8ba3129cc1610e52f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a1f20425ba9433eb72beabc6c179543": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "317d76f349d547fb8fc458961d6af56e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dce60906b70044169297d5d2618b2461",
      "max": 289,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_73904cb7aaca4c20965c56a3215fa848",
      "value": 289
     }
    },
    "374269e944984fa6b0e7be0a9b7771ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43e0937b09934e8d81de9d5bd21152ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "47f3d82231b54c0e948063e35ed27bbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ae06861e12c0469eab67b07d93d5ca9f",
       "IPY_MODEL_8dd32717940249b880b4290d57110cb8",
       "IPY_MODEL_1ac36ddd5d054d9d8d79a3643753f5b8"
      ],
      "layout": "IPY_MODEL_c42e69c4808949fb9c48546ae09e0621"
     }
    },
    "48fcf028aa8142efa520d6b04fc9a69d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56b1b65d98414340b2a13a25497296c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5883cb8d54e445a3a5b322806571f4e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "63e26f8985ac4227a5633d724be0a9b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "670b7fdf8ce9480ba404f973c7c15649": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b9a5cce10a1418bb1cb63c079c91a79": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73904cb7aaca4c20965c56a3215fa848": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "73dfeace493049ab93cc2032eec05390": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08662b5cf05644e2a2829cee2713a1be",
      "placeholder": "​",
      "style": "IPY_MODEL_e0bca5090f5640a89f83b850823c01df",
      "value": "Downloading: 100%"
     }
    },
    "753c832e90654b54aab4fc228f0ac2d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e90994f2d614906a24b33a1f0766325": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "821c221cb1a3456d942d112818b32aed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "855b3aa3c9574fb491e06709952b2f89": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8723a9a082cb4893a6805bae8241d977": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_73dfeace493049ab93cc2032eec05390",
       "IPY_MODEL_317d76f349d547fb8fc458961d6af56e",
       "IPY_MODEL_e2af00816f8346bc81062993427a3dad"
      ],
      "layout": "IPY_MODEL_753c832e90654b54aab4fc228f0ac2d2"
     }
    },
    "8dd32717940249b880b4290d57110cb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e7e95d8c696434989cee60ad5db6509",
      "max": 494860,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_20b60f13afde495092f035b7fb8737e9",
      "value": 494860
     }
    },
    "911d5b008fab4808a6ff95d0291bbbba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c19183ce5143404a99ccd6977289ecd5",
      "max": 425,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7e90994f2d614906a24b33a1f0766325",
      "value": 425
     }
    },
    "97d7ae458fda43f695365b242f4b562b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d6a1c66def434ee2ae83f2e2c9ad28a8",
       "IPY_MODEL_911d5b008fab4808a6ff95d0291bbbba",
       "IPY_MODEL_b87418a2e0af464b8324cd03caea58a3"
      ],
      "layout": "IPY_MODEL_0f4b1da5893148e78fe567d61ba231e4"
     }
    },
    "97e2c78205234ff0929b3e887e6dfd46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98dfab65718b4e0d9704b00dc283c7ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e7e95d8c696434989cee60ad5db6509": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a47e27bdd7fb4ea39d77341ae161c8c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97e2c78205234ff0929b3e887e6dfd46",
      "max": 248477,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f149704594904529b3ffce9432d49fa7",
      "value": 248477
     }
    },
    "ae06861e12c0469eab67b07d93d5ca9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98dfab65718b4e0d9704b00dc283c7ba",
      "placeholder": "​",
      "style": "IPY_MODEL_07e43b56c69a4d9d875efc7b71a4899f",
      "value": "Downloading: 100%"
     }
    },
    "b87418a2e0af464b8324cd03caea58a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56b1b65d98414340b2a13a25497296c9",
      "placeholder": "​",
      "style": "IPY_MODEL_821c221cb1a3456d942d112818b32aed",
      "value": " 425/425 [00:00&lt;00:00, 15.8kB/s]"
     }
    },
    "b9fda1875e9a429f83ea4602832a79cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1cd22e9c4f014e69a6f1206012fddb8c",
      "placeholder": "​",
      "style": "IPY_MODEL_1b151d1b646f46acac755fa1288580c8",
      "value": " 125/125 [00:00&lt;00:00, 4.72kB/s]"
     }
    },
    "c19183ce5143404a99ccd6977289ecd5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3aa08f8f15447d0933fff8adcdb09bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c42e69c4808949fb9c48546ae09e0621": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb5d3e8bd5ef4aa6a4155088545a3d0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0ae8de401f94ffe87bdd9439f9136c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d220bf12546244efa0652985ab2b3053": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63e26f8985ac4227a5633d724be0a9b2",
      "max": 125,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5883cb8d54e445a3a5b322806571f4e7",
      "value": 125
     }
    },
    "d668f036c5934d80a2b07d95f6432f0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1d6c0ce65f804337969d49c07722c886",
       "IPY_MODEL_d220bf12546244efa0652985ab2b3053",
       "IPY_MODEL_b9fda1875e9a429f83ea4602832a79cf"
      ],
      "layout": "IPY_MODEL_855b3aa3c9574fb491e06709952b2f89"
     }
    },
    "d6a1c66def434ee2ae83f2e2c9ad28a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b9a5cce10a1418bb1cb63c079c91a79",
      "placeholder": "​",
      "style": "IPY_MODEL_0f44031b6cd4459d8f03cd4ac96f332d",
      "value": "Downloading: 100%"
     }
    },
    "db6df438a1cb460487931c1c9f5498dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_374269e944984fa6b0e7be0a9b7771ee",
      "placeholder": "​",
      "style": "IPY_MODEL_e2b4c0ebddbb4c26aa121c0aec986957",
      "value": "Downloading: 100%"
     }
    },
    "dce60906b70044169297d5d2618b2461": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0bca5090f5640a89f83b850823c01df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e2af00816f8346bc81062993427a3dad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb5d3e8bd5ef4aa6a4155088545a3d0c",
      "placeholder": "​",
      "style": "IPY_MODEL_d0ae8de401f94ffe87bdd9439f9136c2",
      "value": " 289/289 [00:00&lt;00:00, 11.1kB/s]"
     }
    },
    "e2b4c0ebddbb4c26aa121c0aec986957": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f149704594904529b3ffce9432d49fa7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f2f6fa4ca9d94cc18d1d3569191cc2fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f54e09e1acae4d28bbddcf27f0eadd55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_db6df438a1cb460487931c1c9f5498dd",
       "IPY_MODEL_a47e27bdd7fb4ea39d77341ae161c8c8",
       "IPY_MODEL_13b5d6ec770a4ef2a29dc9e354f0a5e4"
      ],
      "layout": "IPY_MODEL_2171c39ae28b45d8ba3129cc1610e52f"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
