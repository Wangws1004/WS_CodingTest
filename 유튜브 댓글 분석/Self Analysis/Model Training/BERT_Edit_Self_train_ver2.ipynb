{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/ubuntu/anaconda3/lib/python3.10/site-packages (23.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ubuntu/anaconda3/lib/python3.10/site-packages (4.24.0)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (0.11.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/ubuntu/anaconda3/lib/python3.10/site-packages (2.15.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (12.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (0.5)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: xxhash in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.18.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (0.19.4)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu==2.8.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (23.5.26)\n",
      "Requirement already satisfied: gast>=0.2.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (3.7.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.1.2)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (16.0.6)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (3.20.0)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (65.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (4.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.14.1)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (2.8.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (2.8.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorflow-gpu==2.8.0) (1.59.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-gpu==2.8.0) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu==2.8.0) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-gpu==2.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.20 in /home/ubuntu/anaconda3/lib/python3.10/site-packages (3.20.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install protobuf==3.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Qww_V4GzhgoS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import re\n",
    "import os\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wC6Rnt6iCxB",
    "outputId": "23d687d4-646b-4afa-f8ac-e5ce7a210c67"
   },
   "outputs": [],
   "source": [
    "# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/finance_sentiment_corpus/main/finance_data.csv\", filename=\"finance_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1aP870z3iRc_",
    "outputId": "84b0007f-0732-4872-e647-d01c5334efe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 수 : 5100\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('self_training_data.csv')\n",
    "print('총 샘플의 수 :',len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "9eEIdsG4iZYf",
    "outputId": "222a027b-fd6c-4820-c662-7cb50f59377e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>name</th>\n",
       "      <th>theme</th>\n",
       "      <th>동영상 제목</th>\n",
       "      <th>댓글</th>\n",
       "      <th>댓글 작성일</th>\n",
       "      <th>PRO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>검은사막</td>\n",
       "      <td>게임성</td>\n",
       "      <td>릴카 피파 하축단 마지막+검은사막 아토락시온 레이드(feat.서새봄,노돌리,소풍왔니...</td>\n",
       "      <td>오늘 영상도 재밌게 시청하겠습니다:)</td>\n",
       "      <td>2023-07-30T23:56:32Z</td>\n",
       "      <td>오늘 영상도 재밌게 시청하겠습니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>검은사막</td>\n",
       "      <td>게임성</td>\n",
       "      <td>릴카 피파 하축단 마지막+검은사막 아토락시온 레이드(feat.서새봄,노돌리,소풍왔니...</td>\n",
       "      <td>오 아침 업로드 귀하다</td>\n",
       "      <td>2023-07-30T22:10:42Z</td>\n",
       "      <td>오 아침 업로드 귀하다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>리니지</td>\n",
       "      <td>BM</td>\n",
       "      <td>[리니지M] 갑자기 생각도 못한 이벤트를 하네? ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 뭐야 이거 (9...</td>\n",
       "      <td>4개 계정으로 모두 추천했어요 에디션 당첨되시길 ^^</td>\n",
       "      <td>2023-09-27T14:15:45Z</td>\n",
       "      <td>4개 계정으로 모두 추천했어요 에디션 당첨되시길</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>제2의나라</td>\n",
       "      <td>BM</td>\n",
       "      <td>[제2의 나라] 히사이시 조, 제2의 나라를 지휘하다_30s</td>\n",
       "      <td>BHXTHB 추천부탁드립니다 10연뽑기 가져다 드리겠습니다</td>\n",
       "      <td>2021-05-28T11:46:22Z</td>\n",
       "      <td>BHXTHB 추천부탁드립니다 10연뽑기 가져다 드리겠습니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>제2의나라</td>\n",
       "      <td>BM</td>\n",
       "      <td>[제2의 나라] 코엑스에 거대 고양이 '우다닥'이 나타났다?!</td>\n",
       "      <td>BHXTHB 추천부탁드립니다 10연뽑기 가져다 드리겠습니다ㅎㅎ</td>\n",
       "      <td>2021-05-28T17:23:05Z</td>\n",
       "      <td>BHXTHB 추천부탁드립니다 10연뽑기 가져다 드리겠습니다ㅎㅎ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5095</th>\n",
       "      <td>2</td>\n",
       "      <td>신의탑</td>\n",
       "      <td>시스템</td>\n",
       "      <td>'신의탑M'을 시작하려는 비선별인원을 위한 종합 가이드</td>\n",
       "      <td>초반에 사람 몰리는 이유는 리세마라때문입니다.\\n방치수집게임은 뽑기가 첨이자끝인데 ...</td>\n",
       "      <td>2022-04-23T11:24:50Z</td>\n",
       "      <td>초반에 사람 몰리는 이유는 리세마라때문입니다  방치수집게임은 뽑기가 첨이자끝인데 오...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5096</th>\n",
       "      <td>2</td>\n",
       "      <td>신의탑</td>\n",
       "      <td>시스템</td>\n",
       "      <td>신의탑 업뎃 미리보기! 재화보상 상향에 연이화까지.. 미쳤다 | 신의 탑 새로운 세...</td>\n",
       "      <td>전 이틀전에 접었습니다 여기에 긴글을 적고 싶지만 무과금 소과금분들 이게임 하지마세...</td>\n",
       "      <td>2023-08-23T22:35:10Z</td>\n",
       "      <td>전 이틀전에 접었습니다 여기에 긴글을 적고 싶지만 무과금 소과금분들 이게임 하지마세...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5097</th>\n",
       "      <td>2</td>\n",
       "      <td>신의탑</td>\n",
       "      <td>시스템</td>\n",
       "      <td>진짜 넷마블게임 보고 내가 괜찮다고 느낄 줄이야! - 신의탑: 새로운 세계. 종합 ...</td>\n",
       "      <td>개인적으로 이분 현질 하츠 풀돌햇는데 시나 막히면 아니 ×× 이걸 어떻게 깨라고 만...</td>\n",
       "      <td>2023-08-01T14:01:21Z</td>\n",
       "      <td>개인적으로 이분 현질 하츠 풀돌햇는데 시나 막히면 아니    이걸 어떻게 깨라고 만...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5098</th>\n",
       "      <td>2</td>\n",
       "      <td>신의탑</td>\n",
       "      <td>시스템</td>\n",
       "      <td>신의탑 새로운세계 유저들이 뿔난 이유! 개선 사항 공지 올라옴 [사키엘TV]</td>\n",
       "      <td>뽑기 확률도 조작한거같고\\n애초에 개 창렬인데다가\\n확률 자체가 쓰레기고\\n재화 보...</td>\n",
       "      <td>2023-08-17T17:29:42Z</td>\n",
       "      <td>뽑기 확률도 조작한거같고 애초에 개 창렬인데다가 확률 자체가 쓰레기고 재화 보상도 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5099</th>\n",
       "      <td>2</td>\n",
       "      <td>검은사막</td>\n",
       "      <td>시스템</td>\n",
       "      <td>검은사막 개떡상 근황. 신규 유저들 막피한 고인물 PK유저 강력제재, 진실은? | ...</td>\n",
       "      <td>공방합이 차이나면 컨을 떠나서 죽일 수가 없는 데 당연히 문재로 보고 대처해야죠.이...</td>\n",
       "      <td>2023-07-25T19:01:31Z</td>\n",
       "      <td>공방합이 차이나면 컨을 떠나서 죽일 수가 없는 데 당연히 문재로 보고 대처해야죠 이...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels   name theme                                             동영상 제목  \\\n",
       "0          0   검은사막   게임성  릴카 피파 하축단 마지막+검은사막 아토락시온 레이드(feat.서새봄,노돌리,소풍왔니...   \n",
       "1          0   검은사막   게임성  릴카 피파 하축단 마지막+검은사막 아토락시온 레이드(feat.서새봄,노돌리,소풍왔니...   \n",
       "2          0    리니지    BM  [리니지M] 갑자기 생각도 못한 이벤트를 하네? ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 뭐야 이거 (9...   \n",
       "3          0  제2의나라    BM                  [제2의 나라] 히사이시 조, 제2의 나라를 지휘하다_30s   \n",
       "4          0  제2의나라    BM                 [제2의 나라] 코엑스에 거대 고양이 '우다닥'이 나타났다?!   \n",
       "...      ...    ...   ...                                                ...   \n",
       "5095       2    신의탑   시스템                     '신의탑M'을 시작하려는 비선별인원을 위한 종합 가이드   \n",
       "5096       2    신의탑   시스템  신의탑 업뎃 미리보기! 재화보상 상향에 연이화까지.. 미쳤다 | 신의 탑 새로운 세...   \n",
       "5097       2    신의탑   시스템  진짜 넷마블게임 보고 내가 괜찮다고 느낄 줄이야! - 신의탑: 새로운 세계. 종합 ...   \n",
       "5098       2    신의탑   시스템         신의탑 새로운세계 유저들이 뿔난 이유! 개선 사항 공지 올라옴 [사키엘TV]   \n",
       "5099       2   검은사막   시스템  검은사막 개떡상 근황. 신규 유저들 막피한 고인물 PK유저 강력제재, 진실은? | ...   \n",
       "\n",
       "                                                     댓글                댓글 작성일  \\\n",
       "0                                  오늘 영상도 재밌게 시청하겠습니다:)  2023-07-30T23:56:32Z   \n",
       "1                                          오 아침 업로드 귀하다  2023-07-30T22:10:42Z   \n",
       "2                         4개 계정으로 모두 추천했어요 에디션 당첨되시길 ^^  2023-09-27T14:15:45Z   \n",
       "3                      BHXTHB 추천부탁드립니다 10연뽑기 가져다 드리겠습니다  2021-05-28T11:46:22Z   \n",
       "4                    BHXTHB 추천부탁드립니다 10연뽑기 가져다 드리겠습니다ㅎㅎ  2021-05-28T17:23:05Z   \n",
       "...                                                 ...                   ...   \n",
       "5095  초반에 사람 몰리는 이유는 리세마라때문입니다.\\n방치수집게임은 뽑기가 첨이자끝인데 ...  2022-04-23T11:24:50Z   \n",
       "5096  전 이틀전에 접었습니다 여기에 긴글을 적고 싶지만 무과금 소과금분들 이게임 하지마세...  2023-08-23T22:35:10Z   \n",
       "5097  개인적으로 이분 현질 하츠 풀돌햇는데 시나 막히면 아니 ×× 이걸 어떻게 깨라고 만...  2023-08-01T14:01:21Z   \n",
       "5098  뽑기 확률도 조작한거같고\\n애초에 개 창렬인데다가\\n확률 자체가 쓰레기고\\n재화 보...  2023-08-17T17:29:42Z   \n",
       "5099  공방합이 차이나면 컨을 떠나서 죽일 수가 없는 데 당연히 문재로 보고 대처해야죠.이...  2023-07-25T19:01:31Z   \n",
       "\n",
       "                                                    PRO  \n",
       "0                                  오늘 영상도 재밌게 시청하겠습니다    \n",
       "1                                          오 아침 업로드 귀하다  \n",
       "2                         4개 계정으로 모두 추천했어요 에디션 당첨되시길     \n",
       "3                      BHXTHB 추천부탁드립니다 10연뽑기 가져다 드리겠습니다  \n",
       "4                    BHXTHB 추천부탁드립니다 10연뽑기 가져다 드리겠습니다ㅎㅎ  \n",
       "...                                                 ...  \n",
       "5095  초반에 사람 몰리는 이유는 리세마라때문입니다  방치수집게임은 뽑기가 첨이자끝인데 오...  \n",
       "5096  전 이틀전에 접었습니다 여기에 긴글을 적고 싶지만 무과금 소과금분들 이게임 하지마세...  \n",
       "5097  개인적으로 이분 현질 하츠 풀돌햇는데 시나 막히면 아니    이걸 어떻게 깨라고 만...  \n",
       "5098  뽑기 확률도 조작한거같고 애초에 개 창렬인데다가 확률 자체가 쓰레기고 재화 보상도 ...  \n",
       "5099  공방합이 차이나면 컨을 떠나서 죽일 수가 없는 데 당연히 문재로 보고 대처해야죠 이...  \n",
       "\n",
       "[5100 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "t9XJj_iziaYh",
    "outputId": "eabc6763-3d47-4b01-8b70-2e2cf1888a79"
   },
   "outputs": [],
   "source": [
    "# data['labels'] = data['labels'].replace(['neutral', 'positive', 'negative'],[0, 1, 2])\n",
    "# data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "RNyrW0ynix3O"
   },
   "outputs": [],
   "source": [
    "# '동영상 제목', '댓글 작성일', '댓글' 컬럼 삭제\n",
    "data = data.drop(['name', 'theme', '동영상 제목', '댓글 작성일', '댓글'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "5Pz9t4U2i35Q",
    "outputId": "e950d978-63d4-49d7-c6e7-f55fe8f251e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>PRO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>오늘 영상도 재밌게 시청하겠습니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>오 아침 업로드 귀하다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4개 계정으로 모두 추천했어요 에디션 당첨되시길</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>BHXTHB 추천부탁드립니다 10연뽑기 가져다 드리겠습니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>BHXTHB 추천부탁드립니다 10연뽑기 가져다 드리겠습니다ㅎㅎ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                 PRO\n",
       "0       0                오늘 영상도 재밌게 시청하겠습니다  \n",
       "1       0                        오 아침 업로드 귀하다\n",
       "2       0       4개 계정으로 모두 추천했어요 에디션 당첨되시길   \n",
       "3       0    BHXTHB 추천부탁드립니다 10연뽑기 가져다 드리겠습니다\n",
       "4       0  BHXTHB 추천부탁드립니다 10연뽑기 가져다 드리겠습니다ㅎㅎ"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>kor_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>오늘 영상도 재밌게 시청하겠습니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>오 아침 업로드 귀하다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4개 계정으로 모두 추천했어요 에디션 당첨되시길</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>BHXTHB 추천부탁드립니다 10연뽑기 가져다 드리겠습니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>BHXTHB 추천부탁드립니다 10연뽑기 가져다 드리겠습니다ㅎㅎ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5095</th>\n",
       "      <td>2</td>\n",
       "      <td>초반에 사람 몰리는 이유는 리세마라때문입니다  방치수집게임은 뽑기가 첨이자끝인데 오...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5096</th>\n",
       "      <td>2</td>\n",
       "      <td>전 이틀전에 접었습니다 여기에 긴글을 적고 싶지만 무과금 소과금분들 이게임 하지마세...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5097</th>\n",
       "      <td>2</td>\n",
       "      <td>개인적으로 이분 현질 하츠 풀돌햇는데 시나 막히면 아니    이걸 어떻게 깨라고 만...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5098</th>\n",
       "      <td>2</td>\n",
       "      <td>뽑기 확률도 조작한거같고 애초에 개 창렬인데다가 확률 자체가 쓰레기고 재화 보상도 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5099</th>\n",
       "      <td>2</td>\n",
       "      <td>공방합이 차이나면 컨을 떠나서 죽일 수가 없는 데 당연히 문재로 보고 대처해야죠 이...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                       kor_sentence\n",
       "0          0                               오늘 영상도 재밌게 시청하겠습니다  \n",
       "1          0                                       오 아침 업로드 귀하다\n",
       "2          0                      4개 계정으로 모두 추천했어요 에디션 당첨되시길   \n",
       "3          0                   BHXTHB 추천부탁드립니다 10연뽑기 가져다 드리겠습니다\n",
       "4          0                 BHXTHB 추천부탁드립니다 10연뽑기 가져다 드리겠습니다ㅎㅎ\n",
       "...      ...                                                ...\n",
       "5095       2  초반에 사람 몰리는 이유는 리세마라때문입니다  방치수집게임은 뽑기가 첨이자끝인데 오...\n",
       "5096       2  전 이틀전에 접었습니다 여기에 긴글을 적고 싶지만 무과금 소과금분들 이게임 하지마세...\n",
       "5097       2  개인적으로 이분 현질 하츠 풀돌햇는데 시나 막히면 아니    이걸 어떻게 깨라고 만...\n",
       "5098       2  뽑기 확률도 조작한거같고 애초에 개 창렬인데다가 확률 자체가 쓰레기고 재화 보상도 ...\n",
       "5099       2  공방합이 차이나면 컨을 떠나서 죽일 수가 없는 데 당연히 문재로 보고 대처해야죠 이...\n",
       "\n",
       "[5100 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'PRO' 칼럼을 'kor_sentence'로 변경\n",
    "data.rename(columns={'PRO': 'kor_sentence'}, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b7EW631ui4OA",
    "outputId": "b1e1a6ed-f426-4586-cd9b-20b7af122dab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5100 entries, 0 to 5099\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   labels        5100 non-null   int64 \n",
      " 1   kor_sentence  5100 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 79.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5100.000000\n",
       "mean        1.000000\n",
       "std         0.816577\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         1.000000\n",
       "75%         2.000000\n",
       "max         2.000000\n",
       "Name: labels, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['labels'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1700\n",
       "1    1700\n",
       "2    1700\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈 문자열과 숫자로 변환할 수 없는 값을 NaN으로 대체\n",
    "data['labels'] = pd.to_numeric(data['labels'], errors='coerce')\n",
    "\n",
    "# NaN 값을 원하는 기본값으로 대체\n",
    "data['labels'].fillna(10, inplace=True)\n",
    "\n",
    "# 최종적으로 int로 형변환\n",
    "data['labels'] = data['labels'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1700\n",
       "1    1700\n",
       "2    1700\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>kor_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>오늘 영상도 재밌게 시청하겠습니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>오 아침 업로드 귀하다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4개 계정으로 모두 추천했어요 에디션 당첨되시길</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>BHXTHB 추천부탁드립니다 10연뽑기 가져다 드리겠습니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>BHXTHB 추천부탁드립니다 10연뽑기 가져다 드리겠습니다ㅎㅎ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5095</th>\n",
       "      <td>2</td>\n",
       "      <td>초반에 사람 몰리는 이유는 리세마라때문입니다  방치수집게임은 뽑기가 첨이자끝인데 오...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5096</th>\n",
       "      <td>2</td>\n",
       "      <td>전 이틀전에 접었습니다 여기에 긴글을 적고 싶지만 무과금 소과금분들 이게임 하지마세...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5097</th>\n",
       "      <td>2</td>\n",
       "      <td>개인적으로 이분 현질 하츠 풀돌햇는데 시나 막히면 아니    이걸 어떻게 깨라고 만...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5098</th>\n",
       "      <td>2</td>\n",
       "      <td>뽑기 확률도 조작한거같고 애초에 개 창렬인데다가 확률 자체가 쓰레기고 재화 보상도 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5099</th>\n",
       "      <td>2</td>\n",
       "      <td>공방합이 차이나면 컨을 떠나서 죽일 수가 없는 데 당연히 문재로 보고 대처해야죠 이...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                       kor_sentence\n",
       "0          0                               오늘 영상도 재밌게 시청하겠습니다  \n",
       "1          0                                       오 아침 업로드 귀하다\n",
       "2          0                      4개 계정으로 모두 추천했어요 에디션 당첨되시길   \n",
       "3          0                   BHXTHB 추천부탁드립니다 10연뽑기 가져다 드리겠습니다\n",
       "4          0                 BHXTHB 추천부탁드립니다 10연뽑기 가져다 드리겠습니다ㅎㅎ\n",
       "...      ...                                                ...\n",
       "5095       2  초반에 사람 몰리는 이유는 리세마라때문입니다  방치수집게임은 뽑기가 첨이자끝인데 오...\n",
       "5096       2  전 이틀전에 접었습니다 여기에 긴글을 적고 싶지만 무과금 소과금분들 이게임 하지마세...\n",
       "5097       2  개인적으로 이분 현질 하츠 풀돌햇는데 시나 막히면 아니    이걸 어떻게 깨라고 만...\n",
       "5098       2  뽑기 확률도 조작한거같고 애초에 개 창렬인데다가 확률 자체가 쓰레기고 재화 보상도 ...\n",
       "5099       2  공방합이 차이나면 컨을 떠나서 죽일 수가 없는 데 당연히 문재로 보고 대처해야죠 이...\n",
       "\n",
       "[5100 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data['labels'] != 10]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JkvjJa1Ji7Eo",
    "outputId": "ab2e76cb-c617-45c4-da22-683985e79108"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측값 여부 : False\n"
     ]
    }
   ],
   "source": [
    "print('결측값 여부 :',data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UoAyW4Lii8xX",
    "outputId": "df771080-bc2f-414f-a73b-0f15a213eb13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kor_sentence 열의 유니크한 값 : 5092\n"
     ]
    }
   ],
   "source": [
    "print('kor_sentence 열의 유니크한 값 :',data['kor_sentence'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "cks_QRBfjKBU"
   },
   "outputs": [],
   "source": [
    "duplicate = data[data.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "ZwkZ7T0BjL7d",
    "outputId": "71c8b1dc-5b31-40e3-8beb-7818f7ca8d89"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>kor_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3396</th>\n",
       "      <td>1</td>\n",
       "      <td>오늘 해볼려ㅕ는데 꿀팁 감사하빈다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5051</th>\n",
       "      <td>2</td>\n",
       "      <td>전술장비는 왜 자꾸 집착하는거야 참내</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5061</th>\n",
       "      <td>2</td>\n",
       "      <td>그냥 줄줄 개소리 써놨네 ㅋㅌㅋㅋ 이 참에 제대로 논란 먹고 한번 더 나락가야지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5093</th>\n",
       "      <td>2</td>\n",
       "      <td>전 이틀전에 접었습니다 여기에 긴글을 적고 싶지만 무과금 소과금분들 이게임 하지마세...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5096</th>\n",
       "      <td>2</td>\n",
       "      <td>전 이틀전에 접었습니다 여기에 긴글을 적고 싶지만 무과금 소과금분들 이게임 하지마세...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                       kor_sentence\n",
       "3396       1                              오늘 해볼려ㅕ는데 꿀팁 감사하빈다   \n",
       "5051       2                               전술장비는 왜 자꾸 집착하는거야 참내\n",
       "5061       2       그냥 줄줄 개소리 써놨네 ㅋㅌㅋㅋ 이 참에 제대로 논란 먹고 한번 더 나락가야지\n",
       "5093       2  전 이틀전에 접었습니다 여기에 긴글을 적고 싶지만 무과금 소과금분들 이게임 하지마세...\n",
       "5096       2  전 이틀전에 접었습니다 여기에 긴글을 적고 싶지만 무과금 소과금분들 이게임 하지마세..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "prnB1Yg5jBt2",
    "outputId": "b0e72b35-ed7d-4c31-e781-5378cff76361"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 수 : 5092\n"
     ]
    }
   ],
   "source": [
    "# 중복 제거\n",
    "data.drop_duplicates(subset=['kor_sentence'], inplace=True)\n",
    "print('총 샘플의 수 :',len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "StnulPDqjuKX",
    "outputId": "1d679065-7cc0-433d-91be-fe7464ace638"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['labels'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dP_BFHlojwiN",
    "outputId": "c081665b-4f69-4d15-b02e-9566bfc57bd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블의 분포\n",
      "   labels  count\n",
      "0       0   1700\n",
      "1       1   1699\n",
      "2       2   1693\n"
     ]
    }
   ],
   "source": [
    "print('레이블의 분포')\n",
    "print(data.groupby('labels').size().reset_index(name='count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CfQdxYqMj3o8",
    "outputId": "e3adf4ef-9e82-4ac7-a624-6fe56f9c3df7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중립의 비율 = 33.386%\n",
      "긍정의 비율 = 33.366%\n",
      "부정의 비율 = 33.248%\n"
     ]
    }
   ],
   "source": [
    "print(f'중립의 비율 = {round(data[\"labels\"].value_counts()[0]/len(data) * 100,3)}%')\n",
    "print(f'긍정의 비율 = {round(data[\"labels\"].value_counts()[1]/len(data) * 100,3)}%')\n",
    "print(f'부정의 비율 = {round(data[\"labels\"].value_counts()[2]/len(data) * 100,3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "jKKmVrDRk46e",
    "outputId": "07e6e8cc-7760-484b-eb3b-087ae964cb51"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>kor_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>오늘 영상도 재밌게 시청하겠습니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>오 아침 업로드 귀하다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4개 계정으로 모두 추천했어요 에디션 당첨되시길</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>BHXTHB 추천부탁드립니다 10연뽑기 가져다 드리겠습니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>BHXTHB 추천부탁드립니다 10연뽑기 가져다 드리겠습니다ㅎㅎ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5094</th>\n",
       "      <td>2</td>\n",
       "      <td>하   어제 16  4 올라왔는데 접어야하나</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5095</th>\n",
       "      <td>2</td>\n",
       "      <td>초반에 사람 몰리는 이유는 리세마라때문입니다  방치수집게임은 뽑기가 첨이자끝인데 오...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5097</th>\n",
       "      <td>2</td>\n",
       "      <td>개인적으로 이분 현질 하츠 풀돌햇는데 시나 막히면 아니    이걸 어떻게 깨라고 만...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5098</th>\n",
       "      <td>2</td>\n",
       "      <td>뽑기 확률도 조작한거같고 애초에 개 창렬인데다가 확률 자체가 쓰레기고 재화 보상도 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5099</th>\n",
       "      <td>2</td>\n",
       "      <td>공방합이 차이나면 컨을 떠나서 죽일 수가 없는 데 당연히 문재로 보고 대처해야죠 이...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5092 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                       kor_sentence\n",
       "0          0                               오늘 영상도 재밌게 시청하겠습니다  \n",
       "1          0                                       오 아침 업로드 귀하다\n",
       "2          0                      4개 계정으로 모두 추천했어요 에디션 당첨되시길   \n",
       "3          0                   BHXTHB 추천부탁드립니다 10연뽑기 가져다 드리겠습니다\n",
       "4          0                 BHXTHB 추천부탁드립니다 10연뽑기 가져다 드리겠습니다ㅎㅎ\n",
       "...      ...                                                ...\n",
       "5094       2                           하   어제 16  4 올라왔는데 접어야하나\n",
       "5095       2  초반에 사람 몰리는 이유는 리세마라때문입니다  방치수집게임은 뽑기가 첨이자끝인데 오...\n",
       "5097       2  개인적으로 이분 현질 하츠 풀돌햇는데 시나 막히면 아니    이걸 어떻게 깨라고 만...\n",
       "5098       2  뽑기 확률도 조작한거같고 애초에 개 창렬인데다가 확률 자체가 쓰레기고 재화 보상도 ...\n",
       "5099       2  공방합이 차이나면 컨을 떠나서 죽일 수가 없는 데 당연히 문재로 보고 대처해야죠 이...\n",
       "\n",
       "[5092 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l8foVC2rkJtF",
    "outputId": "e5526eb9-1b41-4bd4-fc85-752670824790"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "본문의 개수: 5092\n",
      "레이블의 개수: 5092\n"
     ]
    }
   ],
   "source": [
    "X_data = data['kor_sentence']\n",
    "y_data = data['labels']\n",
    "print('본문의 개수: {}'.format(len(X_data)))\n",
    "print('레이블의 개수: {}'.format(len(y_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "qmFecWmSkHiu"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=0, stratify=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HiPJQoBql2T_",
    "outputId": "012118ee-7e39-4d9a-fe40-0aad31cc89d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 개수 : 4073\n",
      "테스트 샘플의 개수 : 1019\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플의 개수 :', len(X_train))\n",
    "print('테스트 샘플의 개수 :', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-gTg1Z2kYK2",
    "outputId": "c2162a05-dac7-47b5-d30d-5b9cb91a538e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------훈련 데이터의 비율-----------\n",
      "중립 = 33.391%\n",
      "긍정 = 33.366%\n",
      "부정 = 33.243%\n"
     ]
    }
   ],
   "source": [
    "print('--------훈련 데이터의 비율-----------')\n",
    "print(f'중립 = {round(y_train.value_counts()[0]/len(y_train) * 100,3)}%')\n",
    "print(f'긍정 = {round(y_train.value_counts()[1]/len(y_train) * 100,3)}%')\n",
    "print(f'부정 = {round(y_train.value_counts()[2]/len(y_train) * 100,3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6E_XYZIVkcP3",
    "outputId": "2aae17b0-fe59-46e9-b2dc-0287d03e63a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------테스트 데이터의 비율-----------\n",
      "중립 = 33.366%\n",
      "긍정 = 33.366%\n",
      "부정 = 33.268%\n"
     ]
    }
   ],
   "source": [
    "print('--------테스트 데이터의 비율-----------')\n",
    "print(f'중립 = {round(y_test.value_counts()[0]/len(y_test) * 100,3)}%')\n",
    "print(f'긍정 = {round(y_test.value_counts()[1]/len(y_test) * 100,3)}%')\n",
    "print(f'부정 = {round(y_test.value_counts()[2]/len(y_test) * 100,3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "WqLBfWmypQ6Y"
   },
   "outputs": [],
   "source": [
    "max_seq_len = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "f54e09e1acae4d28bbddcf27f0eadd55",
      "2171c39ae28b45d8ba3129cc1610e52f",
      "db6df438a1cb460487931c1c9f5498dd",
      "a47e27bdd7fb4ea39d77341ae161c8c8",
      "13b5d6ec770a4ef2a29dc9e354f0a5e4",
      "e2b4c0ebddbb4c26aa121c0aec986957",
      "374269e944984fa6b0e7be0a9b7771ee",
      "f149704594904529b3ffce9432d49fa7",
      "97e2c78205234ff0929b3e887e6dfd46",
      "43e0937b09934e8d81de9d5bd21152ba",
      "c3aa08f8f15447d0933fff8adcdb09bf",
      "d668f036c5934d80a2b07d95f6432f0c",
      "855b3aa3c9574fb491e06709952b2f89",
      "1d6c0ce65f804337969d49c07722c886",
      "d220bf12546244efa0652985ab2b3053",
      "b9fda1875e9a429f83ea4602832a79cf",
      "f2f6fa4ca9d94cc18d1d3569191cc2fc",
      "2a1f20425ba9433eb72beabc6c179543",
      "5883cb8d54e445a3a5b322806571f4e7",
      "63e26f8985ac4227a5633d724be0a9b2",
      "1b151d1b646f46acac755fa1288580c8",
      "1cd22e9c4f014e69a6f1206012fddb8c",
      "8723a9a082cb4893a6805bae8241d977",
      "753c832e90654b54aab4fc228f0ac2d2",
      "73dfeace493049ab93cc2032eec05390",
      "317d76f349d547fb8fc458961d6af56e",
      "e2af00816f8346bc81062993427a3dad",
      "e0bca5090f5640a89f83b850823c01df",
      "08662b5cf05644e2a2829cee2713a1be",
      "73904cb7aaca4c20965c56a3215fa848",
      "dce60906b70044169297d5d2618b2461",
      "d0ae8de401f94ffe87bdd9439f9136c2",
      "cb5d3e8bd5ef4aa6a4155088545a3d0c",
      "47f3d82231b54c0e948063e35ed27bbd",
      "c42e69c4808949fb9c48546ae09e0621",
      "ae06861e12c0469eab67b07d93d5ca9f",
      "8dd32717940249b880b4290d57110cb8",
      "1ac36ddd5d054d9d8d79a3643753f5b8",
      "07e43b56c69a4d9d875efc7b71a4899f",
      "98dfab65718b4e0d9704b00dc283c7ba",
      "20b60f13afde495092f035b7fb8737e9",
      "9e7e95d8c696434989cee60ad5db6509",
      "670b7fdf8ce9480ba404f973c7c15649",
      "48fcf028aa8142efa520d6b04fc9a69d",
      "97d7ae458fda43f695365b242f4b562b",
      "0f4b1da5893148e78fe567d61ba231e4",
      "d6a1c66def434ee2ae83f2e2c9ad28a8",
      "911d5b008fab4808a6ff95d0291bbbba",
      "b87418a2e0af464b8324cd03caea58a3",
      "0f44031b6cd4459d8f03cd4ac96f332d",
      "6b9a5cce10a1418bb1cb63c079c91a79",
      "7e90994f2d614906a24b33a1f0766325",
      "c19183ce5143404a99ccd6977289ecd5",
      "821c221cb1a3456d942d112818b32aed",
      "56b1b65d98414340b2a13a25497296c9"
     ]
    },
    "id": "h7qMQ_RVpUTv",
    "outputId": "c765d045-9c78-4527-c297-4e34b32a49b3"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('klue/bert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "6Lx0JeclpCd3"
   },
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, labels, max_seq_len, tokenizer):\n",
    "\n",
    "    input_ids, attention_masks, token_type_ids, data_labels = [], [], [], []\n",
    "\n",
    "    for example, label in tqdm(zip(examples, labels), total=len(examples)):\n",
    "        # input_id는 워드 임베딩을 위한 문장의 정수 인코딩\n",
    "        input_id = tokenizer.encode(example, max_length=max_seq_len, pad_to_max_length=True)\n",
    "\n",
    "        # attention_mask는 실제 단어가 위치하면 1, 패딩의 위치에는 0인 시퀀스.\n",
    "        padding_count = input_id.count(tokenizer.pad_token_id)\n",
    "        attention_mask = [1] * (max_seq_len - padding_count) + [0] * padding_count\n",
    "\n",
    "        # token_type_id은 세그먼트 인코딩\n",
    "        token_type_id = [0] * max_seq_len\n",
    "\n",
    "        assert len(input_id) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_id), max_seq_len)\n",
    "        assert len(attention_mask) == max_seq_len, \"Error with attention mask length {} vs {}\".format(len(attention_mask), max_seq_len)\n",
    "        assert len(token_type_id) == max_seq_len, \"Error with token type length {} vs {}\".format(len(token_type_id), max_seq_len)\n",
    "\n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        data_labels.append(label)\n",
    "\n",
    "    input_ids = np.array(input_ids, dtype=int)\n",
    "    attention_masks = np.array(attention_masks, dtype=int)\n",
    "    token_type_ids = np.array(token_type_ids, dtype=int)\n",
    "\n",
    "    data_labels = np.asarray(data_labels, dtype=np.int32)\n",
    "\n",
    "    return (input_ids, attention_masks, token_type_ids), data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K6GwA8ropGXJ",
    "outputId": "77324d21-e34c-4a64-b635-a650b9e4c70a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4073 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/ubuntu/anaconda3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████| 4073/4073 [00:00<00:00, 4472.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# train_X, train_y = convert_examples_to_features(X_train, y_train, max_seq_len=max_seq_len, tokenizer=tokenizer)\n",
    "\n",
    "# 학습 데이터 변환\n",
    "train_X, train_y = convert_examples_to_features(X_train, y_train, max_seq_len=max_seq_len, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FSUWW7XFphCU",
    "outputId": "2dffdb0f-f0ff-46af-b18d-ab75a5b27504"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1019/1019 [00:00<00:00, 4482.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# test_X, test_y = convert_examples_to_features(X_test, y_test, max_seq_len=max_seq_len, tokenizer=tokenizer)\n",
    "\n",
    "# 검증 데이터 변환\n",
    "val_X, val_y = convert_examples_to_features(X_test, y_test, max_seq_len=max_seq_len, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M9H0TQaUpl6q",
    "outputId": "1ff82442-9130-4b80-9941-d0b205dc29a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어에 대한 정수 인코딩 : [    2 25305  4778  2474  2267  2496 31369  1098   850  2031  2069  3636\n",
      "  3732  1363  2075     3     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "어텐션 마스크 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "세그먼트 인코딩 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "각 인코딩의 길이 : 128\n",
      "정수 인코딩 복원 : [CLS] 리니지 프리섭화되면서 뭔 돈들을 그리 많이 쓰나 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "레이블 : 2\n"
     ]
    }
   ],
   "source": [
    "input_id = train_X[0][0]\n",
    "attention_mask = train_X[1][0]\n",
    "token_type_id = train_X[2][0]\n",
    "label = train_y[0]\n",
    "\n",
    "print('단어에 대한 정수 인코딩 :',input_id)\n",
    "print('어텐션 마스크 :',attention_mask)\n",
    "print('세그먼트 인코딩 :',token_type_id)\n",
    "print('각 인코딩의 길이 :', len(input_id))\n",
    "print('정수 인코딩 복원 :',tokenizer.decode(input_id))\n",
    "print('레이블 :',label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ltdAJTeIp1_b",
    "outputId": "8803b4d0-b4f7-40f5-87e6-21cb0fc49dd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA GPU를 사용합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 01:53:12.425087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-27 01:53:12.438613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-27 01:53:12.440784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-27 01:53:12.446606: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-27 01:53:12.448132: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-27 01:53:12.450206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-27 01:53:12.452282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-27 01:53:17.532713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-27 01:53:17.534300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-27 01:53:17.535626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-27 01:53:17.537790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13227 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# TPU를 사용할 수 있는지 확인합니다\n",
    "if 'COLAB_TPU_ADDR' in os.environ:\n",
    "    # TPU가 사용 가능한 경우 TPU를 설정합니다\n",
    "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
    "    tf.config.experimental_connect_to_cluster(resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
    "    print('TPU를 사용합니다.')\n",
    "else:\n",
    "    # TPU가 사용 불가능한 경우 CUDA GPU를 사용합니다\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    if len(physical_devices) == 0:\n",
    "        raise RuntimeError(\"GPU를 찾을 수 없습니다. TensorFlow가 올바르게 설치되어 있는지 확인하세요.\")\n",
    "\n",
    "    # 모든 GPU 메모리를 필요에 따라 동적으로 할당하도록 설정합니다\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "    # CUDA GPU를 사용하는 경우 문자열 \"/gpu:0\"을 전달합니다\n",
    "    strategy = tf.distribute.OneDeviceStrategy(\"/gpu:0\")\n",
    "    print('CUDA GPU를 사용합니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "with strategy.scope():\n",
    "    model = TFBertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=3, from_pt=True)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bl2kHoBup9Di",
    "outputId": "ab3416de-da5f-4cc7-9f96-03099c375f59"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# with strategy.scope():\n",
    "#   model = TFBertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=3, from_pt=True)\n",
    "#   optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "#   loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "#   #model.compile(optimizer=optimizer, loss=model.compute_loss, metrics = ['accuracy'])\n",
    "#   model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFBertForSequenceClassification\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping 설정\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    min_delta=0.001,\n",
    "    patience=30,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# ModelCheckpoint 설정\n",
    "checkpoint_path = \"best_model_self(2).h5\"\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(\n",
    "    train_X, train_y, epochs=200, batch_size=32,\n",
    "    validation_data=(val_X, val_y),\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "# 평가 데이터 변환\n",
    "test_X, test_y = convert_examples_to_features(X_test, y_test, max_seq_len=max_seq_len, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 01:53:23.254826: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_4465\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020FlatMapDataset:4\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.7455 - accuracy: 0.6648"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 01:54:48.552953: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_24516\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\021FlatMapDataset:27\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.73865, saving model to best_model_self(2).h5\n",
      "102/102 [==============================] - 95s 788ms/step - loss: 0.7455 - accuracy: 0.6648 - val_loss: 0.6030 - val_accuracy: 0.7387\n",
      "Epoch 2/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.3767 - accuracy: 0.8610\n",
      "Epoch 2: val_accuracy improved from 0.73865 to 0.74724, saving model to best_model_self(2).h5\n",
      "102/102 [==============================] - 81s 790ms/step - loss: 0.3767 - accuracy: 0.8610 - val_loss: 0.6398 - val_accuracy: 0.7472\n",
      "Epoch 3/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.1601 - accuracy: 0.9503\n",
      "Epoch 3: val_accuracy improved from 0.74724 to 0.77791, saving model to best_model_self(2).h5\n",
      "102/102 [==============================] - 81s 792ms/step - loss: 0.1601 - accuracy: 0.9503 - val_loss: 0.7106 - val_accuracy: 0.7779\n",
      "Epoch 4/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.9708\n",
      "Epoch 4: val_accuracy did not improve from 0.77791\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0900 - accuracy: 0.9708 - val_loss: 0.9463 - val_accuracy: 0.7607\n",
      "Epoch 5/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 0.9822\n",
      "Epoch 5: val_accuracy did not improve from 0.77791\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0574 - accuracy: 0.9822 - val_loss: 0.9510 - val_accuracy: 0.7681\n",
      "Epoch 6/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.9837\n",
      "Epoch 6: val_accuracy improved from 0.77791 to 0.77914, saving model to best_model_self(2).h5\n",
      "102/102 [==============================] - 81s 793ms/step - loss: 0.0531 - accuracy: 0.9837 - val_loss: 0.9257 - val_accuracy: 0.7791\n",
      "Epoch 7/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0384 - accuracy: 0.9877\n",
      "Epoch 7: val_accuracy did not improve from 0.77914\n",
      "102/102 [==============================] - 78s 760ms/step - loss: 0.0384 - accuracy: 0.9877 - val_loss: 1.0622 - val_accuracy: 0.7742\n",
      "Epoch 8/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9871\n",
      "Epoch 8: val_accuracy did not improve from 0.77914\n",
      "102/102 [==============================] - 78s 761ms/step - loss: 0.0369 - accuracy: 0.9871 - val_loss: 1.1429 - val_accuracy: 0.7644\n",
      "Epoch 9/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9899\n",
      "Epoch 9: val_accuracy improved from 0.77914 to 0.78773, saving model to best_model_self(2).h5\n",
      "102/102 [==============================] - 81s 794ms/step - loss: 0.0359 - accuracy: 0.9899 - val_loss: 1.0594 - val_accuracy: 0.7877\n",
      "Epoch 10/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9929\n",
      "Epoch 10: val_accuracy did not improve from 0.78773\n",
      "102/102 [==============================] - 78s 761ms/step - loss: 0.0223 - accuracy: 0.9929 - val_loss: 1.0941 - val_accuracy: 0.7865\n",
      "Epoch 11/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9923\n",
      "Epoch 11: val_accuracy improved from 0.78773 to 0.79509, saving model to best_model_self(2).h5\n",
      "102/102 [==============================] - 82s 801ms/step - loss: 0.0213 - accuracy: 0.9923 - val_loss: 0.9925 - val_accuracy: 0.7951\n",
      "Epoch 12/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9886\n",
      "Epoch 12: val_accuracy improved from 0.79509 to 0.80368, saving model to best_model_self(2).h5\n",
      "102/102 [==============================] - 82s 802ms/step - loss: 0.0351 - accuracy: 0.9886 - val_loss: 1.0049 - val_accuracy: 0.8037\n",
      "Epoch 13/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9932\n",
      "Epoch 13: val_accuracy did not improve from 0.80368\n",
      "102/102 [==============================] - 78s 760ms/step - loss: 0.0222 - accuracy: 0.9932 - val_loss: 1.0627 - val_accuracy: 0.7951\n",
      "Epoch 14/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9902\n",
      "Epoch 14: val_accuracy did not improve from 0.80368\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0327 - accuracy: 0.9902 - val_loss: 1.0323 - val_accuracy: 0.7926\n",
      "Epoch 15/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9966\n",
      "Epoch 15: val_accuracy did not improve from 0.80368\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0088 - accuracy: 0.9966 - val_loss: 1.1985 - val_accuracy: 0.7706\n",
      "Epoch 16/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9982\n",
      "Epoch 16: val_accuracy did not improve from 0.80368\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 1.4340 - val_accuracy: 0.7620\n",
      "Epoch 17/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9939\n",
      "Epoch 17: val_accuracy did not improve from 0.80368\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0189 - accuracy: 0.9939 - val_loss: 1.1996 - val_accuracy: 0.7730\n",
      "Epoch 18/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9917\n",
      "Epoch 18: val_accuracy did not improve from 0.80368\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0274 - accuracy: 0.9917 - val_loss: 1.1623 - val_accuracy: 0.7693\n",
      "Epoch 19/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9902\n",
      "Epoch 19: val_accuracy did not improve from 0.80368\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0321 - accuracy: 0.9902 - val_loss: 0.9783 - val_accuracy: 0.8025\n",
      "Epoch 20/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9957\n",
      "Epoch 20: val_accuracy did not improve from 0.80368\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0108 - accuracy: 0.9957 - val_loss: 1.3000 - val_accuracy: 0.7632\n",
      "Epoch 21/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9966\n",
      "Epoch 21: val_accuracy did not improve from 0.80368\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0090 - accuracy: 0.9966 - val_loss: 1.3220 - val_accuracy: 0.7853\n",
      "Epoch 22/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9979\n",
      "Epoch 22: val_accuracy did not improve from 0.80368\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 1.3664 - val_accuracy: 0.7877\n",
      "Epoch 23/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9966\n",
      "Epoch 23: val_accuracy did not improve from 0.80368\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0081 - accuracy: 0.9966 - val_loss: 1.3133 - val_accuracy: 0.7693\n",
      "Epoch 24/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9936\n",
      "Epoch 24: val_accuracy did not improve from 0.80368\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0147 - accuracy: 0.9936 - val_loss: 1.2433 - val_accuracy: 0.7779\n",
      "Epoch 25/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9920\n",
      "Epoch 25: val_accuracy did not improve from 0.80368\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0263 - accuracy: 0.9920 - val_loss: 1.1118 - val_accuracy: 0.7988\n",
      "Epoch 26/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9936\n",
      "Epoch 26: val_accuracy did not improve from 0.80368\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0245 - accuracy: 0.9936 - val_loss: 1.3681 - val_accuracy: 0.7497\n",
      "Epoch 27/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9951\n",
      "Epoch 27: val_accuracy did not improve from 0.80368\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0164 - accuracy: 0.9951 - val_loss: 1.3109 - val_accuracy: 0.7828\n",
      "Epoch 28/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9972\n",
      "Epoch 28: val_accuracy did not improve from 0.80368\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0068 - accuracy: 0.9972 - val_loss: 1.3568 - val_accuracy: 0.7853\n",
      "Epoch 29/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9899\n",
      "Epoch 29: val_accuracy did not improve from 0.80368\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0298 - accuracy: 0.9899 - val_loss: 1.2563 - val_accuracy: 0.7632\n",
      "Epoch 30/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0405 - accuracy: 0.9902\n",
      "Epoch 30: val_accuracy did not improve from 0.80368\n",
      "102/102 [==============================] - 78s 760ms/step - loss: 0.0405 - accuracy: 0.9902 - val_loss: 1.0435 - val_accuracy: 0.7939\n",
      "Epoch 31/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9975\n",
      "Epoch 31: val_accuracy did not improve from 0.80368\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 1.2459 - val_accuracy: 0.7926\n",
      "Epoch 32/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9991\n",
      "Epoch 32: val_accuracy improved from 0.80368 to 0.81595, saving model to best_model_self(2).h5\n",
      "102/102 [==============================] - 81s 793ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 1.2501 - val_accuracy: 0.8160\n",
      "Epoch 33/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9954\n",
      "Epoch 33: val_accuracy did not improve from 0.81595\n",
      "102/102 [==============================] - 77s 759ms/step - loss: 0.0183 - accuracy: 0.9954 - val_loss: 1.1659 - val_accuracy: 0.7939\n",
      "Epoch 34/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9960\n",
      "Epoch 34: val_accuracy did not improve from 0.81595\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0109 - accuracy: 0.9960 - val_loss: 1.3144 - val_accuracy: 0.7804\n",
      "Epoch 35/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9985\n",
      "Epoch 35: val_accuracy did not improve from 0.81595\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0034 - accuracy: 0.9985 - val_loss: 1.5014 - val_accuracy: 0.7816\n",
      "Epoch 36/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9988\n",
      "Epoch 36: val_accuracy did not improve from 0.81595\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 1.5045 - val_accuracy: 0.7902\n",
      "Epoch 37/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9969\n",
      "Epoch 37: val_accuracy did not improve from 0.81595\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0073 - accuracy: 0.9969 - val_loss: 1.3941 - val_accuracy: 0.7890\n",
      "Epoch 38/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9951\n",
      "Epoch 38: val_accuracy did not improve from 0.81595\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 1.2264 - val_accuracy: 0.7853\n",
      "Epoch 39/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9985\n",
      "Epoch 39: val_accuracy did not improve from 0.81595\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0030 - accuracy: 0.9985 - val_loss: 1.3367 - val_accuracy: 0.8049\n",
      "Epoch 40/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9960\n",
      "Epoch 40: val_accuracy did not improve from 0.81595\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0172 - accuracy: 0.9960 - val_loss: 1.1235 - val_accuracy: 0.7926\n",
      "Epoch 41/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9966\n",
      "Epoch 41: val_accuracy did not improve from 0.81595\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0134 - accuracy: 0.9966 - val_loss: 1.2463 - val_accuracy: 0.8074\n",
      "Epoch 42/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9969\n",
      "Epoch 42: val_accuracy did not improve from 0.81595\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 1.2214 - val_accuracy: 0.8074\n",
      "Epoch 43/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9905\n",
      "Epoch 43: val_accuracy did not improve from 0.81595\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0310 - accuracy: 0.9905 - val_loss: 1.0696 - val_accuracy: 0.8074\n",
      "Epoch 44/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9942\n",
      "Epoch 44: val_accuracy did not improve from 0.81595\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0254 - accuracy: 0.9942 - val_loss: 1.0799 - val_accuracy: 0.7939\n",
      "Epoch 45/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9975\n",
      "Epoch 45: val_accuracy did not improve from 0.81595\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 1.1970 - val_accuracy: 0.8086\n",
      "Epoch 46/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9932\n",
      "Epoch 46: val_accuracy did not improve from 0.81595\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0220 - accuracy: 0.9932 - val_loss: 1.1299 - val_accuracy: 0.7975\n",
      "Epoch 47/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.9936\n",
      "Epoch 47: val_accuracy did not improve from 0.81595\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0215 - accuracy: 0.9936 - val_loss: 1.1534 - val_accuracy: 0.8025\n",
      "Epoch 48/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9975\n",
      "Epoch 48: val_accuracy did not improve from 0.81595\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0045 - accuracy: 0.9975 - val_loss: 1.3532 - val_accuracy: 0.8061\n",
      "Epoch 49/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9988\n",
      "Epoch 49: val_accuracy did not improve from 0.81595\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 1.4264 - val_accuracy: 0.8135\n",
      "Epoch 50/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9972\n",
      "Epoch 50: val_accuracy did not improve from 0.81595\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0051 - accuracy: 0.9972 - val_loss: 1.5106 - val_accuracy: 0.7939\n",
      "Epoch 51/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9945\n",
      "Epoch 51: val_accuracy did not improve from 0.81595\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 1.3765 - val_accuracy: 0.8025\n",
      "Epoch 52/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9902\n",
      "Epoch 52: val_accuracy did not improve from 0.81595\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0313 - accuracy: 0.9902 - val_loss: 1.1541 - val_accuracy: 0.8147\n",
      "Epoch 53/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9957\n",
      "Epoch 53: val_accuracy did not improve from 0.81595\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 1.2047 - val_accuracy: 0.7951\n",
      "Epoch 54/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.9936\n",
      "Epoch 54: val_accuracy did not improve from 0.81595\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0270 - accuracy: 0.9936 - val_loss: 1.1946 - val_accuracy: 0.8135\n",
      "Epoch 55/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9988\n",
      "Epoch 55: val_accuracy improved from 0.81595 to 0.81718, saving model to best_model_self(2).h5\n",
      "102/102 [==============================] - 81s 794ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 1.3124 - val_accuracy: 0.8172\n",
      "Epoch 56/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9988\n",
      "Epoch 56: val_accuracy did not improve from 0.81718\n",
      "102/102 [==============================] - 77s 759ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 1.3715 - val_accuracy: 0.8172\n",
      "Epoch 57/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9975\n",
      "Epoch 57: val_accuracy did not improve from 0.81718\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 1.2770 - val_accuracy: 0.8147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9979\n",
      "Epoch 58: val_accuracy did not improve from 0.81718\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 1.3319 - val_accuracy: 0.8037\n",
      "Epoch 59/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9979\n",
      "Epoch 59: val_accuracy did not improve from 0.81718\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 1.4216 - val_accuracy: 0.7902\n",
      "Epoch 60/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9979\n",
      "Epoch 60: val_accuracy did not improve from 0.81718\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 1.4279 - val_accuracy: 0.7890\n",
      "Epoch 61/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9988\n",
      "Epoch 61: val_accuracy did not improve from 0.81718\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.4233 - val_accuracy: 0.8061\n",
      "Epoch 62/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9991\n",
      "Epoch 62: val_accuracy did not improve from 0.81718\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0018 - accuracy: 0.9991 - val_loss: 1.4874 - val_accuracy: 0.8037\n",
      "Epoch 63/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9988\n",
      "Epoch 63: val_accuracy did not improve from 0.81718\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 1.4822 - val_accuracy: 0.8086\n",
      "Epoch 64/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9991\n",
      "Epoch 64: val_accuracy did not improve from 0.81718\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0019 - accuracy: 0.9991 - val_loss: 1.5116 - val_accuracy: 0.8049\n",
      "Epoch 65/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9985\n",
      "Epoch 65: val_accuracy did not improve from 0.81718\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0020 - accuracy: 0.9985 - val_loss: 1.5284 - val_accuracy: 0.8037\n",
      "Epoch 66/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9991\n",
      "Epoch 66: val_accuracy did not improve from 0.81718\n",
      "102/102 [==============================] - 78s 761ms/step - loss: 0.0019 - accuracy: 0.9991 - val_loss: 1.5555 - val_accuracy: 0.8049\n",
      "Epoch 67/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9991\n",
      "Epoch 67: val_accuracy did not improve from 0.81718\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0019 - accuracy: 0.9991 - val_loss: 1.5779 - val_accuracy: 0.8049\n",
      "Epoch 68/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9905\n",
      "Epoch 68: val_accuracy did not improve from 0.81718\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0309 - accuracy: 0.9905 - val_loss: 1.4574 - val_accuracy: 0.7853\n",
      "Epoch 69/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9920\n",
      "Epoch 69: val_accuracy did not improve from 0.81718\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0241 - accuracy: 0.9920 - val_loss: 1.3428 - val_accuracy: 0.8025\n",
      "Epoch 70/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 0.9920\n",
      "Epoch 70: val_accuracy did not improve from 0.81718\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0282 - accuracy: 0.9920 - val_loss: 1.0506 - val_accuracy: 0.8061\n",
      "Epoch 71/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9954\n",
      "Epoch 71: val_accuracy did not improve from 0.81718\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 1.2917 - val_accuracy: 0.7877\n",
      "Epoch 72/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9951\n",
      "Epoch 72: val_accuracy did not improve from 0.81718\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 1.3964 - val_accuracy: 0.7853\n",
      "Epoch 73/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9969\n",
      "Epoch 73: val_accuracy did not improve from 0.81718\n",
      "102/102 [==============================] - 78s 760ms/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 1.2698 - val_accuracy: 0.8074\n",
      "Epoch 74/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9975\n",
      "Epoch 74: val_accuracy did not improve from 0.81718\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0056 - accuracy: 0.9975 - val_loss: 1.4222 - val_accuracy: 0.8000\n",
      "Epoch 75/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9975\n",
      "Epoch 75: val_accuracy improved from 0.81718 to 0.81963, saving model to best_model_self(2).h5\n",
      "102/102 [==============================] - 81s 794ms/step - loss: 0.0106 - accuracy: 0.9975 - val_loss: 1.2508 - val_accuracy: 0.8196\n",
      "Epoch 76/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9963\n",
      "Epoch 76: val_accuracy did not improve from 0.81963\n",
      "102/102 [==============================] - 78s 760ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 1.2613 - val_accuracy: 0.7877\n",
      "Epoch 77/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9988\n",
      "Epoch 77: val_accuracy improved from 0.81963 to 0.82699, saving model to best_model_self(2).h5\n",
      "102/102 [==============================] - 81s 794ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 1.2894 - val_accuracy: 0.8270\n",
      "Epoch 78/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 78: val_accuracy improved from 0.82699 to 0.83190, saving model to best_model_self(2).h5\n",
      "102/102 [==============================] - 81s 793ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 1.3454 - val_accuracy: 0.8319\n",
      "Epoch 79/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9988\n",
      "Epoch 79: val_accuracy improved from 0.83190 to 0.83436, saving model to best_model_self(2).h5\n",
      "102/102 [==============================] - 81s 793ms/step - loss: 0.0019 - accuracy: 0.9988 - val_loss: 1.3838 - val_accuracy: 0.8344\n",
      "Epoch 80/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9991\n",
      "Epoch 80: val_accuracy improved from 0.83436 to 0.83681, saving model to best_model_self(2).h5\n",
      "102/102 [==============================] - 81s 793ms/step - loss: 0.0019 - accuracy: 0.9991 - val_loss: 1.3939 - val_accuracy: 0.8368\n",
      "Epoch 81/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9988\n",
      "Epoch 81: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 78s 760ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.4581 - val_accuracy: 0.8270\n",
      "Epoch 82/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9963\n",
      "Epoch 82: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 1.3176 - val_accuracy: 0.8086\n",
      "Epoch 83/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9975\n",
      "Epoch 83: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0115 - accuracy: 0.9975 - val_loss: 1.1636 - val_accuracy: 0.8196\n",
      "Epoch 84/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9979\n",
      "Epoch 84: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 1.3579 - val_accuracy: 0.8258\n",
      "Epoch 85/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9982\n",
      "Epoch 85: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0039 - accuracy: 0.9982 - val_loss: 1.4454 - val_accuracy: 0.8098\n",
      "Epoch 86/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9945\n",
      "Epoch 86: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 1.2266 - val_accuracy: 0.8209\n",
      "Epoch 87/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.9902\n",
      "Epoch 87: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0373 - accuracy: 0.9902 - val_loss: 1.1264 - val_accuracy: 0.7939\n",
      "Epoch 88/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9957\n",
      "Epoch 88: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0099 - accuracy: 0.9957 - val_loss: 1.1421 - val_accuracy: 0.8233\n",
      "Epoch 89/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9963\n",
      "Epoch 89: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0069 - accuracy: 0.9963 - val_loss: 1.4705 - val_accuracy: 0.7902\n",
      "Epoch 90/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9954\n",
      "Epoch 90: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 1.1294 - val_accuracy: 0.8233\n",
      "Epoch 91/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9969\n",
      "Epoch 91: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0073 - accuracy: 0.9969 - val_loss: 1.2071 - val_accuracy: 0.8135\n",
      "Epoch 92/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9972\n",
      "Epoch 92: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0074 - accuracy: 0.9972 - val_loss: 1.1630 - val_accuracy: 0.8160\n",
      "Epoch 93/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9982\n",
      "Epoch 93: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0029 - accuracy: 0.9982 - val_loss: 1.2400 - val_accuracy: 0.8270\n",
      "Epoch 94/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9985\n",
      "Epoch 94: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0022 - accuracy: 0.9985 - val_loss: 1.3741 - val_accuracy: 0.8049\n",
      "Epoch 95/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9975\n",
      "Epoch 95: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 1.2772 - val_accuracy: 0.7988\n",
      "Epoch 96/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9988\n",
      "Epoch 96: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 1.2296 - val_accuracy: 0.8049\n",
      "Epoch 97/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9991\n",
      "Epoch 97: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0019 - accuracy: 0.9991 - val_loss: 1.2876 - val_accuracy: 0.8209\n",
      "Epoch 98/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9969\n",
      "Epoch 98: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 78s 761ms/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 1.3239 - val_accuracy: 0.7988\n",
      "Epoch 99/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9966\n",
      "Epoch 99: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 78s 761ms/step - loss: 0.0158 - accuracy: 0.9966 - val_loss: 1.3806 - val_accuracy: 0.7791\n",
      "Epoch 100/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9966\n",
      "Epoch 100: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 78s 761ms/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 1.2506 - val_accuracy: 0.8123\n",
      "Epoch 101/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9985\n",
      "Epoch 101: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 1.3435 - val_accuracy: 0.8061\n",
      "Epoch 102/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9948\n",
      "Epoch 102: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 78s 761ms/step - loss: 0.0230 - accuracy: 0.9948 - val_loss: 1.3305 - val_accuracy: 0.7853\n",
      "Epoch 103/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9985\n",
      "Epoch 103: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 78s 761ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 1.4143 - val_accuracy: 0.7804\n",
      "Epoch 104/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9942\n",
      "Epoch 104: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 78s 761ms/step - loss: 0.0232 - accuracy: 0.9942 - val_loss: 1.4508 - val_accuracy: 0.7656\n",
      "Epoch 105/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9951\n",
      "Epoch 105: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 78s 760ms/step - loss: 0.0183 - accuracy: 0.9951 - val_loss: 1.1888 - val_accuracy: 0.7840\n",
      "Epoch 106/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9948\n",
      "Epoch 106: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0185 - accuracy: 0.9948 - val_loss: 1.1359 - val_accuracy: 0.7963\n",
      "Epoch 107/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9966\n",
      "Epoch 107: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 78s 761ms/step - loss: 0.0127 - accuracy: 0.9966 - val_loss: 1.2899 - val_accuracy: 0.8049\n",
      "Epoch 108/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9988\n",
      "Epoch 108: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 77s 760ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 1.3750 - val_accuracy: 0.8074\n",
      "Epoch 109/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9982\n",
      "Epoch 109: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 78s 761ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 1.3385 - val_accuracy: 0.8025\n",
      "Epoch 110/200\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9985\n",
      "Epoch 110: val_accuracy did not improve from 0.83681\n",
      "102/102 [==============================] - 78s 763ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 1.3496 - val_accuracy: 0.8074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f85981b1180>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # EarlyStopping 설정\n",
    "# early_stopping = EarlyStopping(\n",
    "#     monitor=\"val_accuracy\",\n",
    "#     min_delta=0.001,\n",
    "#     patience=30,\n",
    "#     restore_best_weights=True\n",
    "# )\n",
    "\n",
    "# # ModelCheckpoint 설정\n",
    "# checkpoint_path = \"best_model_self(3).h5\"\n",
    "# model_checkpoint = ModelCheckpoint(\n",
    "#     filepath=checkpoint_path,\n",
    "#     save_weights_only=True,\n",
    "#     monitor='val_accuracy',  # val_loss를 기준으로 성능을 평가합니다\n",
    "#     mode='max',  # 'min' 모드로 설정하여 val_loss가 최소일 때 모델을 저장합니다\n",
    "#     save_best_only=True,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# # 모델 학습\n",
    "# model.fit(\n",
    "#     train_X, train_y, epochs=200, batch_size=32, validation_split=0.2,\n",
    "#     callbacks=[early_stopping, model_checkpoint]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "model.evaluate(test_X, test_y, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7zQ3dpqz1UaN",
    "outputId": "f782d935-4cba-4b7f-c01d-38c5a0896254"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 04:16:29.834541: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_103851\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\023FlatMapDataset:1246\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step - loss: 1.3221 - accuracy: 0.8224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.322080373764038, 0.8223748803138733]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.evaluate(test_X, test_y, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model_self(2).h5\n",
    "# 1/1 [==============================] - 8s 8s/step - loss: 1.3221 - accuracy: 0.8224\n",
    "# [1.322080373764038, 0.8223748803138733]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model_self(3).h5\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "BERT finance sentiment analysis_kor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07e43b56c69a4d9d875efc7b71a4899f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "08662b5cf05644e2a2829cee2713a1be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f44031b6cd4459d8f03cd4ac96f332d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0f4b1da5893148e78fe567d61ba231e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13b5d6ec770a4ef2a29dc9e354f0a5e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3aa08f8f15447d0933fff8adcdb09bf",
      "placeholder": "​",
      "style": "IPY_MODEL_43e0937b09934e8d81de9d5bd21152ba",
      "value": " 243k/243k [00:00&lt;00:00, 1.58MB/s]"
     }
    },
    "1ac36ddd5d054d9d8d79a3643753f5b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48fcf028aa8142efa520d6b04fc9a69d",
      "placeholder": "​",
      "style": "IPY_MODEL_670b7fdf8ce9480ba404f973c7c15649",
      "value": " 483k/483k [00:00&lt;00:00, 1.60MB/s]"
     }
    },
    "1b151d1b646f46acac755fa1288580c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1cd22e9c4f014e69a6f1206012fddb8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d6c0ce65f804337969d49c07722c886": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a1f20425ba9433eb72beabc6c179543",
      "placeholder": "​",
      "style": "IPY_MODEL_f2f6fa4ca9d94cc18d1d3569191cc2fc",
      "value": "Downloading: 100%"
     }
    },
    "20b60f13afde495092f035b7fb8737e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2171c39ae28b45d8ba3129cc1610e52f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a1f20425ba9433eb72beabc6c179543": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "317d76f349d547fb8fc458961d6af56e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dce60906b70044169297d5d2618b2461",
      "max": 289,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_73904cb7aaca4c20965c56a3215fa848",
      "value": 289
     }
    },
    "374269e944984fa6b0e7be0a9b7771ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43e0937b09934e8d81de9d5bd21152ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "47f3d82231b54c0e948063e35ed27bbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ae06861e12c0469eab67b07d93d5ca9f",
       "IPY_MODEL_8dd32717940249b880b4290d57110cb8",
       "IPY_MODEL_1ac36ddd5d054d9d8d79a3643753f5b8"
      ],
      "layout": "IPY_MODEL_c42e69c4808949fb9c48546ae09e0621"
     }
    },
    "48fcf028aa8142efa520d6b04fc9a69d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56b1b65d98414340b2a13a25497296c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5883cb8d54e445a3a5b322806571f4e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "63e26f8985ac4227a5633d724be0a9b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "670b7fdf8ce9480ba404f973c7c15649": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b9a5cce10a1418bb1cb63c079c91a79": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73904cb7aaca4c20965c56a3215fa848": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "73dfeace493049ab93cc2032eec05390": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08662b5cf05644e2a2829cee2713a1be",
      "placeholder": "​",
      "style": "IPY_MODEL_e0bca5090f5640a89f83b850823c01df",
      "value": "Downloading: 100%"
     }
    },
    "753c832e90654b54aab4fc228f0ac2d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e90994f2d614906a24b33a1f0766325": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "821c221cb1a3456d942d112818b32aed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "855b3aa3c9574fb491e06709952b2f89": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8723a9a082cb4893a6805bae8241d977": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_73dfeace493049ab93cc2032eec05390",
       "IPY_MODEL_317d76f349d547fb8fc458961d6af56e",
       "IPY_MODEL_e2af00816f8346bc81062993427a3dad"
      ],
      "layout": "IPY_MODEL_753c832e90654b54aab4fc228f0ac2d2"
     }
    },
    "8dd32717940249b880b4290d57110cb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e7e95d8c696434989cee60ad5db6509",
      "max": 494860,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_20b60f13afde495092f035b7fb8737e9",
      "value": 494860
     }
    },
    "911d5b008fab4808a6ff95d0291bbbba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c19183ce5143404a99ccd6977289ecd5",
      "max": 425,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7e90994f2d614906a24b33a1f0766325",
      "value": 425
     }
    },
    "97d7ae458fda43f695365b242f4b562b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d6a1c66def434ee2ae83f2e2c9ad28a8",
       "IPY_MODEL_911d5b008fab4808a6ff95d0291bbbba",
       "IPY_MODEL_b87418a2e0af464b8324cd03caea58a3"
      ],
      "layout": "IPY_MODEL_0f4b1da5893148e78fe567d61ba231e4"
     }
    },
    "97e2c78205234ff0929b3e887e6dfd46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98dfab65718b4e0d9704b00dc283c7ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e7e95d8c696434989cee60ad5db6509": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a47e27bdd7fb4ea39d77341ae161c8c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97e2c78205234ff0929b3e887e6dfd46",
      "max": 248477,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f149704594904529b3ffce9432d49fa7",
      "value": 248477
     }
    },
    "ae06861e12c0469eab67b07d93d5ca9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98dfab65718b4e0d9704b00dc283c7ba",
      "placeholder": "​",
      "style": "IPY_MODEL_07e43b56c69a4d9d875efc7b71a4899f",
      "value": "Downloading: 100%"
     }
    },
    "b87418a2e0af464b8324cd03caea58a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56b1b65d98414340b2a13a25497296c9",
      "placeholder": "​",
      "style": "IPY_MODEL_821c221cb1a3456d942d112818b32aed",
      "value": " 425/425 [00:00&lt;00:00, 15.8kB/s]"
     }
    },
    "b9fda1875e9a429f83ea4602832a79cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1cd22e9c4f014e69a6f1206012fddb8c",
      "placeholder": "​",
      "style": "IPY_MODEL_1b151d1b646f46acac755fa1288580c8",
      "value": " 125/125 [00:00&lt;00:00, 4.72kB/s]"
     }
    },
    "c19183ce5143404a99ccd6977289ecd5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3aa08f8f15447d0933fff8adcdb09bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c42e69c4808949fb9c48546ae09e0621": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb5d3e8bd5ef4aa6a4155088545a3d0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0ae8de401f94ffe87bdd9439f9136c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d220bf12546244efa0652985ab2b3053": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63e26f8985ac4227a5633d724be0a9b2",
      "max": 125,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5883cb8d54e445a3a5b322806571f4e7",
      "value": 125
     }
    },
    "d668f036c5934d80a2b07d95f6432f0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1d6c0ce65f804337969d49c07722c886",
       "IPY_MODEL_d220bf12546244efa0652985ab2b3053",
       "IPY_MODEL_b9fda1875e9a429f83ea4602832a79cf"
      ],
      "layout": "IPY_MODEL_855b3aa3c9574fb491e06709952b2f89"
     }
    },
    "d6a1c66def434ee2ae83f2e2c9ad28a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b9a5cce10a1418bb1cb63c079c91a79",
      "placeholder": "​",
      "style": "IPY_MODEL_0f44031b6cd4459d8f03cd4ac96f332d",
      "value": "Downloading: 100%"
     }
    },
    "db6df438a1cb460487931c1c9f5498dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_374269e944984fa6b0e7be0a9b7771ee",
      "placeholder": "​",
      "style": "IPY_MODEL_e2b4c0ebddbb4c26aa121c0aec986957",
      "value": "Downloading: 100%"
     }
    },
    "dce60906b70044169297d5d2618b2461": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0bca5090f5640a89f83b850823c01df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e2af00816f8346bc81062993427a3dad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb5d3e8bd5ef4aa6a4155088545a3d0c",
      "placeholder": "​",
      "style": "IPY_MODEL_d0ae8de401f94ffe87bdd9439f9136c2",
      "value": " 289/289 [00:00&lt;00:00, 11.1kB/s]"
     }
    },
    "e2b4c0ebddbb4c26aa121c0aec986957": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f149704594904529b3ffce9432d49fa7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f2f6fa4ca9d94cc18d1d3569191cc2fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f54e09e1acae4d28bbddcf27f0eadd55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_db6df438a1cb460487931c1c9f5498dd",
       "IPY_MODEL_a47e27bdd7fb4ea39d77341ae161c8c8",
       "IPY_MODEL_13b5d6ec770a4ef2a29dc9e354f0a5e4"
      ],
      "layout": "IPY_MODEL_2171c39ae28b45d8ba3129cc1610e52f"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
